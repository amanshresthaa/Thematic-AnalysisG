2024-12-05 17:28:36,761 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:37,036 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:37,048 - root - WARNING - 	*** Since DSPy 2.5.16+, TypedPredictors are now deprecated, underperform, and are about to be removed! ***
Please use standard predictors, e.g. dspy.Predict and dspy.ChainOfThought.
They now support type annotations and other features of TypedPredictors and tend to work much better out of the box.
Please let us know if you face any issues: https://github.com/stanfordnlp/dspy/issues
2024-12-05 17:28:37,048 - src.analysis.metrics - INFO - Comprehensive Assessment DSPy module initialized successfully.
2024-12-05 17:28:37,053 - src.processing.answer_generator - INFO - Unoptimized DSPy module initialized successfully.
2024-12-05 17:28:37,107 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:40,269 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:40,272 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:40,290 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:40,294 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:40,299 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:28:40,301 - __main__ - INFO - Starting Standard Quotation Extraction Pipeline
2024-12-05 17:28:40,301 - __main__ - INFO - Configuring DSPy Language Model
2024-12-05 17:28:40,301 - __main__ - INFO - Loading codebase chunks from 'data/codebase_chunks/standard/codebase_chunks.json'
2024-12-05 17:28:40,301 - src.data.data_loader - ERROR - Error loading JSON file 'data/codebase_chunks/standard/codebase_chunks.json': File does not exist.
2024-12-05 17:28:40,301 - __main__ - INFO - Initializing ContextualVectorDB
2024-12-05 17:28:40,307 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-05 17:28:40,307 - src.core.contextual_vector_db - INFO - Total chunks to process: 0
2024-12-05 17:28:40,307 - src.core.contextual_vector_db - INFO - Processing 0 chunks with 1 threads.
2024-12-05 17:28:40,319 - src.core.contextual_vector_db - INFO - Starting embedding generation.
2024-12-05 17:28:40,320 - src.core.contextual_vector_db - INFO - Embedding generation completed.
2024-12-05 17:28:40,320 - src.core.contextual_vector_db - INFO - Vector database metadata saved to './data/contextual_db/contextual_vector_db.pkl'
2024-12-05 17:28:40,320 - src.core.contextual_vector_db - ERROR - Error creating FAISS index: list index out of range
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 199, in create_faiss_index
    embedding_dim = len(self.embeddings[0])
                        ~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-12-05 17:28:40,321 - __main__ - ERROR - Error loading data into ContextualVectorDB: list index out of range
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 239, in run_pipeline_with_config
    self.contextual_db.load_data(codebase_chunks, parallel_threads=1)
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 97, in load_data
    self._build_faiss_index()
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 193, in _build_faiss_index
    self.create_faiss_index()
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 199, in create_faiss_index
    embedding_dim = len(self.embeddings[0])
                        ~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-12-05 17:28:40,321 - __main__ - INFO - Converting data: Quotation to Keyword Conversion (Standard)
2024-12-05 17:28:40,321 - __main__ - INFO - Conversion successful: Quotation to Keyword Conversion (Standard)
2024-12-05 17:28:40,321 - __main__ - INFO - Starting Keyword Extraction Pipeline for Standard Quotation
2024-12-05 17:28:40,321 - __main__ - INFO - Configuring DSPy Language Model
2024-12-05 17:28:40,322 - __main__ - INFO - Loading codebase chunks from 'data/codebase_chunks/keyword/codebase_chunks_keyword.json'
2024-12-05 17:28:40,322 - src.data.data_loader - ERROR - Error loading JSON file 'data/codebase_chunks/keyword/codebase_chunks_keyword.json': File does not exist.
2024-12-05 17:28:40,322 - __main__ - INFO - Initializing ContextualVectorDB
2024-12-05 17:28:40,328 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-05 17:28:40,328 - src.core.contextual_vector_db - INFO - Total chunks to process: 0
2024-12-05 17:28:40,328 - src.core.contextual_vector_db - INFO - Processing 0 chunks with 1 threads.
2024-12-05 17:28:40,328 - src.core.contextual_vector_db - INFO - Starting embedding generation.
2024-12-05 17:28:40,328 - src.core.contextual_vector_db - INFO - Embedding generation completed.
2024-12-05 17:28:40,329 - src.core.contextual_vector_db - INFO - Vector database metadata saved to './data/contextual_db/contextual_vector_db.pkl'
2024-12-05 17:28:40,329 - src.core.contextual_vector_db - ERROR - Error creating FAISS index: list index out of range
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 199, in create_faiss_index
    embedding_dim = len(self.embeddings[0])
                        ~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-12-05 17:28:40,329 - __main__ - ERROR - Error loading data into ContextualVectorDB: list index out of range
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 239, in run_pipeline_with_config
    self.contextual_db.load_data(codebase_chunks, parallel_threads=1)
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 97, in load_data
    self._build_faiss_index()
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 193, in _build_faiss_index
    self.create_faiss_index()
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 199, in create_faiss_index
    embedding_dim = len(self.embeddings[0])
                        ~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-12-05 17:28:40,329 - __main__ - INFO - Converting data: Keyword to Coding Conversion (Standard)
2024-12-05 17:28:40,329 - __main__ - INFO - Conversion successful: Keyword to Coding Conversion (Standard)
2024-12-05 17:28:40,329 - __main__ - INFO - Starting Coding Analysis Pipeline for Standard Keyword Extraction
2024-12-05 17:28:40,329 - __main__ - INFO - Configuring DSPy Language Model
2024-12-05 17:28:40,329 - __main__ - INFO - Loading codebase chunks from 'data/codebase_chunks/coding/codebase_chunks_coding.json'
2024-12-05 17:28:40,329 - src.data.data_loader - ERROR - Error loading JSON file 'data/codebase_chunks/coding/codebase_chunks_coding.json': File does not exist.
2024-12-05 17:28:40,329 - __main__ - INFO - Initializing ContextualVectorDB
2024-12-05 17:28:40,335 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-05 17:28:40,335 - src.core.contextual_vector_db - INFO - Total chunks to process: 0
2024-12-05 17:28:40,335 - src.core.contextual_vector_db - INFO - Processing 0 chunks with 1 threads.
2024-12-05 17:28:40,335 - src.core.contextual_vector_db - INFO - Starting embedding generation.
2024-12-05 17:28:40,335 - src.core.contextual_vector_db - INFO - Embedding generation completed.
2024-12-05 17:28:40,335 - src.core.contextual_vector_db - INFO - Vector database metadata saved to './data/contextual_db/contextual_vector_db.pkl'
2024-12-05 17:28:40,335 - src.core.contextual_vector_db - ERROR - Error creating FAISS index: list index out of range
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 199, in create_faiss_index
    embedding_dim = len(self.embeddings[0])
                        ~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-12-05 17:28:40,335 - __main__ - ERROR - Error loading data into ContextualVectorDB: list index out of range
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 239, in run_pipeline_with_config
    self.contextual_db.load_data(codebase_chunks, parallel_threads=1)
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 97, in load_data
    self._build_faiss_index()
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 193, in _build_faiss_index
    self.create_faiss_index()
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/core/contextual_vector_db.py", line 199, in create_faiss_index
    embedding_dim = len(self.embeddings[0])
                        ~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-12-05 17:28:40,336 - __main__ - INFO - Converting data: Coding to Theme Conversion (Standard)
2024-12-05 17:28:40,336 - __main__ - INFO - Conversion successful: Coding to Theme Conversion (Standard)
2024-12-05 17:28:40,336 - __main__ - INFO - All pipelines and conversion steps executed successfully up to Coding Analysis.
2024-12-05 17:29:25,150 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:25,196 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:25,204 - root - WARNING - 	*** Since DSPy 2.5.16+, TypedPredictors are now deprecated, underperform, and are about to be removed! ***
Please use standard predictors, e.g. dspy.Predict and dspy.ChainOfThought.
They now support type annotations and other features of TypedPredictors and tend to work much better out of the box.
Please let us know if you face any issues: https://github.com/stanfordnlp/dspy/issues
2024-12-05 17:29:25,204 - src.analysis.metrics - INFO - Comprehensive Assessment DSPy module initialized successfully.
2024-12-05 17:29:25,209 - src.processing.answer_generator - INFO - Unoptimized DSPy module initialized successfully.
2024-12-05 17:29:25,212 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:26,143 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:26,145 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:26,156 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:26,159 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:26,162 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-05 17:29:26,162 - __main__ - INFO - Starting Standard Quotation Extraction Pipeline
2024-12-05 17:29:26,162 - __main__ - INFO - Configuring DSPy Language Model
2024-12-05 17:29:26,162 - __main__ - INFO - Loading codebase chunks from 'data/codebase_chunks/standard/codebase_chunks.json'
2024-12-05 17:29:26,162 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/standard/codebase_chunks.json' successfully with 1 entries.
2024-12-05 17:29:26,162 - __main__ - INFO - Initializing ContextualVectorDB
2024-12-05 17:29:26,168 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-05 17:29:26,168 - src.core.contextual_vector_db - INFO - Total chunks to process: 3
2024-12-05 17:29:26,168 - src.core.contextual_vector_db - INFO - Processing 3 chunks with 1 threads.
2024-12-05 17:29:26,189 - src.core.contextual_vector_db - INFO - Starting embedding generation.
2024-12-05 17:29:27,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-05 17:29:27,335 - src.core.contextual_vector_db - INFO - Embedding generation completed.
2024-12-05 17:29:27,336 - src.core.contextual_vector_db - INFO - Vector database metadata saved to './data/contextual_db/contextual_vector_db.pkl'
2024-12-05 17:29:27,336 - src.core.contextual_vector_db - INFO - Embedding dimension: 1536
2024-12-05 17:29:27,338 - src.core.contextual_vector_db - INFO - FAISS index created with 3 vectors.
2024-12-05 17:29:27,339 - src.core.contextual_vector_db - INFO - FAISS index saved to './data/contextual_db/faiss_index.bin'
2024-12-05 17:29:27,339 - src.core.contextual_vector_db - INFO - Contextual Vector database loaded and saved. Total chunks processed: 3
2024-12-05 17:29:27,340 - __main__ - INFO - Creating Elasticsearch BM25 index 'contextual_bm25_index_standard_quotation'
2024-12-05 17:29:27,351 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.010s]
2024-12-05 17:29:27,356 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_standard_quotation [status:200 duration:0.005s]
2024-12-05 17:29:27,357 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_standard_quotation' already exists. Skipping creation.
2024-12-05 17:29:27,357 - __main__ - INFO - ElasticsearchBM25 instance created with index 'contextual_bm25_index_standard_quotation'.
2024-12-05 17:29:27,382 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.025s]
2024-12-05 17:29:27,403 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_refresh [status:200 duration:0.020s]
2024-12-05 17:29:27,403 - src.core.elasticsearch_bm25 - INFO - Indexed 3/3 documents successfully
2024-12-05 17:29:27,403 - __main__ - INFO - Elasticsearch BM25 index 'contextual_bm25_index_standard_quotation' created successfully with 3 documents indexed.
2024-12-05 17:29:27,403 - __main__ - INFO - Loading standard queries from 'data/input/quotation/queries.json'
2024-12-05 17:29:27,403 - src.data.data_loader - ERROR - Error loading JSON file 'data/input/quotation/queries.json': File does not exist.
2024-12-05 17:29:27,403 - __main__ - ERROR - No standard queries found to process.
2024-12-05 17:29:27,403 - __main__ - INFO - Validating standard queries
2024-12-05 17:29:27,405 - src.processing.query_processor - INFO - Validated 0 transcripts out of 0 provided.
2024-12-05 17:29:27,405 - __main__ - INFO - Initializing quotation selection optimizer
2024-12-05 17:29:28,007 - __main__ - ERROR - Unexpected error in run_pipeline_with_config: Unable to find '/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/data/training_data/quotation/quotation_training_data.csv'
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 264, in run_pipeline_with_config
    await optimizer_init_func(config)
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 103, in initialize_quotation_optimizer
    quotation_train_dataset = dl.from_csv(
                              ^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/datasets/dataloader.py", line 62, in from_csv
    dataset = load_dataset("csv", data_files=file_path)["train"]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 1562, in dataset_module_factory
    ).get_module()
      ^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 942, in get_module
    data_files = DataFilesDict.from_patterns(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 721, in from_patterns
    else DataFilesList.from_patterns(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 624, in from_patterns
    resolve_pattern(
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 411, in resolve_pattern
    raise FileNotFoundError(error_msg)
FileNotFoundError: Unable to find '/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/data/training_data/quotation/quotation_training_data.csv'
2024-12-05 17:29:28,010 - __main__ - INFO - Converting data: Quotation to Keyword Conversion (Standard)
2024-12-05 17:29:28,011 - __main__ - INFO - Conversion successful: Quotation to Keyword Conversion (Standard)
2024-12-05 17:29:28,011 - __main__ - INFO - Starting Keyword Extraction Pipeline for Standard Quotation
2024-12-05 17:29:28,011 - __main__ - INFO - Configuring DSPy Language Model
2024-12-05 17:29:28,011 - __main__ - INFO - Loading codebase chunks from 'data/codebase_chunks/keyword/codebase_chunks_keyword.json'
2024-12-05 17:29:28,011 - src.data.data_loader - ERROR - Error loading JSON file 'data/codebase_chunks/keyword/codebase_chunks_keyword.json': File does not exist.
2024-12-05 17:29:28,011 - __main__ - INFO - Initializing ContextualVectorDB
2024-12-05 17:29:28,021 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-05 17:29:28,021 - src.core.contextual_vector_db - INFO - Loading vector database and FAISS index from disk.
2024-12-05 17:29:28,022 - src.core.contextual_vector_db - INFO - Vector database metadata loaded from './data/contextual_db/contextual_vector_db.pkl' with 3 entries.
2024-12-05 17:29:28,022 - src.core.contextual_vector_db - INFO - Chunks loaded: ['interview_001_chunk_0', 'interview_001_chunk_1', 'interview_001_chunk_2']
2024-12-05 17:29:28,022 - src.core.contextual_vector_db - INFO - FAISS index loaded from './data/contextual_db/faiss_index.bin' with 3 vectors.
2024-12-05 17:29:28,022 - __main__ - INFO - Creating Elasticsearch BM25 index 'contextual_bm25_index_keyword_extraction'
2024-12-05 17:29:28,027 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.004s]
2024-12-05 17:29:28,029 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_keyword_extraction [status:200 duration:0.002s]
2024-12-05 17:29:28,029 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_keyword_extraction' already exists. Skipping creation.
2024-12-05 17:29:28,029 - __main__ - INFO - ElasticsearchBM25 instance created with index 'contextual_bm25_index_keyword_extraction'.
2024-12-05 17:29:28,046 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.017s]
2024-12-05 17:29:28,058 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_refresh [status:200 duration:0.011s]
2024-12-05 17:29:28,058 - src.core.elasticsearch_bm25 - INFO - Indexed 3/3 documents successfully
2024-12-05 17:29:28,058 - __main__ - INFO - Elasticsearch BM25 index 'contextual_bm25_index_keyword_extraction' created successfully with 3 documents indexed.
2024-12-05 17:29:28,058 - __main__ - INFO - Loading standard queries from 'data/input/keyword/queries_keyword_standard.json'
2024-12-05 17:29:28,058 - src.data.data_loader - ERROR - Error loading JSON file 'data/input/keyword/queries_keyword_standard.json': File does not exist.
2024-12-05 17:29:28,058 - __main__ - ERROR - No standard queries found to process.
2024-12-05 17:29:28,058 - __main__ - INFO - Validating standard queries
2024-12-05 17:29:28,060 - src.processing.query_processor - INFO - Validated 0 transcripts out of 0 provided.
2024-12-05 17:29:28,060 - __main__ - INFO - Initializing keyword extraction optimizer
2024-12-05 17:29:28,234 - __main__ - ERROR - Unexpected error in run_pipeline_with_config: Unable to find '/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/data/training_data/keyword/keyword_training_data.csv'
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 264, in run_pipeline_with_config
    await optimizer_init_func(config)
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 138, in initialize_keyword_optimizer
    keyword_train_dataset = dl.from_csv(
                            ^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/datasets/dataloader.py", line 62, in from_csv
    dataset = load_dataset("csv", data_files=file_path)["train"]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 1562, in dataset_module_factory
    ).get_module()
      ^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 942, in get_module
    data_files = DataFilesDict.from_patterns(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 721, in from_patterns
    else DataFilesList.from_patterns(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 624, in from_patterns
    resolve_pattern(
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 411, in resolve_pattern
    raise FileNotFoundError(error_msg)
FileNotFoundError: Unable to find '/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/data/training_data/keyword/keyword_training_data.csv'
2024-12-05 17:29:28,235 - __main__ - INFO - Converting data: Keyword to Coding Conversion (Standard)
2024-12-05 17:29:28,235 - __main__ - INFO - Conversion successful: Keyword to Coding Conversion (Standard)
2024-12-05 17:29:28,235 - __main__ - INFO - Starting Coding Analysis Pipeline for Standard Keyword Extraction
2024-12-05 17:29:28,235 - __main__ - INFO - Configuring DSPy Language Model
2024-12-05 17:29:28,235 - __main__ - INFO - Loading codebase chunks from 'data/codebase_chunks/coding/codebase_chunks_coding.json'
2024-12-05 17:29:28,236 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/coding/codebase_chunks_coding.json' successfully with 1 entries.
2024-12-05 17:29:28,236 - __main__ - INFO - Initializing ContextualVectorDB
2024-12-05 17:29:28,242 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-05 17:29:28,242 - src.core.contextual_vector_db - INFO - Loading vector database and FAISS index from disk.
2024-12-05 17:29:28,242 - src.core.contextual_vector_db - INFO - Vector database metadata loaded from './data/contextual_db/contextual_vector_db.pkl' with 3 entries.
2024-12-05 17:29:28,242 - src.core.contextual_vector_db - INFO - Chunks loaded: ['interview_001_chunk_0', 'interview_001_chunk_1', 'interview_001_chunk_2']
2024-12-05 17:29:28,242 - src.core.contextual_vector_db - INFO - FAISS index loaded from './data/contextual_db/faiss_index.bin' with 3 vectors.
2024-12-05 17:29:28,242 - __main__ - INFO - Creating Elasticsearch BM25 index 'contextual_bm25_index_coding_analysis'
2024-12-05 17:29:28,245 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.003s]
2024-12-05 17:29:28,253 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_coding_analysis [status:200 duration:0.008s]
2024-12-05 17:29:28,253 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_coding_analysis' already exists. Skipping creation.
2024-12-05 17:29:28,253 - __main__ - INFO - ElasticsearchBM25 instance created with index 'contextual_bm25_index_coding_analysis'.
2024-12-05 17:29:28,271 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.017s]
2024-12-05 17:29:28,288 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_refresh [status:200 duration:0.017s]
2024-12-05 17:29:28,288 - src.core.elasticsearch_bm25 - INFO - Indexed 3/3 documents successfully
2024-12-05 17:29:28,288 - __main__ - INFO - Elasticsearch BM25 index 'contextual_bm25_index_coding_analysis' created successfully with 3 documents indexed.
2024-12-05 17:29:28,288 - __main__ - INFO - Loading standard queries from 'data/input/coding/queries_coding_standard.json'
2024-12-05 17:29:28,288 - src.data.data_loader - ERROR - Error loading JSON file 'data/input/coding/queries_coding_standard.json': File does not exist.
2024-12-05 17:29:28,288 - __main__ - ERROR - No standard queries found to process.
2024-12-05 17:29:28,288 - __main__ - INFO - Validating standard queries
2024-12-05 17:29:28,289 - src.processing.query_processor - INFO - Validated 0 transcripts out of 0 provided.
2024-12-05 17:29:28,289 - __main__ - INFO - Initializing coding analysis optimizer
2024-12-05 17:29:28,459 - __main__ - ERROR - Unexpected error in run_pipeline_with_config: Unable to find '/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/data/training_data/coding/coding_training_data.csv'
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 264, in run_pipeline_with_config
    await optimizer_init_func(config)
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/main.py", line 173, in initialize_coding_optimizer
    coding_train_dataset = dl.from_csv(
                           ^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/datasets/dataloader.py", line 62, in from_csv
    dataset = load_dataset("csv", data_files=file_path)["train"]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 1562, in dataset_module_factory
    ).get_module()
      ^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/load.py", line 942, in get_module
    data_files = DataFilesDict.from_patterns(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 721, in from_patterns
    else DataFilesList.from_patterns(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 624, in from_patterns
    resolve_pattern(
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/datasets/data_files.py", line 411, in resolve_pattern
    raise FileNotFoundError(error_msg)
FileNotFoundError: Unable to find '/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/data/training_data/coding/coding_training_data.csv'
2024-12-05 17:29:28,460 - __main__ - INFO - Converting data: Coding to Theme Conversion (Standard)
2024-12-05 17:29:28,461 - __main__ - INFO - Conversion successful: Coding to Theme Conversion (Standard)
2024-12-05 17:29:28,461 - __main__ - INFO - All pipelines and conversion steps executed successfully up to Coding Analysis.
