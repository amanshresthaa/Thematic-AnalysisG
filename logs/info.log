2024-12-10 21:59:45,581 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:45,830 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:45,843 - root - WARNING - 	*** Since DSPy 2.5.16+, TypedPredictors are now deprecated, underperform, and are about to be removed! ***
Please use standard predictors, e.g. dspy.Predict and dspy.ChainOfThought.
They now support type annotations and other features of TypedPredictors and tend to work much better out of the box.
Please let us know if you face any issues: https://github.com/stanfordnlp/dspy/issues
2024-12-10 21:59:45,843 - src.analysis.metrics - INFO - Comprehensive Assessment DSPy module initialized successfully.
2024-12-10 21:59:45,848 - src.processing.answer_generator - INFO - Unoptimized DSPy module initialized successfully.
2024-12-10 21:59:45,905 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:48,881 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:48,902 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:48,906 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:48,912 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 21:59:48,912 - __main__ - INFO - Launching Thematic Analysis Pipeline
2024-12-10 21:59:48,912 - __main__ - INFO - Initializing ThematicAnalysisPipeline
2024-12-10 21:59:48,920 - __main__ - INFO - ThematicAnalysisPipeline instance created with ContextualVectorDB initialized
2024-12-10 21:59:48,920 - __main__ - INFO - Starting Thematic Analysis Pipeline
2024-12-10 21:59:48,920 - __main__ - INFO - Starting Standard Quotation Extraction Pipeline
2024-12-10 21:59:48,920 - __main__ - INFO - Starting pipeline with EnhancedQuotationModule
2024-12-10 21:59:48,920 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 21:59:48,921 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 21:59:48,922 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 21:59:48,922 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 21:59:48,922 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 21:59:48,922 - src.core.contextual_vector_db - INFO - Total chunks to process: 5.
2024-12-10 21:59:48,922 - src.core.contextual_vector_db - INFO - Processing 5 chunks with 4 threads.
2024-12-10 21:59:48,948 - src.core.contextual_vector_db - INFO - Starting embedding generation.
2024-12-10 21:59:50,072 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 21:59:50,221 - src.core.contextual_vector_db - INFO - Vector database metadata saved to './data/contextual_db/contextual_vector_db.pkl'.
2024-12-10 21:59:50,221 - src.core.contextual_vector_db - INFO - Embedding dimension: 1536.
2024-12-10 21:59:50,222 - src.core.contextual_vector_db - INFO - FAISS index created with 5 vectors.
2024-12-10 21:59:50,223 - src.core.contextual_vector_db - INFO - FAISS index saved to './data/contextual_db/faiss_index.bin'.
2024-12-10 21:59:50,223 - src.core.contextual_vector_db - INFO - FAISS index built and saved in 0.00 seconds.
2024-12-10 21:59:50,223 - src.core.contextual_vector_db - INFO - Embedding generation completed. Total embeddings: 5.
2024-12-10 21:59:50,223 - src.core.contextual_vector_db - INFO - Vector database metadata saved to './data/contextual_db/contextual_vector_db.pkl'.
2024-12-10 21:59:50,223 - src.core.contextual_vector_db - INFO - Embedding dimension: 1536.
2024-12-10 21:59:50,224 - src.core.contextual_vector_db - INFO - FAISS index created with 5 vectors.
2024-12-10 21:59:50,224 - src.core.contextual_vector_db - INFO - FAISS index saved to './data/contextual_db/faiss_index.bin'.
2024-12-10 21:59:50,224 - src.core.contextual_vector_db - INFO - FAISS index built and saved in 0.00 seconds.
2024-12-10 21:59:50,224 - src.core.contextual_vector_db - INFO - Contextual Vector database loaded and saved. Total chunks processed: 5.
2024-12-10 21:59:50,224 - __main__ - INFO - Loaded data into ContextualVectorDB in 1.30s
2024-12-10 21:59:50,224 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_standard_quotation
2024-12-10 21:59:50,224 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_standard_quotation
2024-12-10 21:59:50,231 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.006s]
2024-12-10 21:59:50,235 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_standard_quotation [status:200 duration:0.004s]
2024-12-10 21:59:50,235 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_standard_quotation' already exists. Skipping creation.
2024-12-10 21:59:50,325 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.089s]
2024-12-10 21:59:50,349 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_refresh [status:200 duration:0.024s]
2024-12-10 21:59:50,349 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 21:59:50,349 - __main__ - INFO - Successfully indexed 5 documents in 0.11s
2024-12-10 21:59:50,349 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.13s
2024-12-10 21:59:50,349 - __main__ - INFO - Created Elasticsearch BM25 index in 0.13s
2024-12-10 21:59:50,349 - __main__ - INFO - Loading queries from data/input/queries_quotation.json
2024-12-10 21:59:50,350 - src.data.data_loader - INFO - Loaded JSON file 'data/input/queries_quotation.json' successfully with 11 entries.
2024-12-10 21:59:50,350 - __main__ - INFO - Loaded 11 queries
2024-12-10 21:59:50,350 - __main__ - INFO - Validating queries
2024-12-10 21:59:50,351 - src.processing.query_processor - INFO - Validated 11 transcripts out of 11 provided.
2024-12-10 21:59:50,351 - __main__ - INFO - Validated 11 queries
2024-12-10 21:59:50,351 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 21:59:50,351 - __main__ - INFO - Initializing optimizer for EnhancedQuotationModule
2024-12-10 21:59:50,351 - __main__ - INFO - Initializing quotation selection optimizer
2024-12-10 21:59:50,977 - __main__ - INFO - Loaded quotation training dataset: 1 samples
2024-12-10 21:59:50,987 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:50,997 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,005 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,012 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,019 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,025 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,031 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,037 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,044 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,050 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,056 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,062 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,069 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,075 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,082 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,089 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,095 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,101 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,108 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,114 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,121 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,126 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,133 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,139 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 21:59:51,140 - __main__ - INFO - Compiled optimized quotation program in 0.16s
2024-12-10 21:59:51,140 - __main__ - INFO - Saved optimized quotation program to data/optimized/optimized_quotation_program.json
2024-12-10 21:59:51,140 - __main__ - INFO - Quotation optimizer initialization completed in 0.79s
2024-12-10 21:59:51,140 - __main__ - INFO - Initialized optimizer in 0.79s
2024-12-10 21:59:51,140 - __main__ - INFO - Initializing EnhancedQuotationModule
2024-12-10 21:59:51,148 - __main__ - INFO - Initialized EnhancedQuotationModule with assertions
2024-12-10 21:59:51,148 - __main__ - INFO - Processing queries with k=20
2024-12-10 21:59:51,149 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_quotation.json'.
2024-12-10 21:59:51,149 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 21:59:51,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 21:59:51,770 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations
***
and I encourage people to be aligned with that ready to go [Music] hello everyone welcome to open AI Dev day
***
I am Harry stebbings of 20 VC and I am very very excited to interview
***
Sam ultman welcome Sam Sam thank you for letting me do this today with you thanks for doing now we have many many questions from the audience
***
and so I wanted to start with one when we look forward is the future of open AI more models like A1 or is it more larger models that we would maybe have expected of old how do we think about that
***
I mean we want to make things better across the board but this direction of reasoning models is of particular importance to us
***
I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do and the the ability for models like this is to for example contribute to new science uh help write a lot more very difficult code uh that I think can drive things forward to a significant degree
***
so you should expect rapid Improvement in the O Series of models and it's of great strategic importance to us another one that I thought was really important for us to touch on was when we look forward to open ai's future plans how do you think about developing no code tools for non-technical Founders to build and scale AI apps how do you think about that it'll get there for sure uh I I think the the first step will be tools that make people who know how to code well more productive
***
but eventually I think we can offer really high quality no code tools and already there's some out there that makes sense
***
but you can't you can't sort of in a no code way say I have like a full startup I want to build um that's going to take a while
***
so when we look at where we are in the stack today open AI sits in a certain place how far up the stack is open AI going go
***
I think it's a brilliant question but if you're spending a lot of time tuning your rag system is this a waste of time because open AI ultimately thinks I'll own this part of the application layer or is it not and how do you answer a Founder who has that question the general answer we try to give is we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future if on the other hand you build a company that benefits from the model getting better and better if you know an oracle told you today that 04 was going to be just absolutely incredible and do all of these things that right now feel impossible and you were happy about that
***
then you know maybe we're wrong but at least that's what we're going for and if instead you say okay there's this area where there are many but you pick one of the many areas where 01 preview underperforms and say I'm going to patch this and just barely get it to work then you're sort of assuming that the next turn of the model crank won't be as good as we think it will be and that is the general philosophical message we try to get out to startups like we we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today um will just be taken care of by Future generations
***
and you know I encourage people to be aligned with that we did an interview before with Brad and sorry it's not quite on schedule
***
but I think the show has always been successful when we kind of go a little bit off schedule there was this brilliant'.
2024-12-10 21:59:51,845 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.075s]
2024-12-10 21:59:51,885 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.028s]
2024-12-10 21:59:51,886 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 21:59:51,886 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 21:59:51,887 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 21:59:51,887 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 21:59:51,887 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 21:59:51,887 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations
***
and I encourage people to be aligned with that ready to go [Music] hello everyone welcome to open AI Dev day
***
I am Harry stebbings of 20 VC and I am very very excited to interview
***
Sam ultman welcome Sam Sam thank you for letting me do this today with you thanks for doing now we have many many questions from the audience
***
and so I wanted to start with one when we look forward is the future of open AI more models like A1 or is it more larger models that we would maybe have expected of old how do we think about that
***
I mean we want to make things better across the board but this direction of reasoning models is of particular importance to us
***
I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do and the the ability for models like this is to for example contribute to new science uh help write a lot more very difficult code uh that I think can drive things forward to a significant degree
***
so you should expect rapid Improvement in the O Series of models and it's of great strategic importance to us another one that I thought was really important for us to touch on was when we look forward to open ai's future plans how do you think about developing no code tools for non-technical Founders to build and scale AI apps how do you think about that it'll get there for sure uh I I think the the first step will be tools that make people who know how to code well more productive
***
but eventually I think we can offer really high quality no code tools and already there's some out there that makes sense
***
but you can't you can't sort of in a no code way say I have like a full startup I want to build um that's going to take a while
***
so when we look at where we are in the stack today open AI sits in a certain place how far up the stack is open AI going go
***
I think it's a brilliant question but if you're spending a lot of time tuning your rag system is this a waste of time because open AI ultimately thinks I'll own this part of the application layer or is it not and how do you answer a Founder who has that question the general answer we try to give is we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future if on the other hand you build a company that benefits from the model getting better and better if you know an oracle told you today that 04 was going to be just absolutely incredible and do all of these things that right now feel impossible and you were happy about that
***
then you know maybe we're wrong but at least that's what we're going for and if instead you say okay there's this area where there are many but you pick one of the many areas where 01 preview underperforms and say I'm going to patch this and just barely get it to work then you're sort of assuming that the next turn of the model crank won't be as good as we think it will be and that is the general philosophical message we try to get out to startups like we we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today um will just be taken care of by Future generations
***
and you know I encourage people to be aligned with that we did an interview before with Brad and sorry it's not quite on schedule
***
but I think the show has always been successful when we kind of go a little bit off schedule there was this brilliant': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 21:59:51,888 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.74s
2024-12-10 21:59:51,901 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 21:59:51,902 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 21:59:53,194 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 21:59:53,202 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.30s. Top score: 1.0000, Bottom score: 0.9758
2024-12-10 21:59:53,202 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.05s. Returned 5 results
2024-12-10 21:59:53,203 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: we are going to try our hardest and believe we will succeed at making our models better and better a...
2024-12-10 21:59:53,232 - src.processing.query_processor - INFO - Selected 2 quotations for transcript chunk.
2024-12-10 21:59:53,233 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I f...'
2024-12-10 21:59:53,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 21:59:53,547 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I felt a little bit guilty
***
but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and
***
so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever
***
and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do
***
so it's it no longer seems to be such an issue
***
but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people
***
you you said about the trillions of dollars of value to be created that
***
and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one um
***
but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take'.
2024-12-10 21:59:53,610 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.061s]
2024-12-10 21:59:53,652 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.029s]
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 21:59:53,653 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 21:59:53,653 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 21:59:53,653 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 21:59:53,653 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I felt a little bit guilty
***
but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and
***
so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever
***
and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do
***
so it's it no longer seems to be such an issue
***
but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people
***
you you said about the trillions of dollars of value to be created that
***
and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one um
***
but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 21:59:53,654 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.42s
2024-12-10 21:59:53,667 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 21:59:53,667 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I f...' with 5 documents
2024-12-10 21:59:54,525 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 21:59:54,527 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 0.9999, Bottom score: 0.0192
2024-12-10 21:59:54,527 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.29s. Returned 5 results
2024-12-10 21:59:54,527 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I f...
2024-12-10 21:59:54,557 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 21:59:54,557 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 21:59:54,863 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 21:59:54,879 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful
***
and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out
***
but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis
***
and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered
***
but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong
***
well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant
***
okay sure that's that's like a mild Le annoying thing to have to do
***
and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task'.
2024-12-10 21:59:54,944 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.063s]
2024-12-10 21:59:54,987 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.027s]
2024-12-10 21:59:54,987 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 21:59:54,988 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 21:59:54,988 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 21:59:54,988 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 21:59:54,988 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful
***
and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out
***
but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis
***
and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered
***
but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong
***
well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant
***
okay sure that's that's like a mild Le annoying thing to have to do
***
and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 21:59:54,989 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.43s
2024-12-10 21:59:55,000 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 21:59:55,000 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 21:59:55,843 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 21:59:55,846 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 21:59:55,846 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.29s. Returned 5 results
2024-12-10 21:59:55,846 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
but if we use that as an example and imagine forward to towards it think about what think about ...
2024-12-10 21:59:55,888 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 21:59:55,888 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
really well and you know ping you at when it has questions but come back to you with like a grea...'
2024-12-10 21:59:56,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 21:59:56,165 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun
***
but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure
***
but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it
***
it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one
***
but the actual like Revenue we can make from a model I think justifies the investment to be fair
***
uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable
***
then
***
yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality
***
spe
***
yeah
***
I hope it's just going to work
***
I mean it obviously takes some doing to get done
***
but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it'.
2024-12-10 21:59:56,228 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.061s]
2024-12-10 21:59:56,266 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.025s]
2024-12-10 21:59:56,267 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 21:59:56,267 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 21:59:56,267 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 21:59:56,267 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 21:59:56,267 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 21:59:56,268 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 21:59:56,268 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 21:59:56,268 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 21:59:56,268 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 21:59:56,268 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 21:59:56,268 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 21:59:56,268 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun
***
but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure
***
but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it
***
it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one
***
but the actual like Revenue we can make from a model I think justifies the investment to be fair
***
uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable
***
then
***
yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality
***
spe
***
yeah
***
I hope it's just going to work
***
I mean it obviously takes some doing to get done
***
but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 21:59:56,269 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.38s
2024-12-10 21:59:56,279 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 21:59:56,280 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
really well and you know ping you at when it has questions but come back to you with like a grea...' with 5 documents
2024-12-10 21:59:58,085 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 21:59:58,086 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.81s. Top score: 1.0000, Bottom score: 0.0004
2024-12-10 21:59:58,087 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.20s. Returned 5 results
2024-12-10 21:59:58,087 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
really well and you know ping you at when it has questions but come back to you with like a grea...
2024-12-10 21:59:58,115 - src.processing.query_processor - INFO - Selected 2 quotations for transcript chunk.
2024-12-10 21:59:58,115 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 21:59:58,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 21:59:58,534 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible
***
and so after after a research does something even if you don't know exactly how they did it
***
it's I say easy
***
but it's doable to go off and copy it
***
and you can see this in the replications of gp4
***
and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations
***
not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building
***
so I'd love way more of that and that is I think the thing most special about us
***
Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that
***
but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid'.
2024-12-10 21:59:58,598 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.062s]
2024-12-10 21:59:58,636 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.025s]
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 21:59:58,637 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 21:59:58,637 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 21:59:58,637 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 21:59:58,637 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible
***
and so after after a research does something even if you don't know exactly how they did it
***
it's I say easy
***
but it's doable to go off and copy it
***
and you can see this in the replications of gp4
***
and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations
***
not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building
***
so I'd love way more of that and that is I think the thing most special about us
***
Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that
***
but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 21:59:58,638 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.52s
2024-12-10 21:59:58,646 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 21:59:58,646 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 21:59:59,568 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 21:59:59,570 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.92s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 21:59:59,570 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.46s. Returned 5 results
2024-12-10 21:59:59,570 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
and then you know there's everyone's favorite question which is what comes beyond the Transforme...
2024-12-10 21:59:59,612 - src.processing.query_processor - INFO - Selected 4 quotations for transcript chunk.
2024-12-10 21:59:59,612 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:00:00,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:00,064 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate
***
so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this
***
but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway
***
and if so I'll deal with it later um Keith R boy uh did a talk
***
and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts
***
so you know I wasn't that young seem to work
***
okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced
***
I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young
***
but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort
***
then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both
***
uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like
***
***'.
2024-12-10 22:00:00,132 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.066s]
2024-12-10 22:00:00,171 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.028s]
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:00,172 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:00,172 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:00:00,172 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:00,172 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate
***
so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this
***
but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway
***
and if so I'll deal with it later um Keith R boy uh did a talk
***
and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts
***
so you know I wasn't that young seem to work
***
okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced
***
I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young
***
but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort
***
then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both
***
uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like
***
***': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:00,173 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.56s
2024-12-10 22:00:00,184 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:00,184 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:00:01,089 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:01,092 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.91s. Top score: 1.0000, Bottom score: 0.0086
2024-12-10 22:00:01,092 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.48s. Returned 5 results
2024-12-10 22:00:01,093 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...
2024-12-10 22:00:01,124 - src.processing.query_processor - INFO - Selected 5 quotations for transcript chunk.
2024-12-10 22:00:01,125 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...'
2024-12-10 22:00:01,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:01,500 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is and one of the things that I feel most grateful about why combinator 4 is inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value and uh we as a society should bet on those people and it's a great thing I am going to return to some semblance of the schedule is I'm I'm really going to get told off but anthropics models have been sometimes cited as being better for coding Tas why is that do you think that's fair and how should developers think about when to pick open AI versus a different provider
***
yeah they have a model that is great at coding for sure uh
***'.
2024-12-10 22:00:01,531 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.030s]
2024-12-10 22:00:01,548 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.007s]
2024-12-10 22:00:01,549 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:01,549 - src.retrieval.retrieval - INFO - Filtered 1 chunks due to missing metadata.
2024-12-10 22:00:01,549 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:01,549 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'somehow just not it's not quite the framing that resonates with me but the part of it that does is and one of the things that I feel most grateful about why combinator 4 is inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value and uh we as a society should bet on those people and it's a great thing I am going to return to some semblance of the schedule is I'm I'm really going to get told off but anthropics models have been sometimes cited as being better for coding Tas why is that do you think that's fair and how should developers think about when to pick open AI versus a different provider
***
yeah they have a model that is great at coding for sure uh
***': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:01,549 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.42s
2024-12-10 22:00:01,556 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:01,556 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...' with 5 documents
2024-12-10 22:00:02,727 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:02,730 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.17s. Top score: 0.9999, Bottom score: 0.0031
2024-12-10 22:00:02,731 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.61s. Returned 5 results
2024-12-10 22:00:02,731 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: somehow just not it's not quite the framing that resonates with me but the part of it that does is a...
2024-12-10 22:00:02,760 - src.processing.query_processor - INFO - Selected 1 quotations for transcript chunk.
2024-12-10 22:00:02,761 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:00:03,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:03,109 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um
***
but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long
***
and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out
***
but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time
***
but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing
***
and no one expects that to be easy and a straight line to success
***
but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side
***
you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us
***
can I ask a really weird one I had a great quote the other day
***
and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one
***
I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long
***
but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place
***
and then I don't feel like particularly likely
***
I can do better than somebody else would have done but I kind of have to make them
***
anyway
***
and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149'.
2024-12-10 22:00:03,170 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.058s]
2024-12-10 22:00:03,210 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.025s]
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:03,211 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:03,212 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:03,212 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:03,212 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:03,212 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um
***
but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long
***
and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out
***
but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time
***
but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing
***
and no one expects that to be easy and a straight line to success
***
but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side
***
you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us
***
can I ask a really weird one I had a great quote the other day
***
and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one
***
I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long
***
but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place
***
and then I don't feel like particularly likely
***
I can do better than somebody else would have done but I kind of have to make them
***
anyway
***
and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:03,213 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.45s
2024-12-10 22:00:03,222 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:03,222 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:00:04,074 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:04,077 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:00:04,077 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.32s. Returned 5 results
2024-12-10 22:00:04,077 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm n...
2024-12-10 22:00:04,109 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:00:04,109 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:00:04,664 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:04,675 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's
***
well
***
I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine
***
but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team
***
um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline
***
but
***
but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance
***
and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that
***
but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a
***
I think that's a bad habit on the whole and but I understand why people do it and B
***
I think the ones people pick for analogize into AI are particularly bad
***
so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models
***
and you get to use them to build all sorts of great stuff
***
and it's like a new primitive for Building Technology'.
2024-12-10 22:00:04,727 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.051s]
2024-12-10 22:00:04,759 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.021s]
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:04,760 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:04,760 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:04,760 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:04,760 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's
***
well
***
I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine
***
but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team
***
um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline
***
but
***
but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance
***
and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that
***
but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a
***
I think that's a bad habit on the whole and but I understand why people do it and B
***
I think the ones people pick for analogize into AI are particularly bad
***
so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models
***
and you get to use them to build all sorts of great stuff
***
and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:04,761 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.65s
2024-12-10 22:00:04,772 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:04,772 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:00:05,595 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:05,597 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.82s. Top score: 0.9998, Bottom score: 0.0269
2024-12-10 22:00:05,597 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.49s. Returned 5 results
2024-12-10 22:00:05,597 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
no um I think the wrong way to do that is to have one person you lean on for everything and the ...
2024-12-10 22:00:05,626 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:00:05,626 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
but if you're trying to build the AI itself that's pretty different another example people uses ...'
2024-12-10 22:00:06,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:06,032 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it
***
and you don't say oh this is a transistor product it's just like
***
oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you
***
so I'm going to say so I'm going to say a short statement you give me your immediate thoughts
***
okay
***
okay
***
so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical
***
I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential
***
so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month
***
Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them
***
I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge
***
it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome
***
but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI
***
but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together
***
I think that's it's really quite remarkable
***
and I specifically left anybody at open a eye out as I was thinking through it'.
2024-12-10 22:00:06,105 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.072s]
2024-12-10 22:00:06,150 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.031s]
2024-12-10 22:00:06,151 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:06,151 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:06,151 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:06,151 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:06,151 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:06,151 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:06,152 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:06,152 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:06,152 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:06,152 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:06,152 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:06,152 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it
***
and you don't say oh this is a transistor product it's just like
***
oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you
***
so I'm going to say so I'm going to say a short statement you give me your immediate thoughts
***
okay
***
okay
***
so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical
***
I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential
***
so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month
***
Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them
***
I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge
***
it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome
***
but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI
***
but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together
***
I think that's it's really quite remarkable
***
and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:06,153 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.53s
2024-12-10 22:00:06,165 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:06,165 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
but if you're trying to build the AI itself that's pretty different another example people uses ...' with 5 documents
2024-12-10 22:00:07,034 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:07,036 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.87s. Top score: 1.0000, Bottom score: 0.0869
2024-12-10 22:00:07,036 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.41s. Returned 5 results
2024-12-10 22:00:07,036 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
but if you're trying to build the AI itself that's pretty different another example people uses ...
2024-12-10 22:00:07,074 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:00:07,075 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:00:07,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:07,435 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***
otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now
***
and I'm not even going that quick
***
but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you
***
but if you were like hey Sam
***
I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable
***
can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general
***
um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team
***
but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement
***
actually I I will just say it
***
I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no
***
and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing
***
I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and
***
Sam thank you for making it happened man' thank you all'.
2024-12-10 22:00:07,491 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.055s]
2024-12-10 22:00:07,546 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.049s]
2024-12-10 22:00:07,546 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:07,546 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:07,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:07,547 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:07,547 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:07,547 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now
***
and I'm not even going that quick
***
but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you
***
but if you were like hey Sam
***
I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable
***
can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general
***
um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team
***
but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement
***
actually I I will just say it
***
I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no
***
and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing
***
I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and
***
Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:07,547 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.47s
2024-12-10 22:00:07,554 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:07,554 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:00:08,399 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:08,402 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:00:08,402 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.33s. Returned 5 results
2024-12-10 22:00:08,402 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
otherwise it would have been a long list of open a eye people first how do you think about the t...
2024-12-10 22:00:08,438 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:00:08,442 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_quotation.json'
2024-12-10 22:00:08,442 - __main__ - INFO - Processed queries in 17.29s
2024-12-10 22:00:08,442 - __main__ - INFO - Starting evaluation
2024-12-10 22:00:08,443 - src.data.data_loader - INFO - Loaded JSONL file 'data/evaluation/evaluation_set_quotation.jsonl' with 3 entries successfully.
2024-12-10 22:00:08,443 - __main__ - INFO - Loaded 3 evaluation queries
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:00:08,443 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:00:08,443 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:00:08,443 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:00:08,443 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:00:08,444 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:08,445 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:00:08,445 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:00:08,445 - __main__ - INFO - Pipeline for EnhancedQuotationModule completed in 19.52s
2024-12-10 22:00:08,445 - __main__ - INFO - Completed Quotation Extraction in 19.52s
2024-12-10 22:00:08,445 - __main__ - INFO - Converting quotation results to keyword format
2024-12-10 22:00:08,447 - __main__ - INFO - Quotation to keyword conversion completed
2024-12-10 22:00:08,447 - __main__ - INFO - Starting Keyword Extraction Pipeline
2024-12-10 22:00:08,448 - __main__ - INFO - Starting pipeline with KeywordExtractionModule
2024-12-10 22:00:08,448 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:00:08,448 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:00:08,448 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:00:08,448 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:00:08,448 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:00:08,448 - src.core.contextual_vector_db - INFO - Vector database is already loaded. Skipping data loading.
2024-12-10 22:00:08,448 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:00:08,448 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_keyword_extraction
2024-12-10 22:00:08,448 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_keyword_extraction
2024-12-10 22:00:08,456 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.007s]
2024-12-10 22:00:08,458 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_keyword_extraction [status:200 duration:0.002s]
2024-12-10 22:00:08,458 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_keyword_extraction' already exists. Skipping creation.
2024-12-10 22:00:08,476 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.018s]
2024-12-10 22:00:08,495 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_refresh [status:200 duration:0.019s]
2024-12-10 22:00:08,495 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:00:08,495 - __main__ - INFO - Successfully indexed 5 documents in 0.04s
2024-12-10 22:00:08,495 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.05s
2024-12-10 22:00:08,495 - __main__ - INFO - Created Elasticsearch BM25 index in 0.05s
2024-12-10 22:00:08,495 - __main__ - INFO - Loading queries from data/input/queries_keyword_standard.json
2024-12-10 22:00:08,496 - src.data.data_loader - INFO - Loaded JSON file 'data/input/queries_keyword_standard.json' successfully with 32 entries.
2024-12-10 22:00:08,496 - __main__ - INFO - Loaded 32 queries
2024-12-10 22:00:08,496 - __main__ - INFO - Validating queries
2024-12-10 22:00:08,497 - src.processing.query_processor - INFO - Validated 32 transcripts out of 32 provided.
2024-12-10 22:00:08,497 - __main__ - INFO - Validated 32 queries
2024-12-10 22:00:08,497 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:00:08,497 - __main__ - INFO - Initializing optimizer for KeywordExtractionModule
2024-12-10 22:00:08,497 - __main__ - INFO - Initializing keyword extraction optimizer
2024-12-10 22:00:09,077 - __main__ - INFO - Loaded keyword training dataset: 3 samples
2024-12-10 22:00:09,097 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,107 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,117 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,125 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,133 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,140 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,147 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,153 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,159 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,167 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:00:09,175 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,182 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:00:09,189 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,195 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,200 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,207 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,214 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,222 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:00:09,228 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,234 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,241 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,248 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,255 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:00:09,261 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,268 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:00:09,275 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,282 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:00:09,289 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,294 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,300 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,306 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,311 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:00:09,318 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,324 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,331 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,338 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,345 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:00:09,351 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,356 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,362 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,367 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:00:09,374 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,380 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:00:09,386 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,392 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:00:09,397 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,403 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:00:09,409 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,414 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,420 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,427 - src.analysis.metrics - INFO - Comprehensive metric score: 0.34
2024-12-10 22:00:09,434 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,442 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,448 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,454 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,459 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,465 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,471 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:00:09,477 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,482 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:09,488 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,494 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:09,499 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:09,505 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:00:09,506 - __main__ - INFO - Compiled optimized keyword program in 0.43s
2024-12-10 22:00:09,507 - __main__ - INFO - Saved optimized keyword program to data/optimized/optimized_keyword_program.json
2024-12-10 22:00:09,507 - __main__ - INFO - Keyword optimizer initialization completed in 1.01s
2024-12-10 22:00:09,507 - __main__ - INFO - Initialized optimizer in 1.01s
2024-12-10 22:00:09,507 - __main__ - INFO - Initializing KeywordExtractionModule
2024-12-10 22:00:09,514 - __main__ - INFO - Initialized KeywordExtractionModule with assertions
2024-12-10 22:00:09,514 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:00:09,514 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_keyword_extraction.json'.
2024-12-10 22:00:09,514 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:00:09,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:09,829 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations...'.
2024-12-10 22:00:09,866 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.036s]
2024-12-10 22:00:09,888 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.010s]
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:09,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:09,889 - src.retrieval.retrieval - INFO - Filtered 7 chunks due to missing metadata.
2024-12-10 22:00:09,889 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:09,890 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations...': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:09,890 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.38s
2024-12-10 22:00:09,899 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:09,899 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:00:10,704 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:10,708 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.81s. Top score: 1.0000, Bottom score: 0.0005
2024-12-10 22:00:10,708 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.19s. Returned 5 results
2024-12-10 22:00:10,708 - src.processing.query_processor - INFO - Processing quotation for keywords: we are going to try our hardest and believe we will succeed at making our models better and better a...
2024-12-10 22:00:10,737 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:10,737 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:00:11,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:11,040 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations...'.
2024-12-10 22:00:11,076 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.034s]
2024-12-10 22:00:11,099 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.010s]
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:11,101 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:11,101 - src.retrieval.retrieval - INFO - Filtered 7 chunks due to missing metadata.
2024-12-10 22:00:11,101 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:11,101 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations...': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:11,102 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.36s
2024-12-10 22:00:11,111 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:11,111 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:00:11,822 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:11,824 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 1.0000, Bottom score: 0.0005
2024-12-10 22:00:11,824 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.09s. Returned 5 results
2024-12-10 22:00:11,825 - src.processing.query_processor - INFO - Processing quotation for keywords: I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...
2024-12-10 22:00:11,856 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:11,857 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...'
2024-12-10 22:00:12,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:12,150 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take'.
2024-12-10 22:00:12,228 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.075s]
2024-12-10 22:00:12,275 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.033s]
2024-12-10 22:00:12,275 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:12,275 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:12,276 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:12,276 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:12,276 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:12,276 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:00:12,277 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.42s
2024-12-10 22:00:12,289 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:12,289 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...' with 5 documents
2024-12-10 22:00:13,370 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:13,373 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.08s. Top score: 0.9999, Bottom score: 0.0183
2024-12-10 22:00:13,374 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.52s. Returned 5 results
2024-12-10 22:00:13,374 - src.processing.query_processor - INFO - Processing quotation for keywords: there will be many trillions of dollars of market cap that gets created new market cap that gets cre...
2024-12-10 22:00:13,402 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:13,402 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...'
2024-12-10 22:00:13,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:13,673 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take'.
2024-12-10 22:00:13,761 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.086s]
2024-12-10 22:00:13,810 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.037s]
2024-12-10 22:00:13,811 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:13,811 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:13,811 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:13,811 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:13,811 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:13,811 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:13,812 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:13,812 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:13,812 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:13,812 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:13,812 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:13,812 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:13,812 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:00:13,813 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.41s
2024-12-10 22:00:13,820 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:13,820 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...' with 5 documents
2024-12-10 22:00:14,681 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:14,684 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 0.9999, Bottom score: 0.0183
2024-12-10 22:00:14,684 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.28s. Returned 5 results
2024-12-10 22:00:14,684 - src.processing.query_processor - INFO - Processing quotation for keywords: I think people have like internalized the rate of Improvement and have heard us on what we intend to...
2024-12-10 22:00:14,706 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:14,706 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...'
2024-12-10 22:00:15,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:15,050 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take'.
2024-12-10 22:00:15,135 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.083s]
2024-12-10 22:00:15,182 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.029s]
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:15,183 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:15,183 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:15,183 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:15,183 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:00:15,184 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.48s
2024-12-10 22:00:15,196 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:15,196 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...' with 5 documents
2024-12-10 22:00:16,129 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:16,131 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.93s. Top score: 0.9999, Bottom score: 0.0183
2024-12-10 22:00:16,131 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.42s. Returned 5 results
2024-12-10 22:00:16,131 - src.processing.query_processor - INFO - Processing quotation for keywords: there will be9 trillion dollars of value created did every single year which will offset the $9 tril...
2024-12-10 22:00:16,164 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:16,164 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:00:16,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:16,485 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task'.
2024-12-10 22:00:16,572 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.084s]
2024-12-10 22:00:16,622 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.035s]
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:16,623 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:16,624 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:16,624 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:16,624 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:16,624 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:16,624 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:00:16,625 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.46s
2024-12-10 22:00:16,639 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:16,639 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:00:17,492 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:17,492 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:00:17,492 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.33s. Returned 5 results
2024-12-10 22:00:17,492 - src.processing.query_processor - INFO - Processing quotation for keywords: think about how much economic value gets unlocked for the world if anybody can just describe like a ...
2024-12-10 22:00:17,508 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:17,509 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:00:17,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:17,797 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task'.
2024-12-10 22:00:17,877 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.079s]
2024-12-10 22:00:17,931 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.037s]
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:17,932 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:17,933 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:17,933 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:17,933 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:00:17,934 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.43s
2024-12-10 22:00:17,947 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:17,947 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:00:18,897 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:18,900 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.95s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:00:18,900 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.39s. Returned 5 results
2024-12-10 22:00:18,900 - src.processing.query_processor - INFO - Processing quotation for keywords: there's clearly a really important place in the Eos system for open source models...
2024-12-10 22:00:18,932 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:18,932 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:00:19,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:19,448 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task'.
2024-12-10 22:00:19,547 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.098s]
2024-12-10 22:00:19,620 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.055s]
2024-12-10 22:00:19,621 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:19,621 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:19,622 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:19,622 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:19,622 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:19,622 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:00:19,623 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.69s
2024-12-10 22:00:19,637 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:19,637 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:00:20,638 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:20,641 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.00s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:00:20,641 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.71s. Returned 5 results
2024-12-10 22:00:20,642 - src.processing.query_processor - INFO - Processing quotation for keywords: the category I think though is more interesting is not the one that people normally talk about where...
2024-12-10 22:00:20,672 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:20,673 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...'
2024-12-10 22:00:20,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:20,986 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun *** but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure *** but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it *** it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one *** but the actual like Revenue we can make from a model I think justifies the investment to be fair *** uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable *** then *** yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality *** spe *** yeah *** I hope it's just going to work *** I mean it obviously takes some doing to get done *** but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it'.
2024-12-10 22:00:21,076 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.088s]
2024-12-10 22:00:21,130 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.039s]
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:21,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:21,131 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:21,131 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:21,132 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun *** but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure *** but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it *** it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one *** but the actual like Revenue we can make from a model I think justifies the investment to be fair *** uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable *** then *** yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality *** spe *** yeah *** I hope it's just going to work *** I mean it obviously takes some doing to get done *** but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:00:21,133 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.46s
2024-12-10 22:00:21,148 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:21,148 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...' with 5 documents
2024-12-10 22:00:22,018 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:22,020 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.87s. Top score: 1.0000, Bottom score: 0.0004
2024-12-10 22:00:22,020 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.35s. Returned 5 results
2024-12-10 22:00:22,021 - src.processing.query_processor - INFO - Processing quotation for keywords: reasoning is our current most important area of focus I think this is what unlocks the next like mas...
2024-12-10 22:00:22,052 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:22,053 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...'
2024-12-10 22:00:22,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:22,350 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun *** but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure *** but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it *** it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one *** but the actual like Revenue we can make from a model I think justifies the investment to be fair *** uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable *** then *** yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality *** spe *** yeah *** I hope it's just going to work *** I mean it obviously takes some doing to get done *** but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it'.
2024-12-10 22:00:22,439 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.087s]
2024-12-10 22:00:22,499 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.047s]
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:22,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:22,499 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:22,499 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:22,499 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun *** but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure *** but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it *** it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one *** but the actual like Revenue we can make from a model I think justifies the investment to be fair *** uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable *** then *** yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality *** spe *** yeah *** I hope it's just going to work *** I mean it obviously takes some doing to get done *** but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:00:22,500 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.45s
2024-12-10 22:00:22,506 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:22,506 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...' with 5 documents
2024-12-10 22:00:23,366 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:23,367 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0004
2024-12-10 22:00:23,367 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.31s. Returned 5 results
2024-12-10 22:00:23,367 - src.processing.query_processor - INFO - Processing quotation for keywords: the actual like Revenue we can make from a model I think justifies the investment to be fair...
2024-12-10 22:00:23,400 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:23,400 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:00:23,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:23,823 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid'.
2024-12-10 22:00:23,913 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.088s]
2024-12-10 22:00:23,984 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.053s]
2024-12-10 22:00:23,985 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:23,985 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:23,985 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:00:23,986 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:23,986 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:23,986 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:23,986 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:23,987 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.59s
2024-12-10 22:00:24,001 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:24,001 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:00:24,842 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:24,844 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.84s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:00:24,844 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.44s. Returned 5 results
2024-12-10 22:00:24,845 - src.processing.query_processor - INFO - Processing quotation for keywords: what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...
2024-12-10 22:00:24,876 - src.processing.query_processor - INFO - Extracted 5 keywords for quotation.
2024-12-10 22:00:24,876 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:00:25,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:25,144 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid'.
2024-12-10 22:00:25,263 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.118s]
2024-12-10 22:00:25,320 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.043s]
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:00:25,321 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:25,322 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:25,322 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:25,322 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:25,323 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.45s
2024-12-10 22:00:25,332 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:25,333 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:00:26,191 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:26,194 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:00:26,194 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.32s. Returned 5 results
2024-12-10 22:00:26,194 - src.processing.query_processor - INFO - Processing quotation for keywords: the repeated ability to go off and do something new and totally unproven...
2024-12-10 22:00:26,226 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:26,226 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:00:26,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:26,614 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid'.
2024-12-10 22:00:26,692 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.075s]
2024-12-10 22:00:26,739 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.033s]
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:00:26,741 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:26,742 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:26,742 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:26,742 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:26,743 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.52s
2024-12-10 22:00:26,755 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:26,755 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:00:27,606 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:27,608 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:00:27,608 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.38s. Returned 5 results
2024-12-10 22:00:27,608 - src.processing.query_processor - INFO - Processing quotation for keywords: there's a huge amount of wasted human talent because this is not an organization style or culture...
2024-12-10 22:00:27,633 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:27,634 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:00:27,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:27,965 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid'.
2024-12-10 22:00:28,040 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.072s]
2024-12-10 22:00:28,084 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.035s]
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:00:28,084 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:28,084 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:28,084 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:28,084 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:28,085 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.45s
2024-12-10 22:00:28,094 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:28,094 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:00:28,989 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:28,991 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.90s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:00:28,992 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.36s. Returned 5 results
2024-12-10 22:00:28,992 - src.processing.query_processor - INFO - Processing quotation for keywords: I hope it'll get us much better than we are now at helping get everyone to their Max potential...
2024-12-10 22:00:29,019 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:29,020 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:00:29,412 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:29,422 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like'.
2024-12-10 22:00:29,492 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.068s]
2024-12-10 22:00:29,538 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.028s]
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:29,539 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:29,539 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:00:29,539 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:29,539 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:29,540 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.52s
2024-12-10 22:00:29,552 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:29,553 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:00:30,387 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:30,390 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.84s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:00:30,390 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.37s. Returned 5 results
2024-12-10 22:00:30,390 - src.processing.query_processor - INFO - Processing quotation for keywords: I badly underappreciated the amount of work it took to be able to like keep charging at the next big...
2024-12-10 22:00:30,415 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:30,416 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:00:30,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:30,764 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like'.
2024-12-10 22:00:30,835 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.070s]
2024-12-10 22:00:30,888 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.037s]
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:30,889 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:30,889 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:00:30,889 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:30,889 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:30,890 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.47s
2024-12-10 22:00:30,901 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:30,901 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:00:31,730 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:31,733 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.83s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:00:31,733 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.32s. Returned 5 results
2024-12-10 22:00:31,734 - src.processing.query_processor - INFO - Processing quotation for keywords: there was either no playbook for this or someone had a secret Playbook they didn't give me....
2024-12-10 22:00:31,761 - src.processing.query_processor - INFO - Extracted 5 keywords for quotation.
2024-12-10 22:00:31,762 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:00:32,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:32,117 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like'.
2024-12-10 22:00:32,190 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.071s]
2024-12-10 22:00:32,234 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.029s]
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:32,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:32,235 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:00:32,235 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:32,235 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:32,236 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.47s
2024-12-10 22:00:32,248 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:32,249 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:00:33,448 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:33,450 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.20s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:00:33,450 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.69s. Returned 5 results
2024-12-10 22:00:33,450 - src.processing.query_processor - INFO - Processing quotation for keywords: you should hire incredibly young people under 30 and that is what Peter teal taught him....
2024-12-10 22:00:33,472 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:33,473 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:00:33,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:33,825 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like'.
2024-12-10 22:00:33,899 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.072s]
2024-12-10 22:00:33,940 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.024s]
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:33,941 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:33,941 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:00:33,941 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:33,942 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:33,942 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.47s
2024-12-10 22:00:33,954 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:33,954 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:00:35,442 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:35,443 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.49s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:00:35,443 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.97s. Returned 5 results
2024-12-10 22:00:35,444 - src.processing.query_processor - INFO - Processing quotation for keywords: when you're like designing some of the most complex and massively expensive computer systems that Hu...
2024-12-10 22:00:35,471 - src.processing.query_processor - INFO - Extracted 5 keywords for quotation.
2024-12-10 22:00:35,473 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:00:35,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:35,822 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like'.
2024-12-10 22:00:35,901 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.077s]
2024-12-10 22:00:35,948 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.031s]
2024-12-10 22:00:35,949 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:35,949 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:35,950 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:35,950 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:35,950 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:35,950 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:35,950 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:35,950 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:35,950 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:00:35,950 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:35,950 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:35,951 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.48s
2024-12-10 22:00:35,961 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:35,961 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:00:36,814 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:36,816 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:00:36,817 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.34s. Returned 5 results
2024-12-10 22:00:36,817 - src.processing.query_processor - INFO - Processing quotation for keywords: you want both....
2024-12-10 22:00:36,845 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:36,845 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...'
2024-12-10 22:00:37,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:37,211 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is and one of the things that I feel most grateful about why combinator 4 is inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value and uh we as a society should bet on those people and it's a great thing I am going to return to some semblance of the schedule is I'm I'm really going to get told off but anthropics models have been sometimes cited as being better for coding Tas why is that do you think that's fair and how should developers think about when to pick open AI versus a different provider *** yeah they have a model that is great at coding for sure ***'.
2024-12-10 22:00:37,247 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.034s]
2024-12-10 22:00:37,269 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.009s]
2024-12-10 22:00:37,270 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:37,270 - src.retrieval.retrieval - INFO - Filtered 1 chunks due to missing metadata.
2024-12-10 22:00:37,270 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:37,270 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'somehow just not it's not quite the framing that resonates with me but the part of it that does is and one of the things that I feel most grateful about why combinator 4 is inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value and uh we as a society should bet on those people and it's a great thing I am going to return to some semblance of the schedule is I'm I'm really going to get told off but anthropics models have been sometimes cited as being better for coding Tas why is that do you think that's fair and how should developers think about when to pick open AI versus a different provider *** yeah they have a model that is great at coding for sure ***': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:37,270 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.42s
2024-12-10 22:00:37,277 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:37,278 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...' with 5 documents
2024-12-10 22:00:38,045 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:38,049 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.77s. Top score: 0.9999, Bottom score: 0.0026
2024-12-10 22:00:38,049 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.20s. Returned 5 results
2024-12-10 22:00:38,049 - src.processing.query_processor - INFO - Processing quotation for keywords: inexperience does not inherently mean not valuable and there are incredibly high potential people at...
2024-12-10 22:00:38,079 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:38,079 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:00:38,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:38,502 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149'.
2024-12-10 22:00:38,594 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.090s]
2024-12-10 22:00:38,656 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.043s]
2024-12-10 22:00:38,657 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:38,657 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:38,657 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:38,657 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:38,658 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:38,658 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:38,658 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:38,658 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:38,658 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:38,658 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:38,658 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:38,658 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:38,658 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:38,659 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.58s
2024-12-10 22:00:38,672 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:38,672 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:00:39,534 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:39,537 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:00:39,537 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.46s. Returned 5 results
2024-12-10 22:00:39,537 - src.processing.query_processor - INFO - Processing quotation for keywords: I think developers use multiple models most of the time and I'm not sure how that's all going to evo...
2024-12-10 22:00:39,570 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:39,570 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:00:40,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:40,455 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149'.
2024-12-10 22:00:40,537 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.081s]
2024-12-10 22:00:40,593 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.042s]
2024-12-10 22:00:40,594 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:40,594 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:40,594 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:40,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:40,595 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:40,595 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:40,595 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:40,596 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 1.03s
2024-12-10 22:00:40,611 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:40,611 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:00:41,500 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:41,504 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.89s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:00:41,504 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.93s. Returned 5 results
2024-12-10 22:00:41,504 - src.processing.query_processor - INFO - Processing quotation for keywords: we have a lot of people here who are excited to build AGI and that that's a very motivating thing...
2024-12-10 22:00:41,536 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:41,536 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:00:41,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:41,856 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149'.
2024-12-10 22:00:41,929 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.072s]
2024-12-10 22:00:41,976 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.033s]
2024-12-10 22:00:41,977 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:41,977 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:41,977 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:41,977 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:41,977 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:41,977 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:41,978 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:41,978 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:41,978 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:41,978 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:41,978 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:41,978 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:41,978 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:41,979 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.44s
2024-12-10 22:00:41,990 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:41,990 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:00:42,869 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:42,871 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:00:42,872 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.34s. Returned 5 results
2024-12-10 22:00:42,872 - src.processing.query_processor - INFO - Processing quotation for keywords: the heaviest things in life are not iron or gold but unmade decisions...
2024-12-10 22:00:42,904 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:42,904 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:00:43,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:43,303 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology'.
2024-12-10 22:00:43,387 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.082s]
2024-12-10 22:00:43,434 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.032s]
2024-12-10 22:00:43,435 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:43,436 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:43,436 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:43,436 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:43,436 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:43,437 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.53s
2024-12-10 22:00:43,449 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:43,449 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:00:44,396 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:44,398 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.95s. Top score: 0.9998, Bottom score: 0.0322
2024-12-10 22:00:44,399 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.49s. Returned 5 results
2024-12-10 22:00:44,399 - src.processing.query_processor - INFO - Processing quotation for keywords: I think the wrong way to do that is to have one person you lean on for everything and the right way ...
2024-12-10 22:00:44,422 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:44,422 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:00:44,720 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:44,729 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology'.
2024-12-10 22:00:44,791 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.061s]
2024-12-10 22:00:44,832 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.031s]
2024-12-10 22:00:44,832 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:44,832 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:44,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:44,833 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:44,833 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:44,833 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:44,834 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.41s
2024-12-10 22:00:44,844 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:44,844 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:00:45,674 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:45,676 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.83s. Top score: 0.9998, Bottom score: 0.0322
2024-12-10 22:00:45,677 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.25s. Returned 5 results
2024-12-10 22:00:45,677 - src.processing.query_processor - INFO - Processing quotation for keywords: the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...
2024-12-10 22:00:45,704 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:45,705 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:00:46,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:46,084 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology'.
2024-12-10 22:00:46,151 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.065s]
2024-12-10 22:00:46,199 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.032s]
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:46,200 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:46,200 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:46,200 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:46,200 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:46,201 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.50s
2024-12-10 22:00:46,211 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:46,211 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:00:47,364 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:47,366 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.15s. Top score: 0.9998, Bottom score: 0.0322
2024-12-10 22:00:47,367 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.66s. Returned 5 results
2024-12-10 22:00:47,367 - src.processing.query_processor - INFO - Processing quotation for keywords: it was very like one of the defining things about the internet Revolution was it was actually really...
2024-12-10 22:00:47,399 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:47,399 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...'
2024-12-10 22:00:47,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:47,675 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it'.
2024-12-10 22:00:47,779 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.102s]
2024-12-10 22:00:47,833 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.037s]
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:47,834 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:47,834 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:47,835 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:47,835 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:47,836 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.44s
2024-12-10 22:00:47,847 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:47,847 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...' with 5 documents
2024-12-10 22:00:48,797 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:48,799 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.95s. Top score: 1.0000, Bottom score: 0.0831
2024-12-10 22:00:48,799 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.40s. Returned 5 results
2024-12-10 22:00:48,800 - src.processing.query_processor - INFO - Processing quotation for keywords: the one I like the most caveat by my earlier comment that I don't think people should be doing this ...
2024-12-10 22:00:48,822 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:48,823 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...'
2024-12-10 22:00:49,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:49,150 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it'.
2024-12-10 22:00:49,251 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.099s]
2024-12-10 22:00:49,313 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.046s]
2024-12-10 22:00:49,314 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:49,314 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:49,314 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:49,314 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:49,314 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:49,314 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:49,315 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:49,315 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:49,315 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:49,315 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:49,315 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:49,315 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:49,316 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.49s
2024-12-10 22:00:49,326 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:49,326 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...' with 5 documents
2024-12-10 22:00:50,231 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:50,235 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.91s. Top score: 1.0000, Bottom score: 0.0831
2024-12-10 22:00:50,235 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.41s. Returned 5 results
2024-12-10 22:00:50,235 - src.processing.query_processor - INFO - Processing quotation for keywords: something about an AI that can understand your whole life doesn't have to like literally be infinite...
2024-12-10 22:00:50,265 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:50,266 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...'
2024-12-10 22:00:50,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:50,547 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it'.
2024-12-10 22:00:50,639 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.086s]
2024-12-10 22:00:50,690 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.035s]
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:50,691 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:50,691 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:00:50,691 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:50,692 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:00:50,692 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.43s
2024-12-10 22:00:50,704 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:50,704 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...' with 5 documents
2024-12-10 22:00:51,565 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:51,568 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0831
2024-12-10 22:00:51,568 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.30s. Returned 5 results
2024-12-10 22:00:51,568 - src.processing.query_processor - INFO - Processing quotation for keywords: I think to really have do what they've done and built I thought about like a bunch of researchers I ...
2024-12-10 22:00:51,597 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:51,597 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:00:51,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:51,933 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all'.
2024-12-10 22:00:52,030 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.094s]
2024-12-10 22:00:52,090 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.044s]
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:52,091 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:52,091 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:52,092 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:52,092 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:52,093 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.50s
2024-12-10 22:00:52,107 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:52,107 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:00:52,997 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:53,001 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.89s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:00:53,001 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.40s. Returned 5 results
2024-12-10 22:00:53,001 - src.processing.query_processor - INFO - Processing quotation for keywords: I think that product is a weakness of mine in general...
2024-12-10 22:00:53,027 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:00:53,027 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:00:53,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:53,400 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all'.
2024-12-10 22:00:53,501 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.098s]
2024-12-10 22:00:53,560 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.043s]
2024-12-10 22:00:53,561 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:53,561 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:53,561 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:53,561 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:53,561 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:53,562 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:53,562 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:53,562 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:53,562 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:53,562 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:53,562 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:53,562 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:53,562 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:53,563 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.54s
2024-12-10 22:00:53,576 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:53,576 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:00:54,375 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:54,377 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.80s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:00:54,377 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.35s. Returned 5 results
2024-12-10 22:00:54,377 - src.processing.query_processor - INFO - Processing quotation for keywords: I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...
2024-12-10 22:00:54,406 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:54,406 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:00:54,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:54,791 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all'.
2024-12-10 22:00:54,875 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.081s]
2024-12-10 22:00:54,923 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.034s]
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:54,925 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:54,926 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:00:54,926 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:54,926 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:00:54,927 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.52s
2024-12-10 22:00:54,940 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:54,940 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:00:55,780 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:55,782 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.84s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:00:55,782 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.38s. Returned 5 results
2024-12-10 22:00:55,782 - src.processing.query_processor - INFO - Processing quotation for keywords: the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...
2024-12-10 22:00:55,806 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:00:55,813 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_keyword_extraction.json'
2024-12-10 22:00:55,814 - __main__ - INFO - Processed queries in 46.30s
2024-12-10 22:00:55,814 - __main__ - INFO - Starting evaluation
2024-12-10 22:00:55,814 - src.data.data_loader - INFO - Loaded JSONL file 'data/evaluation/evaluation_set_keyword.jsonl' with 3 entries successfully.
2024-12-10 22:00:55,814 - __main__ - INFO - Loaded 3 evaluation queries
2024-12-10 22:00:55,814 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:00:55,814 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:00:55,814 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:00:55,814 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:00:55,814 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:00:55,815 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:00:55,816 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:00:55,816 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:00:55,816 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:00:55,816 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:00:55,816 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:00:55,816 - __main__ - INFO - Pipeline for KeywordExtractionModule completed in 47.37s
2024-12-10 22:00:55,816 - __main__ - INFO - Completed Keyword Extraction in 47.37s
2024-12-10 22:00:55,816 - __main__ - INFO - Converting keyword results to coding format
2024-12-10 22:00:55,821 - __main__ - INFO - Keyword to coding conversion completed
2024-12-10 22:00:55,821 - __main__ - INFO - Starting Coding Analysis Pipeline
2024-12-10 22:00:55,821 - __main__ - INFO - Starting pipeline with CodingAnalysisModule
2024-12-10 22:00:55,821 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:00:55,821 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:00:55,821 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:00:55,821 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:00:55,821 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:00:55,821 - src.core.contextual_vector_db - INFO - Vector database is already loaded. Skipping data loading.
2024-12-10 22:00:55,821 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:00:55,821 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_coding_analysis
2024-12-10 22:00:55,821 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_coding_analysis
2024-12-10 22:00:55,829 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.007s]
2024-12-10 22:00:55,833 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_coding_analysis [status:200 duration:0.003s]
2024-12-10 22:00:55,833 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_coding_analysis' already exists. Skipping creation.
2024-12-10 22:00:55,857 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.023s]
2024-12-10 22:00:55,872 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_refresh [status:200 duration:0.015s]
2024-12-10 22:00:55,872 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:00:55,872 - __main__ - INFO - Successfully indexed 5 documents in 0.04s
2024-12-10 22:00:55,872 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.05s
2024-12-10 22:00:55,872 - __main__ - INFO - Created Elasticsearch BM25 index in 0.05s
2024-12-10 22:00:55,872 - __main__ - INFO - Loading queries from data/input/queries_coding_standard.json
2024-12-10 22:00:55,873 - src.data.data_loader - INFO - Loaded JSON file 'data/input/queries_coding_standard.json' successfully with 32 entries.
2024-12-10 22:00:55,873 - __main__ - INFO - Loaded 32 queries
2024-12-10 22:00:55,873 - __main__ - INFO - Validating queries
2024-12-10 22:00:55,874 - src.processing.query_processor - INFO - Validated 32 transcripts out of 32 provided.
2024-12-10 22:00:55,874 - __main__ - INFO - Validated 32 queries
2024-12-10 22:00:55,874 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:00:55,874 - __main__ - INFO - Initializing optimizer for CodingAnalysisModule
2024-12-10 22:00:55,874 - __main__ - INFO - Initializing coding analysis optimizer
2024-12-10 22:00:56,486 - __main__ - INFO - Loaded coding training dataset: 3 samples
2024-12-10 22:00:56,499 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,510 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,521 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,561 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,567 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,573 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,581 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,587 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,592 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,600 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:00:56,606 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,612 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:00:56,619 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,624 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,630 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,636 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,641 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,647 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:00:56,653 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,658 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,665 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,670 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,676 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:00:56,682 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,688 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:00:56,694 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,699 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:00:56,706 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,711 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,717 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,722 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,728 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:00:56,735 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,740 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,746 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,752 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,757 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:00:56,764 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,769 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,775 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,780 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:00:56,786 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,792 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:00:56,799 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,804 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:00:56,810 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,816 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:00:56,822 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,828 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,833 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,839 - src.analysis.metrics - INFO - Comprehensive metric score: 0.34
2024-12-10 22:00:56,845 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,851 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,857 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,863 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,869 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,874 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,880 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:00:56,887 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,892 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:00:56,897 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,903 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:00:56,908 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:00:56,914 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:00:56,915 - __main__ - INFO - Compiled optimized coding program in 0.43s
2024-12-10 22:00:56,916 - __main__ - INFO - Saved optimized coding program to data/optimized/optimized_coding_program.json
2024-12-10 22:00:56,916 - __main__ - INFO - Coding optimizer initialization completed in 1.04s
2024-12-10 22:00:56,916 - __main__ - INFO - Initialized optimizer in 1.04s
2024-12-10 22:00:56,916 - __main__ - INFO - Initializing CodingAnalysisModule
2024-12-10 22:00:56,920 - __main__ - INFO - Initialized CodingAnalysisModule with assertions
2024-12-10 22:00:56,920 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:00:56,921 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_coding_analysis.json'.
2024-12-10 22:00:56,921 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:00:57,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:57,239 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we are going to try our hardest and believe we will succeed at making our models better and better and better...'.
2024-12-10 22:00:57,281 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.040s]
2024-12-10 22:00:57,306 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.010s]
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_17
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_40
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_59
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_69
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_66
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:00:57,309 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:00:57,310 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:57,310 - src.retrieval.retrieval - INFO - Filtered 18 chunks due to missing metadata.
2024-12-10 22:00:57,310 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:57,310 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better...': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:00:57,310 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.39s
2024-12-10 22:00:57,320 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:57,320 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:00:58,033 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:58,037 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.72s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:00:58,037 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.12s. Returned 5 results
2024-12-10 22:00:58,038 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='we are going to try our hardest and believe we will succeed at making our models better and better a...', Keywords=['improvement', 'believe', 'models', 'better']
2024-12-10 22:00:58,039 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:00:58,065 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:00:58,065 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:00:58,065 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...'
2024-12-10 22:00:58,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:58,537 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do...'.
2024-12-10 22:00:58,579 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.040s]
2024-12-10 22:00:58,600 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_23
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:00:58,603 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:58,603 - src.retrieval.retrieval - INFO - Filtered 25 chunks due to missing metadata.
2024-12-10 22:00:58,603 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:58,603 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do...': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:00:58,604 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.54s
2024-12-10 22:00:58,612 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:58,613 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...' with 5 documents
2024-12-10 22:00:59,447 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:00:59,450 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.84s. Top score: 0.9996, Bottom score: 0.0006
2024-12-10 22:00:59,450 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.38s. Returned 5 results
2024-12-10 22:00:59,450 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...', Keywords=['reasoning', 'unlock', 'improvement']
2024-12-10 22:00:59,450 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:00:59,473 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:00:59,473 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:00:59,474 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...'
2024-12-10 22:00:59,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:00:59,785 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before'.
2024-12-10 22:00:59,816 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.029s]
2024-12-10 22:00:59,838 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.012s]
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:00:59,840 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:00:59,840 - src.retrieval.retrieval - INFO - Filtered 7 chunks due to missing metadata.
2024-12-10 22:00:59,841 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:00:59,841 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:00:59,841 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.37s
2024-12-10 22:00:59,849 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:00:59,850 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...' with 5 documents
2024-12-10 22:01:00,574 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:00,577 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9999, Bottom score: 0.0010
2024-12-10 22:01:00,577 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.10s. Returned 5 results
2024-12-10 22:01:00,578 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there will be many trillions of dollars of market cap that gets created new market cap that gets cre...', Keywords=['market cap', 'AI innovations', 'impossible products']
2024-12-10 22:01:00,578 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:00,599 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:00,600 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:00,600 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...'
2024-12-10 22:01:00,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:00,990 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to do'.
2024-12-10 22:01:01,030 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.038s]
2024-12-10 22:01:01,053 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.010s]
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_75
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_15
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_59
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:01,058 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:01:01,059 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_69
2024-12-10 22:01:01,059 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:01,059 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:01:01,059 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:01,059 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_18
2024-12-10 22:01:01,059 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:01:01,059 - src.retrieval.retrieval - INFO - Filtered 35 chunks due to missing metadata.
2024-12-10 22:01:01,059 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:01,059 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think people have like internalized the rate of Improvement and have heard us on what we intend to do': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:01:01,059 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.46s
2024-12-10 22:01:01,067 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:01,067 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...' with 5 documents
2024-12-10 22:01:01,805 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:01,806 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:01:01,807 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.21s. Returned 5 results
2024-12-10 22:01:01,807 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think people have like internalized the rate of Improvement and have heard us on what we intend to...', Keywords=['internalized', 'rate of improvement', 'commitment']
2024-12-10 22:01:01,807 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:01,827 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:01,827 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:01,828 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...'
2024-12-10 22:01:02,151 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:02,221 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed'.
2024-12-10 22:01:02,244 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.022s]
2024-12-10 22:01:02,256 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:02,257 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:01:02,257 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:02,257 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:01:02,257 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.43s
2024-12-10 22:01:02,267 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:02,267 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...' with 5 documents
2024-12-10 22:01:03,035 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:03,037 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.77s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:01:03,037 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.21s. Returned 5 results
2024-12-10 22:01:03,037 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there will be9 trillion dollars of value created did every single year which will offset the $9 tril...', Keywords=['value creation', 'capax', 'AI models']
2024-12-10 22:01:03,038 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:03,063 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:03,063 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:03,063 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...'
2024-12-10 22:01:03,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:03,451 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want'.
2024-12-10 22:01:03,480 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:01:03,495 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:03,496 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:03,496 - src.retrieval.retrieval - INFO - Filtered 11 chunks due to missing metadata.
2024-12-10 22:01:03,496 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:03,496 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:01:03,497 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.43s
2024-12-10 22:01:03,504 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:03,504 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...' with 5 documents
2024-12-10 22:01:04,165 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:04,168 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.66s. Top score: 0.9991, Bottom score: 0.0000
2024-12-10 22:01:04,168 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.11s. Returned 5 results
2024-12-10 22:01:04,169 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='think about how much economic value gets unlocked for the world if anybody can just describe like a ...', Keywords=['economic value', 'software needs', 'transformative potential', 'reasoning']
2024-12-10 22:01:04,169 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:04,193 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:04,193 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:04,194 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's clearly a really important place in the Eos system for open source models...'
2024-12-10 22:01:04,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:04,499 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there's clearly a really important place in the Eos system for open source models'.
2024-12-10 22:01:04,527 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.026s]
2024-12-10 22:01:04,545 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:01:04,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:01:04,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:01:04,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:01:04,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_45
2024-12-10 22:01:04,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:04,547 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:04,547 - src.retrieval.retrieval - INFO - Filtered 6 chunks due to missing metadata.
2024-12-10 22:01:04,547 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:04,547 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's clearly a really important place in the Eos system for open source models': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:01:04,548 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.35s
2024-12-10 22:01:04,557 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:04,557 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's clearly a really important place in the Eos system for open source models...' with 5 documents
2024-12-10 22:01:05,256 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:05,260 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:05,260 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.07s. Returned 5 results
2024-12-10 22:01:05,260 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there's clearly a really important place in the Eos system for open source models...', Keywords=['open source models', 'Eos system', 'transformative potential']
2024-12-10 22:01:05,261 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:05,284 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:05,284 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:05,284 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...'
2024-12-10 22:01:05,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:05,708 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker'.
2024-12-10 22:01:05,738 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:05,753 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:05,754 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:05,754 - src.retrieval.retrieval - INFO - Filtered 15 chunks due to missing metadata.
2024-12-10 22:01:05,754 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:05,754 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:01:05,754 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.47s
2024-12-10 22:01:05,761 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:05,762 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...' with 5 documents
2024-12-10 22:01:06,616 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:06,618 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:06,618 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.33s. Returned 5 results
2024-12-10 22:01:06,619 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the category I think though is more interesting is not the one that people normally talk about where...', Keywords=['smart senior co-worker', 'transformative potential', 'complex tasks']
2024-12-10 22:01:06,619 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:06,646 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:06,646 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:06,646 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...'
2024-12-10 22:01:07,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:07,133 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created'.
2024-12-10 22:01:07,163 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.029s]
2024-12-10 22:01:07,180 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:07,181 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:07,181 - src.retrieval.retrieval - INFO - Filtered 11 chunks due to missing metadata.
2024-12-10 22:01:07,181 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:07,181 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:01:07,181 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.53s
2024-12-10 22:01:07,188 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:07,188 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...' with 5 documents
2024-12-10 22:01:07,856 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:07,859 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.67s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:01:07,859 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.21s. Returned 5 results
2024-12-10 22:01:07,859 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='reasoning is our current most important area of focus I think this is what unlocks the next like mas...', Keywords=['reasoning', 'economic value', 'transformation']
2024-12-10 22:01:07,860 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:07,887 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:07,887 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:07,887 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair...'
2024-12-10 22:01:08,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:08,263 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair'.
2024-12-10 22:01:08,303 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.039s]
2024-12-10 22:01:08,340 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.021s]
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_81
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_53
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_40
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_89
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_75
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_15
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_51
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_22
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_31
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_57
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:08,350 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_88
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:08,351 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:01:08,351 - src.retrieval.retrieval - INFO - Filtered 40 chunks due to missing metadata.
2024-12-10 22:01:08,351 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:08,351 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the actual like Revenue we can make from a model I think justifies the investment to be fair': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:01:08,352 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.46s
2024-12-10 22:01:08,361 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:08,361 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair...' with 5 documents
2024-12-10 22:01:09,074 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:09,076 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:01:09,076 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.19s. Returned 5 results
2024-12-10 22:01:09,076 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the actual like Revenue we can make from a model I think justifies the investment to be fair...', Keywords=['Revenue', 'Investment', 'AI Models']
2024-12-10 22:01:09,076 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:09,097 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:09,098 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:09,098 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...'
2024-12-10 22:01:09,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:09,495 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works'.
2024-12-10 22:01:09,522 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.025s]
2024-12-10 22:01:09,539 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:09,540 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:09,540 - src.retrieval.retrieval - INFO - Filtered 13 chunks due to missing metadata.
2024-12-10 22:01:09,540 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:09,540 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:01:09,541 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.44s
2024-12-10 22:01:09,550 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:09,550 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...' with 5 documents
2024-12-10 22:01:10,308 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:10,310 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 0.9974, Bottom score: 0.0000
2024-12-10 22:01:10,310 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.21s. Returned 5 results
2024-12-10 22:01:10,310 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...', Keywords=['Transformer', 'innovation', 'replicate', 'culture', 'human talent']
2024-12-10 22:01:10,311 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:10,333 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:10,333 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:10,333 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the repeated ability to go off and do something new and totally unproven...'
2024-12-10 22:01:10,643 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:10,654 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the repeated ability to go off and do something new and totally unproven'.
2024-12-10 22:01:10,682 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:10,699 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_16
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_55
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_67
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:10,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_41
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:10,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:10,703 - src.retrieval.retrieval - INFO - Filtered 19 chunks due to missing metadata.
2024-12-10 22:01:10,703 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:10,703 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the repeated ability to go off and do something new and totally unproven': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:01:10,703 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.37s
2024-12-10 22:01:10,718 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:10,719 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the repeated ability to go off and do something new and totally unproven...' with 5 documents
2024-12-10 22:01:11,399 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:11,401 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.68s. Top score: 0.9962, Bottom score: 0.0000
2024-12-10 22:01:11,401 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.07s. Returned 5 results
2024-12-10 22:01:11,401 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the repeated ability to go off and do something new and totally unproven...', Keywords=['innovation', 'unproven', 'ability']
2024-12-10 22:01:11,402 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:11,427 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:11,429 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:11,429 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture...'
2024-12-10 22:01:11,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:11,682 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture'.
2024-12-10 22:01:11,705 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.021s]
2024-12-10 22:01:11,719 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:01:11,720 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:01:11,720 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:11,720 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's a huge amount of wasted human talent because this is not an organization style or culture': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:01:11,721 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.29s
2024-12-10 22:01:11,730 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:11,730 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture...' with 5 documents
2024-12-10 22:01:12,426 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:12,429 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:01:12,429 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.00s. Returned 5 results
2024-12-10 22:01:12,429 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there's a huge amount of wasted human talent because this is not an organization style or culture...', Keywords=['wasted human talent', 'organization style', 'innovation']
2024-12-10 22:01:12,430 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:12,459 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:12,459 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:12,460 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential...'
2024-12-10 22:01:12,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:12,776 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential'.
2024-12-10 22:01:12,809 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.031s]
2024-12-10 22:01:12,829 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_40
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_81
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_23
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:12,831 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:12,831 - src.retrieval.retrieval - INFO - Filtered 21 chunks due to missing metadata.
2024-12-10 22:01:12,831 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:12,831 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I hope it'll get us much better than we are now at helping get everyone to their Max potential': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:01:12,832 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.37s
2024-12-10 22:01:12,840 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:12,840 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential...' with 5 documents
2024-12-10 22:01:13,841 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:13,843 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.00s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:01:13,843 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.38s. Returned 5 results
2024-12-10 22:01:13,843 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I hope it'll get us much better than we are now at helping get everyone to their Max potential...', Keywords=['Max potential', 'innovation', 'unlock potential']
2024-12-10 22:01:13,844 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:13,870 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:13,871 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:13,871 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...'
2024-12-10 22:01:14,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:14,303 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do.'.
2024-12-10 22:01:14,332 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:01:14,347 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:14,347 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:14,347 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:01:14,347 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:14,347 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do.': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:01:14,348 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.48s
2024-12-10 22:01:14,357 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:14,358 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...' with 5 documents
2024-12-10 22:01:15,113 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:15,117 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:01:15,118 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.25s. Returned 5 results
2024-12-10 22:01:15,118 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I badly underappreciated the amount of work it took to be able to like keep charging at the next big...', Keywords=['underappreciated', 'work', 'next big step', 'neglecting']
2024-12-10 22:01:15,118 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:15,142 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:15,142 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:15,142 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me....'
2024-12-10 22:01:15,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:15,536 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me.'.
2024-12-10 22:01:15,555 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.015s]
2024-12-10 22:01:15,569 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:15,569 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:15,569 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:15,569 - src.retrieval.retrieval - INFO - Filtered 2 chunks due to missing metadata.
2024-12-10 22:01:15,570 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:15,570 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there was either no playbook for this or someone had a secret Playbook they didn't give me.': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:01:15,570 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.43s
2024-12-10 22:01:15,578 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:15,578 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me....' with 5 documents
2024-12-10 22:01:16,252 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:16,255 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.68s. Top score: 0.9996, Bottom score: 0.0000
2024-12-10 22:01:16,255 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.11s. Returned 5 results
2024-12-10 22:01:16,255 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there was either no playbook for this or someone had a secret Playbook they didn't give me....', Keywords=['playbook', 'innovation', 'challenges', 'unproven ideas', 'human talent']
2024-12-10 22:01:16,256 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:16,284 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:16,284 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:16,284 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him....'
2024-12-10 22:01:16,552 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:16,564 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him.'.
2024-12-10 22:01:16,592 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:16,606 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:16,606 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:16,606 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:01:16,606 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:16,606 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you should hire incredibly young people under 30 and that is what Peter teal taught him.': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:01:16,607 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.32s
2024-12-10 22:01:16,615 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:16,615 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him....' with 5 documents
2024-12-10 22:01:17,368 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:17,371 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:17,371 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.09s. Returned 5 results
2024-12-10 22:01:17,371 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='you should hire incredibly young people under 30 and that is what Peter teal taught him....', Keywords=['young people', 'innovation', 'talent']
2024-12-10 22:01:17,372 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:17,394 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:17,394 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:17,394 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...'
2024-12-10 22:01:17,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:17,655 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built.'.
2024-12-10 22:01:17,681 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.025s]
2024-12-10 22:01:17,695 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:17,696 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:17,696 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:17,696 - src.retrieval.retrieval - INFO - Filtered 2 chunks due to missing metadata.
2024-12-10 22:01:17,696 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:17,696 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built.': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:01:17,697 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.30s
2024-12-10 22:01:17,704 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:17,704 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...' with 5 documents
2024-12-10 22:01:18,403 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:18,407 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:01:18,407 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.01s. Returned 5 results
2024-12-10 22:01:18,407 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='when you're like designing some of the most complex and massively expensive computer systems that Hu...', Keywords=['designing', 'complex', 'expensive', 'computer systems', 'innovation']
2024-12-10 22:01:18,408 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:18,430 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:18,430 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:18,430 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you want both....'
2024-12-10 22:01:18,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:18,793 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'you want both.'.
2024-12-10 22:01:18,848 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.053s]
2024-12-10 22:01:18,879 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.009s]
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_35
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_29
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_28
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:01:18,884 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_23
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_16
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_70
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_66
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_69
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_14
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_18
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_67
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_60
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_88
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:18,885 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:01:18,885 - src.retrieval.retrieval - INFO - Filtered 45 chunks due to missing metadata.
2024-12-10 22:01:18,885 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:18,885 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you want both.': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:01:18,886 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.46s
2024-12-10 22:01:18,894 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:18,894 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you want both....' with 5 documents
2024-12-10 22:01:20,029 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:20,033 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.14s. Top score: 0.9723, Bottom score: 0.0000
2024-12-10 22:01:20,034 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.60s. Returned 5 results
2024-12-10 22:01:20,034 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='you want both....', Keywords=['innovation', 'replication', 'culture']
2024-12-10 22:01:20,034 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:20,055 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:20,055 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:20,055 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...'
2024-12-10 22:01:20,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:20,553 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value'.
2024-12-10 22:01:20,569 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.016s]
2024-12-10 22:01:20,576 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:20,576 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:01:20,576 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:20,576 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:01:20,577 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.52s
2024-12-10 22:01:20,582 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:20,582 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...' with 5 documents
2024-12-10 22:01:21,278 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:21,280 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:21,280 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.22s. Returned 5 results
2024-12-10 22:01:21,280 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='inexperience does not inherently mean not valuable and there are incredibly high potential people at...', Keywords=['inexperience', 'potential', 'value']
2024-12-10 22:01:21,280 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:21,299 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:21,300 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:21,300 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...'
2024-12-10 22:01:21,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:21,887 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World'.
2024-12-10 22:01:21,921 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.031s]
2024-12-10 22:01:21,936 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:21,937 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:21,937 - src.retrieval.retrieval - INFO - Filtered 13 chunks due to missing metadata.
2024-12-10 22:01:21,937 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:21,938 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:01:21,938 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.64s
2024-12-10 22:01:21,946 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:21,946 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...' with 5 documents
2024-12-10 22:01:22,601 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:22,602 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.66s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:22,602 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.30s. Returned 5 results
2024-12-10 22:01:22,602 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think developers use multiple models most of the time and I'm not sure how that's all going to evo...', Keywords=['multiple models', 'AG genified World', 'collaboration', 'reasoning capabilities']
2024-12-10 22:01:22,602 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:22,618 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:22,619 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:22,619 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing...'
2024-12-10 22:01:23,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:23,116 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing'.
2024-12-10 22:01:23,153 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.034s]
2024-12-10 22:01:23,172 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_15
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_73
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_14
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_46
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:23,175 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:23,176 - src.retrieval.retrieval - INFO - Filtered 28 chunks due to missing metadata.
2024-12-10 22:01:23,176 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:23,176 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:01:23,176 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.56s
2024-12-10 22:01:23,185 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:23,185 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing...' with 5 documents
2024-12-10 22:01:23,978 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:23,980 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.79s. Top score: 1.0000, Bottom score: 0.0127
2024-12-10 22:01:23,980 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.36s. Returned 5 results
2024-12-10 22:01:23,980 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='we have a lot of people here who are excited to build AGI and that that's a very motivating thing...', Keywords=['AGI', 'motivation', 'collaboration']
2024-12-10 22:01:23,981 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:24,007 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:24,007 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:24,007 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions...'
2024-12-10 22:01:24,301 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:24,312 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the heaviest things in life are not iron or gold but unmade decisions'.
2024-12-10 22:01:24,325 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.012s]
2024-12-10 22:01:24,332 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:01:24,333 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:01:24,333 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:24,333 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the heaviest things in life are not iron or gold but unmade decisions': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:01:24,333 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.33s
2024-12-10 22:01:24,345 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:24,345 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions...' with 5 documents
2024-12-10 22:01:25,047 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:25,051 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9963, Bottom score: 0.0000
2024-12-10 22:01:25,051 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.04s. Returned 5 results
2024-12-10 22:01:25,052 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the heaviest things in life are not iron or gold but unmade decisions...', Keywords=['decisions', 'collaboration', 'AI development']
2024-12-10 22:01:25,052 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:25,075 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:25,076 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:25,076 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...'
2024-12-10 22:01:25,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:25,405 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way'.
2024-12-10 22:01:25,436 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:25,449 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:25,450 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:25,450 - src.retrieval.retrieval - INFO - Filtered 16 chunks due to missing metadata.
2024-12-10 22:01:25,450 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:25,450 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:01:25,450 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.37s
2024-12-10 22:01:25,457 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:25,458 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...' with 5 documents
2024-12-10 22:01:26,155 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:26,159 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9999, Bottom score: 0.0002
2024-12-10 22:01:26,159 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.08s. Returned 5 results
2024-12-10 22:01:26,159 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think the wrong way to do that is to have one person you lean on for everything and the right way ...', Keywords=['collaboration', 'decision-making', 'diversity']
2024-12-10 22:01:26,160 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:26,183 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:26,183 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:26,183 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...'
2024-12-10 22:01:26,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:26,478 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before'.
2024-12-10 22:01:26,508 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.029s]
2024-12-10 22:01:26,529 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_57
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_89
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_46
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:26,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:26,532 - src.retrieval.retrieval - INFO - Filtered 15 chunks due to missing metadata.
2024-12-10 22:01:26,532 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:26,532 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:01:26,533 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.35s
2024-12-10 22:01:26,542 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:26,542 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...' with 5 documents
2024-12-10 22:01:27,301 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:27,304 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:01:27,304 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.12s. Returned 5 results
2024-12-10 22:01:27,304 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...', Keywords=['ecosystem complexity', 'fractal scan', 'collaboration', 'integrated systems']
2024-12-10 22:01:27,305 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:27,331 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:27,332 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:27,332 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...'
2024-12-10 22:01:27,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:27,631 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'it was very like one of the defining things about the internet Revolution was it was actually really easy to get started'.
2024-12-10 22:01:27,658 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:27,676 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_41
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_57
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_29
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:27,678 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:27,678 - src.retrieval.retrieval - INFO - Filtered 28 chunks due to missing metadata.
2024-12-10 22:01:27,678 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:27,678 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'it was very like one of the defining things about the internet Revolution was it was actually really easy to get started': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:01:27,679 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.35s
2024-12-10 22:01:27,686 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:27,687 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...' with 5 documents
2024-12-10 22:01:28,390 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:28,392 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9983, Bottom score: 0.0000
2024-12-10 22:01:28,392 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.06s. Returned 5 results
2024-12-10 22:01:28,393 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='it was very like one of the defining things about the internet Revolution was it was actually really...', Keywords=['internet Revolution', 'easy to get started', 'AI development']
2024-12-10 22:01:28,393 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:28,421 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:28,421 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:28,421 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...'
2024-12-10 22:01:28,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:28,744 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties'.
2024-12-10 22:01:28,773 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:28,784 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:01:28,784 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:28,784 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:28,784 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:28,785 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:28,785 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:28,785 - src.retrieval.retrieval - INFO - Filtered 5 chunks due to missing metadata.
2024-12-10 22:01:28,785 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:28,785 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:01:28,785 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.36s
2024-12-10 22:01:28,794 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:28,794 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...' with 5 documents
2024-12-10 22:01:29,545 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:29,548 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.75s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:01:29,548 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.13s. Returned 5 results
2024-12-10 22:01:29,548 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the one I like the most caveat by my earlier comment that I don't think people should be doing this ...', Keywords=['discovery', 'scaling properties', 'analogies']
2024-12-10 22:01:29,549 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:29,574 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:29,574 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:29,575 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...'
2024-12-10 22:01:29,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:29,842 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data'.
2024-12-10 22:01:29,876 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.032s]
2024-12-10 22:01:29,898 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.009s]
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:29,901 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:29,901 - src.retrieval.retrieval - INFO - Filtered 13 chunks due to missing metadata.
2024-12-10 22:01:29,901 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:29,901 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data': [interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:01:29,902 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.33s
2024-12-10 22:01:29,911 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:29,911 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...' with 5 documents
2024-12-10 22:01:30,655 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:30,657 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.75s. Top score: 0.9999, Bottom score: 0.0001
2024-12-10 22:01:30,657 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.08s. Returned 5 results
2024-12-10 22:01:30,657 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='something about an AI that can understand your whole life doesn't have to like literally be infinite...', Keywords=['AI', 'understand', 'data', 'enhance']
2024-12-10 22:01:30,658 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:30,681 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:30,681 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:30,681 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...'
2024-12-10 22:01:30,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:30,980 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I could name'.
2024-12-10 22:01:31,018 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.036s]
2024-12-10 22:01:31,035 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:01:31,037 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:31,038 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:01:31,038 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:31,038 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:01:31,038 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:01:31,038 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:01:31,038 - src.retrieval.retrieval - INFO - Filtered 26 chunks due to missing metadata.
2024-12-10 22:01:31,038 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:31,038 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think to really have do what they've done and built I thought about like a bunch of researchers I could name': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:01:31,038 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.36s
2024-12-10 22:01:31,046 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:31,047 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...' with 5 documents
2024-12-10 22:01:31,741 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:31,744 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9994, Bottom score: 0.0000
2024-12-10 22:01:31,744 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.06s. Returned 5 results
2024-12-10 22:01:31,745 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think to really have do what they've done and built I thought about like a bunch of researchers I ...', Keywords=['AI', 'researchers', 'leadership']
2024-12-10 22:01:31,745 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:31,768 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:31,768 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:31,768 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think that product is a weakness of mine in general...'
2024-12-10 22:01:32,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:32,230 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think that product is a weakness of mine in general'.
2024-12-10 22:01:32,276 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.044s]
2024-12-10 22:01:32,317 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.025s]
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_81
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_32
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_17
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:32,331 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_56
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_66
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_35
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_46
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_73
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_14
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_60
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_49
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_51
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_71
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:01:32,332 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:01:32,332 - src.retrieval.retrieval - INFO - Filtered 45 chunks due to missing metadata.
2024-12-10 22:01:32,332 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:32,332 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think that product is a weakness of mine in general': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1]
2024-12-10 22:01:32,333 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.57s
2024-12-10 22:01:32,341 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:32,341 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think that product is a weakness of mine in general...' with 5 documents
2024-12-10 22:01:33,139 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:33,142 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.80s. Top score: 0.9990, Bottom score: 0.0000
2024-12-10 22:01:33,142 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.37s. Returned 5 results
2024-12-10 22:01:33,142 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think that product is a weakness of mine in general...', Keywords=['product', 'weakness', 'leadership']
2024-12-10 22:01:33,143 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:33,167 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:33,168 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:33,168 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...'
2024-12-10 22:01:33,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:33,580 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years'.
2024-12-10 22:01:33,609 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:01:33,627 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:01:33,629 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:01:33,629 - src.retrieval.retrieval - INFO - Filtered 18 chunks due to missing metadata.
2024-12-10 22:01:33,629 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:33,629 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years': [interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:01:33,630 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.46s
2024-12-10 22:01:33,639 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:33,639 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...' with 5 documents
2024-12-10 22:01:34,345 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:34,348 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:34,349 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.18s. Returned 5 results
2024-12-10 22:01:34,349 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...', Keywords=['Discovery', 'Physics', 'AI', 'Years']
2024-12-10 22:01:34,349 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:34,374 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:34,374 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:01:34,374 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...'
2024-12-10 22:01:34,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:34,782 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science'.
2024-12-10 22:01:34,809 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.026s]
2024-12-10 22:01:34,825 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:01:34,827 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:01:34,827 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:01:34,827 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:01:34,827 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:01:34,827 - src.retrieval.retrieval - INFO - Filtered 4 chunks due to missing metadata.
2024-12-10 22:01:34,827 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:34,827 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1]
2024-12-10 22:01:34,827 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.45s
2024-12-10 22:01:34,837 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:34,837 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...' with 5 documents
2024-12-10 22:01:35,555 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:35,559 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.72s. Top score: 0.9998, Bottom score: 0.0006
2024-12-10 22:01:35,559 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.18s. Returned 5 results
2024-12-10 22:01:35,559 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...', Keywords=['pace of progress', 'discovering new stuff', 'AI research', 'Science']
2024-12-10 22:01:35,560 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:01:35,584 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:01:35,584 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:01:35,594 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_coding_analysis.json'
2024-12-10 22:01:35,594 - __main__ - INFO - Processed queries in 38.67s
2024-12-10 22:01:35,594 - __main__ - INFO - Starting evaluation
2024-12-10 22:01:35,595 - src.data.data_loader - INFO - Loaded JSONL file 'data/evaluation/evaluation_set_coding.jsonl' with 3 entries successfully.
2024-12-10 22:01:35,595 - __main__ - INFO - Loaded 3 evaluation queries
2024-12-10 22:01:35,595 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:01:35,595 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:01:35,595 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:01:35,595 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:01:35,595 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:01:35,596 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:01:35,597 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:01:35,597 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:01:35,597 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:01:35,597 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:01:35,597 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:01:35,597 - __main__ - INFO - Pipeline for CodingAnalysisModule completed in 39.78s
2024-12-10 22:01:35,598 - __main__ - INFO - Completed Coding Analysis in 39.78s
2024-12-10 22:01:35,598 - __main__ - INFO - Converting coding results to theme format
2024-12-10 22:01:35,603 - __main__ - INFO - Coding to theme conversion completed
2024-12-10 22:01:35,603 - __main__ - INFO - Starting Theme Development Pipeline
2024-12-10 22:01:35,603 - __main__ - INFO - Starting pipeline with ThemedevelopmentAnalysisModule
2024-12-10 22:01:35,603 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:01:35,603 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:01:35,603 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:01:35,603 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:01:35,603 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:01:35,603 - src.core.contextual_vector_db - INFO - Vector database is already loaded. Skipping data loading.
2024-12-10 22:01:35,603 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:01:35,604 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_theme_development
2024-12-10 22:01:35,604 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_theme_development
2024-12-10 22:01:35,609 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.005s]
2024-12-10 22:01:35,612 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_theme_development [status:200 duration:0.002s]
2024-12-10 22:01:35,612 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_theme_development' already exists. Skipping creation.
2024-12-10 22:01:35,633 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.021s]
2024-12-10 22:01:35,650 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_refresh [status:200 duration:0.017s]
2024-12-10 22:01:35,650 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:01:35,650 - __main__ - INFO - Successfully indexed 5 documents in 0.04s
2024-12-10 22:01:35,650 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.05s
2024-12-10 22:01:35,650 - __main__ - INFO - Created Elasticsearch BM25 index in 0.05s
2024-12-10 22:01:35,650 - __main__ - INFO - Loading queries from data/input/input/queries_theme.json
2024-12-10 22:01:35,651 - src.data.data_loader - INFO - Loaded JSON file 'data/input/input/queries_theme.json' successfully with 32 entries.
2024-12-10 22:01:35,651 - __main__ - INFO - Loaded 32 queries
2024-12-10 22:01:35,651 - __main__ - INFO - Validating queries
2024-12-10 22:01:35,652 - src.processing.query_processor - INFO - Validated 32 transcripts out of 32 provided.
2024-12-10 22:01:35,652 - __main__ - INFO - Validated 32 queries
2024-12-10 22:01:35,652 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:01:35,652 - __main__ - INFO - Initializing optimizer for ThemedevelopmentAnalysisModule
2024-12-10 22:01:35,652 - __main__ - INFO - Initializing theme development optimizer
2024-12-10 22:01:36,235 - __main__ - INFO - Loaded theme training dataset: 1 samples
2024-12-10 22:01:36,244 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,254 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,262 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,270 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,278 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,284 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,291 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,297 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,304 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,310 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,316 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,322 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,329 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,335 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,341 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,347 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,354 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,359 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,366 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,371 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,378 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,383 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,390 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,396 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:01:36,397 - __main__ - INFO - Compiled optimized theme program in 0.16s
2024-12-10 22:01:36,398 - __main__ - INFO - Saved optimized theme program to data/optimized/optimized_theme_program.json
2024-12-10 22:01:36,398 - __main__ - INFO - Theme optimizer initialization completed in 0.75s
2024-12-10 22:01:36,398 - __main__ - INFO - Initialized optimizer in 0.75s
2024-12-10 22:01:36,398 - __main__ - INFO - Initializing ThemedevelopmentAnalysisModule
2024-12-10 22:01:36,401 - __main__ - INFO - Initialized ThemedevelopmentAnalysisModule with assertions
2024-12-10 22:01:36,401 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:01:36,401 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_theme_development.json'.
2024-12-10 22:01:36,401 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:01:36,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:01:36,778 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we are going to try our hardest and believe we will succeed at making our models better and better and better...     '.
2024-12-10 22:01:36,787 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:01:36,792 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:01:36,793 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:01:36,793 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:01:36,793 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better...     ': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:01:36,793 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.39s
2024-12-10 22:01:36,803 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:01:36,804 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:01:37,521 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:01:37,522 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.72s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:01:37,522 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.12s. Returned 5 results
2024-12-10 22:01:37,522 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='we are going to try our hardest and believe we will succeed at making our models better and better a...', Keywords=['improvement', 'believe', 'models', 'better'], Codes=3
2024-12-10 22:01:37,522 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:01:37,536 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:01:47,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:01:47,372 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:01:47,379 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:01,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:01,509 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:01,519 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:10,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:10,012 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:10,016 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:02:10,019 - src.processing.query_processor - WARNING - No themes developed for quotation: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:02:10,019 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:02:10,020 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...'
2024-12-10 22:02:10,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:02:10,529 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do...     '.
2024-12-10 22:02:10,540 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:02:10,549 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:02:10,549 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:02:10,549 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:02:10,550 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do...     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:02:10,550 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.53s
2024-12-10 22:02:10,558 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:02:10,558 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...' with 5 documents
2024-12-10 22:02:11,243 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:02:11,247 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 0.9996, Bottom score: 0.0006
2024-12-10 22:02:11,247 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.23s. Returned 5 results
2024-12-10 22:02:11,248 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...', Keywords=['reasoning', 'unlock', 'improvement'], Codes=3
2024-12-10 22:02:11,248 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:02:11,270 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:20,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:20,048 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:20,061 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:30,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:30,386 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:30,397 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:39,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:39,765 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:39,771 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:02:39,773 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...'
2024-12-10 22:02:39,774 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:02:39,774 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...'
2024-12-10 22:02:40,266 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:02:40,278 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before     '.
2024-12-10 22:02:40,301 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.018s]
2024-12-10 22:02:40,304 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:02:40,305 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:02:40,305 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:02:40,305 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before     ': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:02:40,305 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.53s
2024-12-10 22:02:40,314 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:02:40,314 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...' with 5 documents
2024-12-10 22:02:41,111 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:02:41,113 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.80s. Top score: 0.9999, Bottom score: 0.0010
2024-12-10 22:02:41,113 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.34s. Returned 5 results
2024-12-10 22:02:41,113 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there will be many trillions of dollars of market cap that gets created new market cap that gets cre...', Keywords=['market cap', 'AI innovations', 'impossible products'], Codes=2
2024-12-10 22:02:41,113 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:02:41,136 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:47,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:47,678 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:47,689 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:02:53,932 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:02:53,937 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:02:53,945 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:02,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:02,744 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:02,751 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:03:02,753 - src.processing.query_processor - WARNING - No themes developed for quotation: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...'
2024-12-10 22:03:02,753 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:03:02,753 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...'
2024-12-10 22:03:03,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:03:03,674 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to do     '.
2024-12-10 22:03:03,687 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:03:03,694 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:03:03,695 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:03:03,695 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:03:03,695 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think people have like internalized the rate of Improvement and have heard us on what we intend to do     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:03:03,695 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.94s
2024-12-10 22:03:03,707 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:03:03,707 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...' with 5 documents
2024-12-10 22:03:04,889 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:03:04,892 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.18s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:03:04,892 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.14s. Returned 5 results
2024-12-10 22:03:04,892 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think people have like internalized the rate of Improvement and have heard us on what we intend to...', Keywords=['internalized', 'rate of improvement', 'commitment'], Codes=3
2024-12-10 22:03:04,893 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:03:04,919 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:13,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:13,757 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:13,769 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:21,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:21,688 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:21,699 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:29,566 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:29,570 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:29,576 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:03:29,579 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...'
2024-12-10 22:03:29,579 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:03:29,580 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...'
2024-12-10 22:03:30,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:03:30,158 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed     '.
2024-12-10 22:03:30,172 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:03:30,178 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:03:30,178 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:03:30,178 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:03:30,178 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed     ': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:03:30,178 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.60s
2024-12-10 22:03:30,190 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:03:30,190 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...' with 5 documents
2024-12-10 22:03:30,899 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:03:30,902 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:03:30,902 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.32s. Returned 5 results
2024-12-10 22:03:30,903 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there will be9 trillion dollars of value created did every single year which will offset the $9 tril...', Keywords=['value creation', 'capax', 'AI models'], Codes=2
2024-12-10 22:03:30,903 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:03:30,930 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:39,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:39,686 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:39,697 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:47,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:47,556 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:47,565 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:03:53,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:03:53,857 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:03:53,862 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:03:53,863 - src.processing.query_processor - WARNING - No themes developed for quotation: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...'
2024-12-10 22:03:53,863 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:03:53,864 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...'
2024-12-10 22:03:54,657 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:03:54,667 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want     '.
2024-12-10 22:03:54,678 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:03:54,684 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.004s]
2024-12-10 22:03:54,684 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:03:54,684 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:03:54,684 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want     ': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:03:54,685 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.82s
2024-12-10 22:03:54,695 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:03:54,695 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...' with 5 documents
2024-12-10 22:03:55,390 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:03:55,393 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9991, Bottom score: 0.0000
2024-12-10 22:03:55,393 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.53s. Returned 5 results
2024-12-10 22:03:55,393 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='think about how much economic value gets unlocked for the world if anybody can just describe like a ...', Keywords=['economic value', 'software needs', 'transformative potential', 'reasoning'], Codes=3
2024-12-10 22:03:55,394 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:03:55,421 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:05,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:06,004 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:06,013 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:18,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:18,205 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:18,217 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:25,576 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:25,582 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:25,589 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:04:25,592 - src.processing.query_processor - WARNING - No themes developed for quotation: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...'
2024-12-10 22:04:25,592 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:04:25,593 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's clearly a really important place in the Eos system for open source models     ...'
2024-12-10 22:04:26,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:04:26,308 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there's clearly a really important place in the Eos system for open source models     '.
2024-12-10 22:04:26,325 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.016s]
2024-12-10 22:04:26,330 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.004s]
2024-12-10 22:04:26,330 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:04:26,330 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:04:26,330 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's clearly a really important place in the Eos system for open source models     ': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:04:26,330 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.74s
2024-12-10 22:04:26,339 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:04:26,339 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's clearly a really important place in the Eos system for open source models     ...' with 5 documents
2024-12-10 22:04:27,028 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:04:27,032 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:04:27,032 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.44s. Returned 5 results
2024-12-10 22:04:27,033 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there's clearly a really important place in the Eos system for open source models...', Keywords=['open source models', 'Eos system', 'transformative potential'], Codes=3
2024-12-10 22:04:27,033 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:04:27,053 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:34,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:34,804 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:34,812 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:42,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:42,145 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:42,155 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:50,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:50,782 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:50,786 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:04:50,788 - src.processing.query_processor - WARNING - No themes developed for quotation: 'there's clearly a really important place in the Eos system for open source models...'
2024-12-10 22:04:50,788 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:04:50,788 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...'
2024-12-10 22:04:51,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:04:51,296 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker     '.
2024-12-10 22:04:51,310 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.013s]
2024-12-10 22:04:51,315 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:04:51,316 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:04:51,316 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:04:51,316 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker     ': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:04:51,316 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.53s
2024-12-10 22:04:51,327 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:04:51,327 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...' with 5 documents
2024-12-10 22:04:51,991 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:04:51,994 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.67s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:04:51,994 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.21s. Returned 5 results
2024-12-10 22:04:51,994 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the category I think though is more interesting is not the one that people normally talk about where...', Keywords=['smart senior co-worker', 'transformative potential', 'complex tasks'], Codes=2
2024-12-10 22:04:51,995 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:04:52,022 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:04:59,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:04:59,170 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:04:59,181 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:05:08,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:05:08,497 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:05:08,508 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:05:19,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:05:19,623 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:05:19,629 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:05:19,632 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the category I think though is more interesting is not the one that people normally talk about where...'
2024-12-10 22:05:19,632 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:05:19,632 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...'
2024-12-10 22:05:20,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:05:20,233 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created     '.
2024-12-10 22:05:20,246 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:05:20,255 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.008s]
2024-12-10 22:05:20,255 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:05:20,255 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:05:20,256 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created     ': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:05:20,256 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.62s
2024-12-10 22:05:20,266 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:05:20,266 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...' with 5 documents
2024-12-10 22:05:20,935 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:05:20,939 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.67s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:05:20,940 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.31s. Returned 5 results
2024-12-10 22:05:20,940 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='reasoning is our current most important area of focus I think this is what unlocks the next like mas...', Keywords=['reasoning', 'economic value', 'transformation'], Codes=3
2024-12-10 22:05:20,940 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:05:20,962 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:05:29,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:05:29,278 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:05:29,285 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:05:37,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:05:37,264 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:05:37,271 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:05:45,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:05:45,463 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:05:45,469 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:05:45,471 - src.processing.query_processor - WARNING - No themes developed for quotation: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...'
2024-12-10 22:05:45,471 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:05:45,472 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair     ...'
2024-12-10 22:05:46,143 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:05:46,153 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair     '.
2024-12-10 22:05:46,164 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:05:46,170 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:05:46,171 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:05:46,171 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:05:46,171 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the actual like Revenue we can make from a model I think justifies the investment to be fair     ': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:05:46,172 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.70s
2024-12-10 22:05:46,184 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:05:46,184 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair     ...' with 5 documents
2024-12-10 22:05:46,919 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:05:46,922 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:05:46,922 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.45s. Returned 5 results
2024-12-10 22:05:46,923 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the actual like Revenue we can make from a model I think justifies the investment to be fair...', Keywords=['Revenue', 'Investment', 'AI Models'], Codes=2
2024-12-10 22:05:46,923 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:05:46,947 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:05:54,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:05:54,382 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:05:54,391 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:06:01,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:06:01,236 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:06:01,245 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:06:08,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:06:08,406 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:06:08,412 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:06:08,413 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the actual like Revenue we can make from a model I think justifies the investment to be fair...'
2024-12-10 22:06:08,413 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:06:08,413 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...'
2024-12-10 22:06:08,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:06:08,964 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works     '.
2024-12-10 22:06:08,978 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:06:08,983 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.004s]
2024-12-10 22:06:08,983 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:06:08,984 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:06:08,984 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works     ': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:06:08,984 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.57s
2024-12-10 22:06:08,993 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:06:08,993 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...' with 5 documents
2024-12-10 22:06:09,748 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:06:09,752 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 0.9974, Bottom score: 0.0000
2024-12-10 22:06:09,752 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.34s. Returned 5 results
2024-12-10 22:06:09,752 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...', Keywords=['Transformer', 'innovation', 'replicate', 'culture', 'human talent'], Codes=3
2024-12-10 22:06:09,753 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:06:09,778 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:06:18,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:06:18,710 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:06:18,720 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:06:28,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:06:28,562 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:06:28,575 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:06:50,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:06:50,108 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:06:50,114 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:06:50,118 - src.processing.query_processor - WARNING - No themes developed for quotation: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...'
2024-12-10 22:06:50,118 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:06:50,118 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the repeated ability to go off and do something new and totally unproven     ...'
2024-12-10 22:06:51,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:06:51,131 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the repeated ability to go off and do something new and totally unproven     '.
2024-12-10 22:06:51,148 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.015s]
2024-12-10 22:06:51,154 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:06:51,154 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:06:51,154 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:06:51,154 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the repeated ability to go off and do something new and totally unproven     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:06:51,154 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 1.04s
2024-12-10 22:06:51,163 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:06:51,163 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the repeated ability to go off and do something new and totally unproven     ...' with 5 documents
2024-12-10 22:06:52,353 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:06:52,355 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.19s. Top score: 0.9962, Bottom score: 0.0000
2024-12-10 22:06:52,356 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.24s. Returned 5 results
2024-12-10 22:06:52,356 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the repeated ability to go off and do something new and totally unproven...', Keywords=['innovation', 'unproven', 'ability'], Codes=2
2024-12-10 22:06:52,356 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:06:52,376 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:07:01,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:07:01,991 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:07:02,002 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:07:11,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:07:11,235 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:07:11,245 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:07:22,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:07:22,158 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:07:22,165 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:07:22,167 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the repeated ability to go off and do something new and totally unproven...'
2024-12-10 22:07:22,167 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:07:22,168 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture   ...'
2024-12-10 22:07:22,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:07:22,824 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture     '.
2024-12-10 22:07:22,837 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:07:22,843 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:07:22,844 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:07:22,844 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:07:22,844 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's a huge amount of wasted human talent because this is not an organization style or culture     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:07:22,844 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.68s
2024-12-10 22:07:22,856 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:07:22,856 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture   ...' with 5 documents
2024-12-10 22:07:23,586 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:07:23,589 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:07:23,589 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.42s. Returned 5 results
2024-12-10 22:07:23,589 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there's a huge amount of wasted human talent because this is not an organization style or culture...', Keywords=['wasted human talent', 'organization style', 'innovation'], Codes=3
2024-12-10 22:07:23,590 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:07:23,616 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:07:32,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:07:32,912 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:07:32,921 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:07:42,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:07:42,432 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:07:42,443 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:07:49,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:07:49,397 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:07:49,402 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:07:49,406 - src.processing.query_processor - WARNING - No themes developed for quotation: 'there's a huge amount of wasted human talent because this is not an organization style or culture...'
2024-12-10 22:07:49,406 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:07:49,406 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     ...'
2024-12-10 22:07:50,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:07:50,120 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     '.
2024-12-10 22:07:50,132 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:07:50,138 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:07:50,139 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:07:50,139 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:07:50,139 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:07:50,139 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.73s
2024-12-10 22:07:50,146 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:07:50,146 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     ...' with 5 documents
2024-12-10 22:07:50,796 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:07:50,800 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.65s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:07:50,800 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.39s. Returned 5 results
2024-12-10 22:07:50,800 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I hope it'll get us much better than we are now at helping get everyone to their Max potential...', Keywords=['Max potential', 'innovation', 'unlock potential'], Codes=3
2024-12-10 22:07:50,801 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:07:50,821 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:01,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:01,307 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:01,312 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:08,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:08,535 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:08,544 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:15,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:15,602 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:15,608 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:08:15,609 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential...'
2024-12-10 22:08:15,609 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:08:15,609 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...'
2024-12-10 22:08:16,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:08:16,172 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do.     '.
2024-12-10 22:08:16,184 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:08:16,191 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:08:16,192 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:08:16,192 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:08:16,192 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do.     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:08:16,192 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.58s
2024-12-10 22:08:16,199 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:08:16,199 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...' with 5 documents
2024-12-10 22:08:16,937 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:08:16,941 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:08:16,942 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.33s. Returned 5 results
2024-12-10 22:08:16,942 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I badly underappreciated the amount of work it took to be able to like keep charging at the next big...', Keywords=['underappreciated', 'work', 'next big step', 'neglecting'], Codes=2
2024-12-10 22:08:16,942 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:08:16,960 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:22,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:22,700 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:22,713 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:27,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:27,885 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:27,895 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:33,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:33,325 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:33,329 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:08:33,331 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...'
2024-12-10 22:08:33,331 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:08:33,331 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     ...'
2024-12-10 22:08:33,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:08:33,936 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     '.
2024-12-10 22:08:33,948 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:08:33,954 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:08:33,954 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:08:33,954 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:08:33,954 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:08:33,954 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.62s
2024-12-10 22:08:33,963 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:08:33,963 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     ...' with 5 documents
2024-12-10 22:08:37,776 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:08:37,778 - src.retrieval.reranking - INFO - Cohere reranking completed in 3.82s. Top score: 0.9996, Bottom score: 0.0000
2024-12-10 22:08:37,779 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 4.45s. Returned 5 results
2024-12-10 22:08:37,779 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there was either no playbook for this or someone had a secret Playbook they didn't give me....', Keywords=['playbook', 'innovation', 'challenges', 'unproven ideas', 'human talent'], Codes=3
2024-12-10 22:08:37,779 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:08:37,800 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:45,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:45,887 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:45,898 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:08:53,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:08:53,737 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:08:53,749 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:09:03,655 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:09:03,663 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:09:03,669 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:09:03,671 - src.processing.query_processor - WARNING - No themes developed for quotation: 'there was either no playbook for this or someone had a secret Playbook they didn't give me....'
2024-12-10 22:09:03,671 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:09:03,671 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     ...'
2024-12-10 22:09:04,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:09:04,670 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     '.
2024-12-10 22:09:04,678 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:09:04,681 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.002s]
2024-12-10 22:09:04,682 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:09:04,682 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:09:04,682 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:09:04,683 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 1.01s
2024-12-10 22:09:04,694 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:09:04,694 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     ...' with 5 documents
2024-12-10 22:09:05,478 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:09:05,481 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.79s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:09:05,481 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.81s. Returned 5 results
2024-12-10 22:09:05,481 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='you should hire incredibly young people under 30 and that is what Peter teal taught him....', Keywords=['young people', 'innovation', 'talent'], Codes=2
2024-12-10 22:09:05,482 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:09:05,506 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:09:12,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:09:12,446 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:09:12,457 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:09:19,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:09:19,563 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:09:19,573 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:09:29,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:09:29,889 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:09:29,898 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:09:29,901 - src.processing.query_processor - WARNING - No themes developed for quotation: 'you should hire incredibly young people under 30 and that is what Peter teal taught him....'
2024-12-10 22:09:29,901 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:09:29,902 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...'
2024-12-10 22:09:30,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:09:30,485 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built.     '.
2024-12-10 22:09:30,497 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:09:30,504 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:09:30,505 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:09:30,505 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:09:30,505 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built.     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:09:30,505 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.60s
2024-12-10 22:09:30,516 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:09:30,516 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...' with 5 documents
2024-12-10 22:09:31,226 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:09:31,230 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:09:31,230 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.33s. Returned 5 results
2024-12-10 22:09:31,230 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='when you're like designing some of the most complex and massively expensive computer systems that Hu...', Keywords=['designing', 'complex', 'expensive', 'computer systems', 'innovation'], Codes=2
2024-12-10 22:09:31,231 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:09:31,256 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:09:48,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:09:48,375 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:09:48,385 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:09:56,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:09:56,663 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:09:56,674 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:10:02,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:10:02,960 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:10:02,966 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:10:02,969 - src.processing.query_processor - WARNING - No themes developed for quotation: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...'
2024-12-10 22:10:02,969 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:10:02,969 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you want both.     ...'
2024-12-10 22:10:03,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:10:03,558 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'you want both.     '.
2024-12-10 22:10:03,575 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.014s]
2024-12-10 22:10:03,579 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.004s]
2024-12-10 22:10:03,580 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:10:03,580 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:10:03,580 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you want both.     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:10:03,580 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.61s
2024-12-10 22:10:03,589 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:10:03,589 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you want both.     ...' with 5 documents
2024-12-10 22:10:06,137 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:10:06,140 - src.retrieval.reranking - INFO - Cohere reranking completed in 2.55s. Top score: 0.9723, Bottom score: 0.0000
2024-12-10 22:10:06,140 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 3.17s. Returned 5 results
2024-12-10 22:10:06,140 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='you want both....', Keywords=['innovation', 'replication', 'culture'], Codes=2
2024-12-10 22:10:06,141 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:10:06,166 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:10:14,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:10:14,440 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:10:14,449 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:10:23,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:10:23,245 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:10:23,256 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:10:33,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:10:33,351 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:10:33,357 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:10:33,358 - src.processing.query_processor - WARNING - No themes developed for quotation: 'you want both....'
2024-12-10 22:10:33,358 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:10:33,359 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...'
2024-12-10 22:10:34,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:10:34,147 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value     '.
2024-12-10 22:10:34,154 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:10:34,158 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:10:34,158 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:10:34,159 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:10:34,159 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value     ': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_3]
2024-12-10 22:10:34,159 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.80s
2024-12-10 22:10:34,170 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:10:34,170 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...' with 5 documents
2024-12-10 22:10:34,879 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:10:34,881 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:10:34,882 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.52s. Returned 5 results
2024-12-10 22:10:34,882 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='inexperience does not inherently mean not valuable and there are incredibly high potential people at...', Keywords=['inexperience', 'potential', 'value'], Codes=2
2024-12-10 22:10:34,882 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:10:34,906 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:10:44,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:10:44,438 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:10:44,446 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:10:54,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:10:54,699 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:10:54,708 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:11:04,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:11:04,164 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:11:04,167 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:11:04,168 - src.processing.query_processor - WARNING - No themes developed for quotation: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...'
2024-12-10 22:11:04,168 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:11:04,168 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...'
2024-12-10 22:11:04,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:11:04,712 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World     '.
2024-12-10 22:11:04,723 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:11:04,731 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:11:04,731 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:11:04,731 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:11:04,731 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World     ': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:11:04,731 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.56s
2024-12-10 22:11:04,745 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:11:04,745 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...' with 5 documents
2024-12-10 22:11:06,188 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:11:06,190 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.45s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:11:06,191 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.02s. Returned 5 results
2024-12-10 22:11:06,191 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think developers use multiple models most of the time and I'm not sure how that's all going to evo...', Keywords=['multiple models', 'AG genified World', 'collaboration', 'reasoning capabilities'], Codes=3
2024-12-10 22:11:06,192 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:11:06,216 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:11:16,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:11:16,381 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:11:16,393 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:11:25,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:11:25,770 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:11:25,779 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:11:35,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:11:35,166 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:11:35,172 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:11:35,175 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...'
2024-12-10 22:11:35,175 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:11:35,175 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing   ...'
2024-12-10 22:11:35,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:11:35,693 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing     '.
2024-12-10 22:11:35,705 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:11:35,714 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.008s]
2024-12-10 22:11:35,715 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:11:35,715 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:11:35,715 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing     ': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1]
2024-12-10 22:11:35,715 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.54s
2024-12-10 22:11:35,728 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:11:35,728 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing   ...' with 5 documents
2024-12-10 22:11:36,769 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:11:36,772 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.04s. Top score: 1.0000, Bottom score: 0.0127
2024-12-10 22:11:36,773 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.60s. Returned 5 results
2024-12-10 22:11:36,773 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='we have a lot of people here who are excited to build AGI and that that's a very motivating thing...', Keywords=['AGI', 'motivation', 'collaboration'], Codes=2
2024-12-10 22:11:36,774 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:11:36,799 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:11:44,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:11:44,609 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:11:44,615 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:12:06,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:12:06,021 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:12:06,031 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:12:16,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:12:16,747 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:12:16,756 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:12:16,758 - src.processing.query_processor - WARNING - No themes developed for quotation: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing...'
2024-12-10 22:12:16,759 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:12:16,759 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions     ...'
2024-12-10 22:12:17,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:12:17,698 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the heaviest things in life are not iron or gold but unmade decisions     '.
2024-12-10 22:12:17,710 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:12:17,715 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:12:17,716 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:12:17,716 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:12:17,716 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the heaviest things in life are not iron or gold but unmade decisions     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:12:17,716 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.96s
2024-12-10 22:12:17,728 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:12:17,728 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions     ...' with 5 documents
2024-12-10 22:12:18,627 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:12:18,631 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.90s. Top score: 0.9963, Bottom score: 0.0000
2024-12-10 22:12:18,631 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.87s. Returned 5 results
2024-12-10 22:12:18,631 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the heaviest things in life are not iron or gold but unmade decisions...', Keywords=['decisions', 'collaboration', 'AI development'], Codes=2
2024-12-10 22:12:18,632 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:12:18,657 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:12:28,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:12:28,539 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:12:28,548 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:12:40,373 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:12:40,378 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:12:40,389 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:12:48,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:12:48,570 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:12:48,576 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:12:48,578 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the heaviest things in life are not iron or gold but unmade decisions...'
2024-12-10 22:12:48,578 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:12:48,579 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...'
2024-12-10 22:12:49,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:12:49,101 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way     '.
2024-12-10 22:12:49,116 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.014s]
2024-12-10 22:12:49,123 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:12:49,124 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:12:49,124 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:12:49,124 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:12:49,124 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.55s
2024-12-10 22:12:49,133 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:12:49,133 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...' with 5 documents
2024-12-10 22:12:54,415 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:12:54,418 - src.retrieval.reranking - INFO - Cohere reranking completed in 5.29s. Top score: 0.9999, Bottom score: 0.0002
2024-12-10 22:12:54,418 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 5.84s. Returned 5 results
2024-12-10 22:12:54,418 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think the wrong way to do that is to have one person you lean on for everything and the right way ...', Keywords=['collaboration', 'decision-making', 'diversity'], Codes=2
2024-12-10 22:12:54,419 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:12:54,445 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:01,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:01,548 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:01,558 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:10,401 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:10,418 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:10,432 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:17,179 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:17,183 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:17,188 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:13:17,190 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...'
2024-12-10 22:13:17,190 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:13:17,191 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...'
2024-12-10 22:13:17,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:13:17,678 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before     '.
2024-12-10 22:13:17,691 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:13:17,698 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:13:17,698 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:13:17,699 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:13:17,699 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before     ': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:13:17,699 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.51s
2024-12-10 22:13:17,711 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:13:17,711 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...' with 5 documents
2024-12-10 22:13:18,439 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:13:18,443 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:13:18,443 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.25s. Returned 5 results
2024-12-10 22:13:18,443 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...', Keywords=['ecosystem complexity', 'fractal scan', 'collaboration', 'integrated systems'], Codes=3
2024-12-10 22:13:18,444 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:13:18,467 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:27,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:27,349 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:27,359 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:36,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:36,230 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:36,240 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:45,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:45,898 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:45,902 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:13:45,904 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...'
2024-12-10 22:13:45,904 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:13:45,904 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...'
2024-12-10 22:13:46,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:13:46,744 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'it was very like one of the defining things about the internet Revolution was it was actually really easy to get started     '.
2024-12-10 22:13:46,756 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:13:46,763 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:13:46,763 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:13:46,763 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:13:46,763 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'it was very like one of the defining things about the internet Revolution was it was actually really easy to get started     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:13:46,763 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.86s
2024-12-10 22:13:46,772 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:13:46,772 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...' with 5 documents
2024-12-10 22:13:48,324 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:13:48,327 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.55s. Top score: 0.9983, Bottom score: 0.0000
2024-12-10 22:13:48,327 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.42s. Returned 5 results
2024-12-10 22:13:48,327 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='it was very like one of the defining things about the internet Revolution was it was actually really...', Keywords=['internet Revolution', 'easy to get started', 'AI development'], Codes=2
2024-12-10 22:13:48,328 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:13:48,348 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:13:55,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:13:55,723 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:13:55,734 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:14:02,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:14:02,654 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:14:02,662 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:14:14,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:14:14,527 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:14:14,532 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:14:14,533 - src.processing.query_processor - WARNING - No themes developed for quotation: 'it was very like one of the defining things about the internet Revolution was it was actually really...'
2024-12-10 22:14:14,533 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:14:14,534 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...'
2024-12-10 22:14:15,125 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:14:15,135 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties     '.
2024-12-10 22:14:15,147 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:14:15,155 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:14:15,156 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:14:15,156 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:14:15,156 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties     ': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:14:15,156 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.62s
2024-12-10 22:14:15,165 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:14:15,165 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...' with 5 documents
2024-12-10 22:14:15,958 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:14:15,961 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.80s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:14:15,961 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.43s. Returned 5 results
2024-12-10 22:14:15,961 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the one I like the most caveat by my earlier comment that I don't think people should be doing this ...', Keywords=['discovery', 'scaling properties', 'analogies'], Codes=3
2024-12-10 22:14:15,961 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:14:15,978 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:14:26,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:14:26,811 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:14:26,817 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:14:39,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:14:39,884 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:14:39,894 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:15:08,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:15:08,331 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:15:08,333 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:15:08,334 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...'
2024-12-10 22:15:08,334 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:15:08,334 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...'
2024-12-10 22:15:09,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:15:09,087 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data     '.
2024-12-10 22:15:09,101 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.013s]
2024-12-10 22:15:09,107 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:15:09,108 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:15:09,108 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:15:09,108 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data     ': [interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:15:09,108 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.77s
2024-12-10 22:15:09,117 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:15:09,117 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...' with 5 documents
2024-12-10 22:15:09,848 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:15:09,851 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9999, Bottom score: 0.0001
2024-12-10 22:15:09,851 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.52s. Returned 5 results
2024-12-10 22:15:09,851 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='something about an AI that can understand your whole life doesn't have to like literally be infinite...', Keywords=['AI', 'understand', 'data', 'enhance'], Codes=2
2024-12-10 22:15:09,851 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:15:09,875 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:15:19,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:15:19,744 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:15:19,754 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:15:31,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:15:31,301 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:15:31,310 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:15:40,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:15:40,375 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:15:40,384 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:15:40,387 - src.processing.query_processor - WARNING - No themes developed for quotation: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...'
2024-12-10 22:15:40,389 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:15:40,390 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...'
2024-12-10 22:15:40,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:15:40,914 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I could name     '.
2024-12-10 22:15:40,930 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.014s]
2024-12-10 22:15:40,937 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:15:40,937 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:15:40,937 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:15:40,937 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think to really have do what they've done and built I thought about like a bunch of researchers I could name     ': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1]
2024-12-10 22:15:40,937 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.55s
2024-12-10 22:15:40,947 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:15:40,947 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...' with 5 documents
2024-12-10 22:15:41,608 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:15:41,611 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.66s. Top score: 0.9994, Bottom score: 0.0000
2024-12-10 22:15:41,611 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.22s. Returned 5 results
2024-12-10 22:15:41,611 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think to really have do what they've done and built I thought about like a bunch of researchers I ...', Keywords=['AI', 'researchers', 'leadership'], Codes=2
2024-12-10 22:15:41,612 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:15:41,634 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:15:48,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:15:48,431 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:15:48,440 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:15:55,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:15:55,700 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:15:55,709 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:16:02,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:16:02,665 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:16:02,671 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:16:02,673 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...'
2024-12-10 22:16:02,673 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:16:02,674 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think that product is a weakness of mine in general     ...'
2024-12-10 22:16:03,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:16:03,254 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I think that product is a weakness of mine in general     '.
2024-12-10 22:16:03,266 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:16:03,274 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:16:03,275 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:16:03,275 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:16:03,275 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think that product is a weakness of mine in general     ': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1]
2024-12-10 22:16:03,275 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.60s
2024-12-10 22:16:03,285 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:16:03,285 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think that product is a weakness of mine in general     ...' with 5 documents
2024-12-10 22:16:03,965 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:16:03,969 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.68s. Top score: 0.9990, Bottom score: 0.0000
2024-12-10 22:16:03,969 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.30s. Returned 5 results
2024-12-10 22:16:03,969 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think that product is a weakness of mine in general...', Keywords=['product', 'weakness', 'leadership'], Codes=2
2024-12-10 22:16:03,970 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:16:03,990 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:16:12,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:16:12,023 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:16:12,032 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:16:25,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:16:25,606 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:16:25,615 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:16:42,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:16:42,502 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:16:42,510 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:16:42,512 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I think that product is a weakness of mine in general...'
2024-12-10 22:16:42,512 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:16:42,512 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...'
2024-12-10 22:16:43,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:16:43,328 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years     '.
2024-12-10 22:16:43,338 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:16:43,343 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.004s]
2024-12-10 22:16:43,343 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:16:43,343 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:16:43,343 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years     ': [interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:16:43,344 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.83s
2024-12-10 22:16:43,352 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:16:43,352 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...' with 5 documents
2024-12-10 22:16:44,034 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:16:44,037 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:16:44,037 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.53s. Returned 5 results
2024-12-10 22:16:44,037 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...', Keywords=['Discovery', 'Physics', 'AI', 'Years'], Codes=3
2024-12-10 22:16:44,038 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:16:44,061 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:16:56,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:16:56,471 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:16:56,482 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:17:10,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:17:10,148 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:17:10,157 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:17:19,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:17:19,058 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:17:19,061 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type); Input should be a valid dictionary: codes, 2 (error type: dict_type)'})
2024-12-10 22:17:19,063 - src.processing.query_processor - WARNING - No themes developed for quotation: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...'
2024-12-10 22:17:19,063 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:17:19,063 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...'
2024-12-10 22:17:19,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2024-12-10 22:17:19,589 - src.core.contextual_vector_db - INFO - FAISS search returned 2000 results for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science     '.
2024-12-10 22:17:19,605 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.014s]
2024-12-10 22:17:19,614 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:17:19,614 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:17:19,614 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:17:19,614 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science     ': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_2]
2024-12-10 22:17:19,614 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.55s
2024-12-10 22:17:19,622 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:17:19,623 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...' with 5 documents
2024-12-10 22:17:20,280 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:17:20,283 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.66s. Top score: 0.9998, Bottom score: 0.0006
2024-12-10 22:17:20,283 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.22s. Returned 5 results
2024-12-10 22:17:20,283 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...', Keywords=['pace of progress', 'discovering new stuff', 'AI research', 'Science'], Codes=2
2024-12-10 22:17:20,284 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:17:20,308 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:17:30,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:17:30,947 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:17:30,957 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:17:38,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:17:38,104 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:17:38,115 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:17:45,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:17:45,530 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:17:45,534 - src.analysis.theme_development_module - ERROR - Error during theme development analysis: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
Traceback (most recent call last):
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/src/analysis/theme_development_module.py", line 45, in forward
    response = self.chain(
               ^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/utils/callback.py", line 202, in wrapper
    return fn(instance, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/primitives/program.py", line 24, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/amankumarshrestha/Documents/GitHub/Thematic-AnalysisG/.venv/lib/python3.12/site-packages/dspy/functional/functional.py", line 396, in forward
    raise ValueError(
ValueError: ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'general': 'Input should be a valid dictionary: codes, 0 (error type: dict_type); Input should be a valid dictionary: codes, 1 (error type: dict_type)'})
2024-12-10 22:17:45,535 - src.processing.query_processor - WARNING - No themes developed for quotation: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...'
2024-12-10 22:17:45,535 - src.processing.query_processor - INFO - Developed 0 themes for theme development.
2024-12-10 22:17:45,547 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_theme_development.json'
2024-12-10 22:17:45,547 - __main__ - INFO - Processed queries in 969.15s
2024-12-10 22:17:45,547 - __main__ - INFO - Starting evaluation
2024-12-10 22:17:45,547 - src.data.data_loader - ERROR - Error loading JSON file 'data/evaluation/evaluation_set_theme.jsonl': File does not exist.
2024-12-10 22:17:45,547 - __main__ - INFO - Loaded 0 evaluation queries
2024-12-10 22:17:45,547 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:17:45,547 - src.evaluation.evaluation - INFO - Starting evaluation of 0 queries.
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Starting evaluation of 0 queries.
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:17:45,548 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Starting evaluation of 0 queries.
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:17:45,549 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:17:45,549 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:17:45,549 - __main__ - INFO - Pipeline for ThemedevelopmentAnalysisModule completed in 969.95s
2024-12-10 22:17:45,549 - __main__ - INFO - Completed Theme Development in 969.95s
2024-12-10 22:17:45,549 - __main__ - INFO - All pipeline stages completed successfully in 1076.63s
2024-12-10 22:17:45,551 - __main__ - INFO - Pipeline execution completed successfully
2024-12-10 22:17:45,551 - __main__ - INFO - Thematic Analysis Pipeline execution finished
2024-12-10 22:24:19,412 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:19,471 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:19,476 - root - WARNING - 	*** Since DSPy 2.5.16+, TypedPredictors are now deprecated, underperform, and are about to be removed! ***
Please use standard predictors, e.g. dspy.Predict and dspy.ChainOfThought.
They now support type annotations and other features of TypedPredictors and tend to work much better out of the box.
Please let us know if you face any issues: https://github.com/stanfordnlp/dspy/issues
2024-12-10 22:24:19,476 - src.analysis.metrics - INFO - Comprehensive Assessment DSPy module initialized successfully.
2024-12-10 22:24:19,478 - src.processing.answer_generator - INFO - Unoptimized DSPy module initialized successfully.
2024-12-10 22:24:19,482 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:20,656 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:20,666 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:20,669 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:20,672 - root - INFO - Logging configuration loaded from config/logging_config.yaml
2024-12-10 22:24:20,672 - __main__ - INFO - Launching Thematic Analysis Pipeline
2024-12-10 22:24:20,672 - __main__ - INFO - Initializing ThematicAnalysisPipeline
2024-12-10 22:24:20,678 - __main__ - INFO - ThematicAnalysisPipeline instance created with ContextualVectorDB initialized
2024-12-10 22:24:20,678 - __main__ - INFO - Starting Thematic Analysis Pipeline
2024-12-10 22:24:20,678 - __main__ - INFO - Starting Standard Quotation Extraction Pipeline
2024-12-10 22:24:20,678 - __main__ - INFO - Starting pipeline with EnhancedQuotationModule
2024-12-10 22:24:20,678 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:24:20,678 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:24:20,679 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:24:20,679 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:24:20,679 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:24:20,679 - src.core.contextual_vector_db - INFO - Loading vector database and FAISS index from disk.
2024-12-10 22:24:20,679 - src.core.contextual_vector_db - INFO - Vector database metadata loaded from './data/contextual_db/contextual_vector_db.pkl' with 5 entries.
2024-12-10 22:24:20,680 - src.core.contextual_vector_db - INFO - FAISS index loaded from './data/contextual_db/faiss_index.bin' with 5 vectors.
2024-12-10 22:24:20,680 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:24:20,680 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_standard_quotation
2024-12-10 22:24:20,680 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_standard_quotation
2024-12-10 22:24:20,703 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.023s]
2024-12-10 22:24:20,707 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_standard_quotation [status:200 duration:0.004s]
2024-12-10 22:24:20,707 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_standard_quotation' already exists. Skipping creation.
2024-12-10 22:24:20,734 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.026s]
2024-12-10 22:24:20,753 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_refresh [status:200 duration:0.019s]
2024-12-10 22:24:20,753 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:24:20,753 - __main__ - INFO - Successfully indexed 5 documents in 0.05s
2024-12-10 22:24:20,753 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.07s
2024-12-10 22:24:20,753 - __main__ - INFO - Created Elasticsearch BM25 index in 0.07s
2024-12-10 22:24:20,753 - __main__ - INFO - Loading queries from data/input/queries_quotation.json
2024-12-10 22:24:20,753 - src.data.data_loader - INFO - Loaded JSON file 'data/input/queries_quotation.json' successfully with 11 entries.
2024-12-10 22:24:20,753 - __main__ - INFO - Loaded 11 queries
2024-12-10 22:24:20,753 - __main__ - INFO - Validating queries
2024-12-10 22:24:20,755 - src.processing.query_processor - INFO - Validated 11 transcripts out of 11 provided.
2024-12-10 22:24:20,755 - __main__ - INFO - Validated 11 queries
2024-12-10 22:24:20,755 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:24:20,755 - __main__ - INFO - Initializing optimizer for EnhancedQuotationModule
2024-12-10 22:24:20,755 - __main__ - INFO - Initializing quotation selection optimizer
2024-12-10 22:24:21,380 - __main__ - INFO - Loaded quotation training dataset: 1 samples
2024-12-10 22:24:21,394 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,403 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,410 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,418 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,425 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,431 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,437 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,443 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,449 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,482 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,496 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,502 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,509 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,515 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,521 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,527 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,534 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,540 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,546 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,552 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,559 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,565 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,571 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,577 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:21,578 - __main__ - INFO - Compiled optimized quotation program in 0.20s
2024-12-10 22:24:21,578 - __main__ - INFO - Saved optimized quotation program to data/optimized/optimized_quotation_program.json
2024-12-10 22:24:21,578 - __main__ - INFO - Quotation optimizer initialization completed in 0.82s
2024-12-10 22:24:21,578 - __main__ - INFO - Initialized optimizer in 0.82s
2024-12-10 22:24:21,578 - __main__ - INFO - Initializing EnhancedQuotationModule
2024-12-10 22:24:21,586 - __main__ - INFO - Initialized EnhancedQuotationModule with assertions
2024-12-10 22:24:21,586 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:24:21,586 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_quotation.json'.
2024-12-10 22:24:21,587 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:24:21,587 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:21,669 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.082s]
2024-12-10 22:24:21,717 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.042s]
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:21,718 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:21,718 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:21,718 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:21,718 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations
***
and I encourage people to be aligned with that ready to go [Music] hello everyone welcome to open AI Dev day
***
I am Harry stebbings of 20 VC and I am very very excited to interview
***
Sam ultman welcome Sam Sam thank you for letting me do this today with you thanks for doing now we have many many questions from the audience
***
and so I wanted to start with one when we look forward is the future of open AI more models like A1 or is it more larger models that we would maybe have expected of old how do we think about that
***
I mean we want to make things better across the board but this direction of reasoning models is of particular importance to us
***
I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do and the the ability for models like this is to for example contribute to new science uh help write a lot more very difficult code uh that I think can drive things forward to a significant degree
***
so you should expect rapid Improvement in the O Series of models and it's of great strategic importance to us another one that I thought was really important for us to touch on was when we look forward to open ai's future plans how do you think about developing no code tools for non-technical Founders to build and scale AI apps how do you think about that it'll get there for sure uh I I think the the first step will be tools that make people who know how to code well more productive
***
but eventually I think we can offer really high quality no code tools and already there's some out there that makes sense
***
but you can't you can't sort of in a no code way say I have like a full startup I want to build um that's going to take a while
***
so when we look at where we are in the stack today open AI sits in a certain place how far up the stack is open AI going go
***
I think it's a brilliant question but if you're spending a lot of time tuning your rag system is this a waste of time because open AI ultimately thinks I'll own this part of the application layer or is it not and how do you answer a Founder who has that question the general answer we try to give is we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future if on the other hand you build a company that benefits from the model getting better and better if you know an oracle told you today that 04 was going to be just absolutely incredible and do all of these things that right now feel impossible and you were happy about that
***
then you know maybe we're wrong but at least that's what we're going for and if instead you say okay there's this area where there are many but you pick one of the many areas where 01 preview underperforms and say I'm going to patch this and just barely get it to work then you're sort of assuming that the next turn of the model crank won't be as good as we think it will be and that is the general philosophical message we try to get out to startups like we we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today um will just be taken care of by Future generations
***
and you know I encourage people to be aligned with that we did an interview before with Brad and sorry it's not quite on schedule
***
but I think the show has always been successful when we kind of go a little bit off schedule there was this brilliant': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:24:21,718 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.13s
2024-12-10 22:24:21,727 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:21,727 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:24:23,176 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:23,184 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.46s. Top score: 1.0000, Bottom score: 0.9758
2024-12-10 22:24:23,184 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.60s. Returned 5 results
2024-12-10 22:24:23,185 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: we are going to try our hardest and believe we will succeed at making our models better and better a...
2024-12-10 22:24:23,214 - src.processing.query_processor - INFO - Selected 2 quotations for transcript chunk.
2024-12-10 22:24:23,215 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I f...'
2024-12-10 22:24:23,215 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:23,322 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.107s]
2024-12-10 22:24:23,361 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.023s]
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:23,362 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:23,362 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:23,362 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:23,362 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I felt a little bit guilty
***
but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and
***
so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever
***
and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do
***
so it's it no longer seems to be such an issue
***
but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people
***
you you said about the trillions of dollars of value to be created that
***
and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one um
***
but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:23,363 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.15s
2024-12-10 22:24:23,373 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:23,373 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I f...' with 5 documents
2024-12-10 22:24:24,247 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:24,250 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 0.9999, Bottom score: 0.0192
2024-12-10 22:24:24,250 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.04s. Returned 5 results
2024-12-10 22:24:24,250 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
yeah sorry for that uh but there was this brilliant kind of meme that came out of it
***
and I f...
2024-12-10 22:24:24,287 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:24:24,287 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:24:24,288 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:24,353 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.066s]
2024-12-10 22:24:24,393 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.032s]
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:24,393 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:24,393 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:24,393 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:24,393 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful
***
and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out
***
but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis
***
and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered
***
but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong
***
well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant
***
okay sure that's that's like a mild Le annoying thing to have to do
***
and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2]
2024-12-10 22:24:24,394 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.11s
2024-12-10 22:24:24,403 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:24,403 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:24:25,294 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:25,297 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.89s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:24:25,297 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.01s. Returned 5 results
2024-12-10 22:24:25,297 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
but if we use that as an example and imagine forward to towards it think about what think about ...
2024-12-10 22:24:25,337 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:24:25,337 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
really well and you know ping you at when it has questions but come back to you with like a grea...'
2024-12-10 22:24:25,337 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:25,402 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.065s]
2024-12-10 22:24:25,441 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.029s]
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:25,441 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:25,441 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:25,441 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:25,441 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun
***
but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure
***
but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it
***
it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one
***
but the actual like Revenue we can make from a model I think justifies the investment to be fair
***
uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable
***
then
***
yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality
***
spe
***
yeah
***
I hope it's just going to work
***
I mean it obviously takes some doing to get done
***
but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:25,442 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.11s
2024-12-10 22:24:25,451 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:25,451 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
really well and you know ping you at when it has questions but come back to you with like a grea...' with 5 documents
2024-12-10 22:24:27,251 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:27,254 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.80s. Top score: 1.0000, Bottom score: 0.0004
2024-12-10 22:24:27,255 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.92s. Returned 5 results
2024-12-10 22:24:27,255 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
really well and you know ping you at when it has questions but come back to you with like a grea...
2024-12-10 22:24:27,286 - src.processing.query_processor - INFO - Selected 2 quotations for transcript chunk.
2024-12-10 22:24:27,286 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:24:27,287 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:27,354 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.068s]
2024-12-10 22:24:27,394 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.028s]
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:24:27,394 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:27,394 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:27,394 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:27,394 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible
***
and so after after a research does something even if you don't know exactly how they did it
***
it's I say easy
***
but it's doable to go off and copy it
***
and you can see this in the replications of gp4
***
and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations
***
not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building
***
so I'd love way more of that and that is I think the thing most special about us
***
Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that
***
but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:27,394 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.11s
2024-12-10 22:24:27,403 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:27,403 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:24:28,257 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:28,261 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:24:28,261 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.97s. Returned 5 results
2024-12-10 22:24:28,261 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
and then you know there's everyone's favorite question which is what comes beyond the Transforme...
2024-12-10 22:24:28,305 - src.processing.query_processor - INFO - Selected 4 quotations for transcript chunk.
2024-12-10 22:24:28,305 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:24:28,305 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:28,380 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.074s]
2024-12-10 22:24:28,413 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.023s]
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:28,414 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:28,414 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:24:28,414 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:28,414 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate
***
so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this
***
but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway
***
and if so I'll deal with it later um Keith R boy uh did a talk
***
and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts
***
so you know I wasn't that young seem to work
***
okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced
***
I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young
***
but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort
***
then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both
***
uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like
***
***': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:28,414 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.11s
2024-12-10 22:24:28,423 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:28,423 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:24:29,865 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:29,866 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.44s. Top score: 1.0000, Bottom score: 0.0086
2024-12-10 22:24:29,866 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.56s. Returned 5 results
2024-12-10 22:24:29,866 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...
2024-12-10 22:24:29,884 - src.processing.query_processor - INFO - Selected 5 quotations for transcript chunk.
2024-12-10 22:24:29,884 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...'
2024-12-10 22:24:29,884 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:29,912 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.027s]
2024-12-10 22:24:29,923 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.006s]
2024-12-10 22:24:29,923 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:29,923 - src.retrieval.retrieval - INFO - Filtered 1 chunks due to missing metadata.
2024-12-10 22:24:29,923 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:29,923 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'somehow just not it's not quite the framing that resonates with me but the part of it that does is and one of the things that I feel most grateful about why combinator 4 is inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value and uh we as a society should bet on those people and it's a great thing I am going to return to some semblance of the schedule is I'm I'm really going to get told off but anthropics models have been sometimes cited as being better for coding Tas why is that do you think that's fair and how should developers think about when to pick open AI versus a different provider
***
yeah they have a model that is great at coding for sure uh
***': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:24:29,923 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:24:29,929 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:29,929 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...' with 5 documents
2024-12-10 22:24:30,642 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:30,644 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9999, Bottom score: 0.0031
2024-12-10 22:24:30,644 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.76s. Returned 5 results
2024-12-10 22:24:30,644 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: somehow just not it's not quite the framing that resonates with me but the part of it that does is a...
2024-12-10 22:24:30,675 - src.processing.query_processor - INFO - Selected 1 quotations for transcript chunk.
2024-12-10 22:24:30,676 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:24:30,676 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:30,739 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.062s]
2024-12-10 22:24:30,778 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.028s]
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:30,778 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:30,778 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:30,778 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:30,778 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um
***
but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long
***
and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out
***
but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time
***
but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing
***
and no one expects that to be easy and a straight line to success
***
but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side
***
you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us
***
can I ask a really weird one I had a great quote the other day
***
and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one
***
I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long
***
but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place
***
and then I don't feel like particularly likely
***
I can do better than somebody else would have done but I kind of have to make them
***
anyway
***
and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:24:30,779 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:24:30,790 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:30,790 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:24:31,614 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:31,617 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.83s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:24:31,617 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.94s. Returned 5 results
2024-12-10 22:24:31,618 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
and it's impressive work
***
I I think developers use multiple models most of the time and I'm n...
2024-12-10 22:24:31,649 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:24:31,650 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:24:31,650 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:31,713 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.063s]
2024-12-10 22:24:31,747 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.024s]
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:31,748 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:31,748 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:31,748 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:31,748 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's
***
well
***
I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine
***
but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team
***
um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline
***
but
***
but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance
***
and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that
***
but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a
***
I think that's a bad habit on the whole and but I understand why people do it and B
***
I think the ones people pick for analogize into AI are particularly bad
***
so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models
***
and you get to use them to build all sorts of great stuff
***
and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:31,748 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:24:31,757 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:31,757 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:24:32,588 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:32,592 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.83s. Top score: 0.9998, Bottom score: 0.0269
2024-12-10 22:24:32,592 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.94s. Returned 5 results
2024-12-10 22:24:32,592 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
no um I think the wrong way to do that is to have one person you lean on for everything and the ...
2024-12-10 22:24:32,634 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:24:32,635 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
but if you're trying to build the AI itself that's pretty different another example people uses ...'
2024-12-10 22:24:32,635 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:32,704 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.069s]
2024-12-10 22:24:32,743 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.030s]
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:32,744 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:32,744 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:32,744 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:32,744 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it
***
and you don't say oh this is a transistor product it's just like
***
oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you
***
so I'm going to say so I'm going to say a short statement you give me your immediate thoughts
***
okay
***
okay
***
so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical
***
I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential
***
so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month
***
Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them
***
I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge
***
it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome
***
but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI
***
but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together
***
I think that's it's really quite remarkable
***
and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:24:32,745 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.11s
2024-12-10 22:24:32,754 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:32,754 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
but if you're trying to build the AI itself that's pretty different another example people uses ...' with 5 documents
2024-12-10 22:24:34,103 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:34,105 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.35s. Top score: 1.0000, Bottom score: 0.0869
2024-12-10 22:24:34,105 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.47s. Returned 5 results
2024-12-10 22:24:34,106 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
but if you're trying to build the AI itself that's pretty different another example people uses ...
2024-12-10 22:24:34,149 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:24:34,149 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***
otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:24:34,149 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:34,209 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.060s]
2024-12-10 22:24:34,248 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_standard_quotation/_search [status:200 duration:0.032s]
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:34,248 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:34,248 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:34,248 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:34,248 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***
otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now
***
and I'm not even going that quick
***
but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you
***
but if you were like hey Sam
***
I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable
***
can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general
***
um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team
***
but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement
***
actually I I will just say it
***
I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no
***
and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing
***
I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and
***
Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:24:34,248 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:24:34,258 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:34,258 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***
otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:24:35,259 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:35,262 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.00s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:24:35,262 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.11s. Returned 5 results
2024-12-10 22:24:35,262 - src.processing.query_processor - INFO - Processing transcript chunk for quotation: ***
otherwise it would have been a long list of open a eye people first how do you think about the t...
2024-12-10 22:24:35,298 - src.processing.query_processor - INFO - Selected 3 quotations for transcript chunk.
2024-12-10 22:24:35,302 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_quotation.json'
2024-12-10 22:24:35,303 - __main__ - INFO - Processed queries in 13.72s
2024-12-10 22:24:35,303 - __main__ - INFO - Starting evaluation
2024-12-10 22:24:35,303 - src.data.data_loader - INFO - Loaded JSONL file 'data/evaluation/evaluation_set_quotation.jsonl' with 3 entries successfully.
2024-12-10 22:24:35,303 - __main__ - INFO - Loaded 3 evaluation queries
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:24:35,303 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:24:35,303 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:24:35,303 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:24:35,303 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:24:35,304 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:24:35,304 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:24:35,304 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:24:35,304 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:24:35,304 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:24:35,305 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:24:35,305 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:24:35,305 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:24:35,305 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:24:35,305 - __main__ - INFO - Pipeline for EnhancedQuotationModule completed in 14.63s
2024-12-10 22:24:35,305 - __main__ - INFO - Completed Quotation Extraction in 14.63s
2024-12-10 22:24:35,305 - __main__ - INFO - Converting quotation results to keyword format
2024-12-10 22:24:35,308 - __main__ - INFO - Quotation to keyword conversion completed
2024-12-10 22:24:35,308 - __main__ - INFO - Starting Keyword Extraction Pipeline
2024-12-10 22:24:35,308 - __main__ - INFO - Starting pipeline with KeywordExtractionModule
2024-12-10 22:24:35,308 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:24:35,308 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:24:35,308 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:24:35,308 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:24:35,308 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:24:35,308 - src.core.contextual_vector_db - INFO - Loading vector database and FAISS index from disk.
2024-12-10 22:24:35,309 - src.core.contextual_vector_db - INFO - Vector database metadata loaded from './data/contextual_db/contextual_vector_db.pkl' with 5 entries.
2024-12-10 22:24:35,309 - src.core.contextual_vector_db - INFO - FAISS index loaded from './data/contextual_db/faiss_index.bin' with 5 vectors.
2024-12-10 22:24:35,309 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:24:35,309 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_keyword_extraction
2024-12-10 22:24:35,309 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_keyword_extraction
2024-12-10 22:24:35,324 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.014s]
2024-12-10 22:24:35,327 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_keyword_extraction [status:200 duration:0.003s]
2024-12-10 22:24:35,327 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_keyword_extraction' already exists. Skipping creation.
2024-12-10 22:24:35,346 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.019s]
2024-12-10 22:24:35,367 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_refresh [status:200 duration:0.021s]
2024-12-10 22:24:35,368 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:24:35,368 - __main__ - INFO - Successfully indexed 5 documents in 0.04s
2024-12-10 22:24:35,368 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.06s
2024-12-10 22:24:35,368 - __main__ - INFO - Created Elasticsearch BM25 index in 0.06s
2024-12-10 22:24:35,368 - __main__ - INFO - Loading queries from data/input/queries_keyword_standard.json
2024-12-10 22:24:35,368 - src.data.data_loader - INFO - Loaded JSON file 'data/input/queries_keyword_standard.json' successfully with 32 entries.
2024-12-10 22:24:35,369 - __main__ - INFO - Loaded 32 queries
2024-12-10 22:24:35,369 - __main__ - INFO - Validating queries
2024-12-10 22:24:35,371 - src.processing.query_processor - INFO - Validated 32 transcripts out of 32 provided.
2024-12-10 22:24:35,371 - __main__ - INFO - Validated 32 queries
2024-12-10 22:24:35,371 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:24:35,371 - __main__ - INFO - Initializing optimizer for KeywordExtractionModule
2024-12-10 22:24:35,371 - __main__ - INFO - Initializing keyword extraction optimizer
2024-12-10 22:24:35,816 - __main__ - INFO - Loaded keyword training dataset: 3 samples
2024-12-10 22:24:35,836 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:35,847 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,855 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:35,862 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:35,869 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,876 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:35,884 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:35,890 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,896 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:35,904 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:24:35,912 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,920 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:24:35,926 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:35,932 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:35,937 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,945 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:35,952 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,960 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:24:35,966 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,972 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:35,979 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:35,985 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:35,992 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:24:35,999 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,006 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:24:36,012 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,019 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:24:36,025 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,031 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,036 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,042 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,048 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:24:36,055 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,060 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,068 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,076 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,083 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:24:36,089 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:36,095 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,100 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,106 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:24:36,111 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,118 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:24:36,124 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,129 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:24:36,135 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,141 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:24:36,148 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,153 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:36,158 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,165 - src.analysis.metrics - INFO - Comprehensive metric score: 0.34
2024-12-10 22:24:36,172 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,179 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:36,186 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,192 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,197 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,203 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,209 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:24:36,216 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:36,221 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:24:36,227 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,233 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:24:36,238 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:24:36,244 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:24:36,245 - __main__ - INFO - Compiled optimized keyword program in 0.43s
2024-12-10 22:24:36,246 - __main__ - INFO - Saved optimized keyword program to data/optimized/optimized_keyword_program.json
2024-12-10 22:24:36,246 - __main__ - INFO - Keyword optimizer initialization completed in 0.88s
2024-12-10 22:24:36,246 - __main__ - INFO - Initialized optimizer in 0.88s
2024-12-10 22:24:36,246 - __main__ - INFO - Initializing KeywordExtractionModule
2024-12-10 22:24:36,253 - __main__ - INFO - Initialized KeywordExtractionModule with assertions
2024-12-10 22:24:36,253 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:24:36,253 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_keyword_extraction.json'.
2024-12-10 22:24:36,253 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:24:36,253 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:36,274 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.020s]
2024-12-10 22:24:36,285 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.006s]
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:36,286 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:36,286 - src.retrieval.retrieval - INFO - Filtered 7 chunks due to missing metadata.
2024-12-10 22:24:36,286 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:36,286 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations...': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:24:36,286 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:24:36,291 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:36,291 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:24:37,102 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:37,104 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.81s. Top score: 1.0000, Bottom score: 0.0005
2024-12-10 22:24:37,105 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.85s. Returned 5 results
2024-12-10 22:24:37,105 - src.processing.query_processor - INFO - Processing quotation for keywords: we are going to try our hardest and believe we will succeed at making our models better and better a...
2024-12-10 22:24:37,136 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:24:37,136 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:24:37,136 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:37,165 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.028s]
2024-12-10 22:24:37,180 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.006s]
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:37,182 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:37,182 - src.retrieval.retrieval - INFO - Filtered 7 chunks due to missing metadata.
2024-12-10 22:24:37,182 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:37,182 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better and if you are building a business that patches some current small shortcomings if we do our job right then that will not be as important in the future we believe that we are on a pretty a quite steep trajectory of improvement and that the current shortcomings of the models today will just be taken care of by Future generations...': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:24:37,182 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:24:37,194 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:37,195 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:24:37,903 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:37,905 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 1.0000, Bottom score: 0.0005
2024-12-10 22:24:37,905 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:24:37,905 - src.processing.query_processor - INFO - Processing quotation for keywords: I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...
2024-12-10 22:24:37,925 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:37,925 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...'
2024-12-10 22:24:37,925 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:37,976 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.051s]
2024-12-10 22:24:38,001 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.017s]
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:38,001 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:38,001 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:38,002 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:38,002 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:38,002 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:38,008 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:38,008 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...' with 5 documents
2024-12-10 22:24:38,944 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:38,947 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.94s. Top score: 0.9999, Bottom score: 0.0183
2024-12-10 22:24:38,947 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.02s. Returned 5 results
2024-12-10 22:24:38,947 - src.processing.query_processor - INFO - Processing quotation for keywords: there will be many trillions of dollars of market cap that gets created new market cap that gets cre...
2024-12-10 22:24:38,977 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:38,977 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...'
2024-12-10 22:24:38,977 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:39,026 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.048s]
2024-12-10 22:24:39,055 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.019s]
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:39,055 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:39,055 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:39,055 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:39,055 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:39,055 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:39,065 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:39,065 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...' with 5 documents
2024-12-10 22:24:40,016 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:40,018 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.95s. Top score: 0.9999, Bottom score: 0.0183
2024-12-10 22:24:40,019 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.04s. Returned 5 results
2024-12-10 22:24:40,019 - src.processing.query_processor - INFO - Processing quotation for keywords: I think people have like internalized the rate of Improvement and have heard us on what we intend to...
2024-12-10 22:24:40,048 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:40,049 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...'
2024-12-10 22:24:40,049 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:40,100 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.051s]
2024-12-10 22:24:40,132 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.020s]
2024-12-10 22:24:40,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:40,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:40,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:40,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:40,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:40,133 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:40,133 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:40,133 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:40,133 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:40,133 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:40,133 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:40,133 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:40,133 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I felt a little bit guilty *** but you you said wearing this 20 VC jump which is incredibly proud moment for me uh for certain segments like the one you mentioned there there would be the potential to steamroll if if you're thinking as a Founder today building where is open aai going to potentially come and steamroll versus where they're not also for me as an investor trying to invest in opportunities that aren't going to get damaged how should Founders and me as an investor think about that there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before and there's this one set of areas where we're going to try to make it relevant which is you know we just want the models to be really really good such that you don't have to like fight so hard to get them to do what you want to do but all of this other stuff which is building these incredible products and services on top of this new technology we think that just gets better and better um one of the surprises to me early on was and this is no longer the case but in like the GPT 3.5 days it felt like 95% of startups something like that wanted to bet against the models getting way better and *** so and they were doing these things where we could already see gp4 coming and we're were like man it's going to be so good it's not going to have these problems if you're building a tool just to get around this one shortcoming of the model that's going to become less and less relevant and we forget how bad the models were a couple of years ago it hasn't been that long on the calendar but there were there were just a lot of things and so it seemed like these good areas to build a thing uh to like to plug a hole rather than to build something to go deliver like the great AI tutor or the great AI medical advisor or whatever *** and so I felt like 95% of people that were were like betting against the models getting better 5% of the people were betting for the models getting better I think that's now reversed I think people have like internalized the rate of Improvement and have heard us on what we intend to do *** so it's it no longer seems to be such an issue *** but it was something we used to fret about a lot because we kind of we saw it was going to happen to all of these very hardworking people *** you you said about the trillions of dollars of value to be created that *** and then I promise we will return to these brilliant questions I'm sure you saw I'm not sure if you saw but Massa sit on stage and say we will have not I'm not going to do anent because my accents are terrible um but there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed I'm just intrigued how did you think about that when you saw that how do you reflect on that I can't put it down to like any I think like if we can get it right with an orders of magnitude that's that's good enough for now there's clearly going to be a lot of capex spent and clearly a lot of value created this happens with every other Mega technological revolution of which this is clearly one *** but you know like next year will be a big push for us into these next Generation systems you talked about when there could be like a no code software agent I don't know how long that's going to take': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:40,133 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:40,142 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:40,142 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** yeah sorry for that uh but there was this brilliant kind of meme that came out of it *** and I f...' with 5 documents
2024-12-10 22:24:41,066 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:41,069 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.93s. Top score: 0.9999, Bottom score: 0.0183
2024-12-10 22:24:41,069 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.02s. Returned 5 results
2024-12-10 22:24:41,069 - src.processing.query_processor - INFO - Processing quotation for keywords: there will be9 trillion dollars of value created did every single year which will offset the $9 tril...
2024-12-10 22:24:41,098 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:41,099 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:24:41,099 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:41,154 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.055s]
2024-12-10 22:24:41,184 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.023s]
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:41,185 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:41,185 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:41,185 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:41,185 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2]
2024-12-10 22:24:41,185 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:24:41,192 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:41,192 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:24:43,385 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:43,389 - src.retrieval.reranking - INFO - Cohere reranking completed in 2.20s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:24:43,390 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.29s. Returned 5 results
2024-12-10 22:24:43,390 - src.processing.query_processor - INFO - Processing quotation for keywords: think about how much economic value gets unlocked for the world if anybody can just describe like a ...
2024-12-10 22:24:43,414 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:24:43,415 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:24:43,415 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:43,463 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.048s]
2024-12-10 22:24:43,498 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.026s]
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:43,499 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:43,499 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:43,499 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:43,499 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2]
2024-12-10 22:24:43,499 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:43,508 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:43,508 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:24:44,423 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:44,426 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.92s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:24:44,426 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.01s. Returned 5 results
2024-12-10 22:24:44,426 - src.processing.query_processor - INFO - Processing quotation for keywords: there's clearly a really important place in the Eos system for open source models...
2024-12-10 22:24:44,450 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:44,450 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...'
2024-12-10 22:24:44,450 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:44,490 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.040s]
2024-12-10 22:24:44,514 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.018s]
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:44,514 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:44,515 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:44,515 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:44,515 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** but if we use that as an example and imagine forward to towards it think about what think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want this is a ways away obviously but when we get there and have it happen um think about how difficult and how expensive that is now think about how much value it creates if you keep the same amount of value but make it wildly more accessible and less expensive that that's really powerful *** and I think we'll see many other examples like that we I mentioned earlier like healthcare and education but those are two that are both like trillions of dollars of value to the world to get right if you and if AI can really really truly enable this to happen in a different way than it has before I don't think big numbers are the point and they're also the debate about whether it's 9 trillion or 1 trillion or whatever like you know I don't smarter people than me it takes to figure that out *** but but the value creation does seem just unbelievable here we're going to get to agents in terms of kind of how that values delivered in terms of like the delivery mechan mechanism for which it's valued open source is an incredibly prominent method through which it could be how do you think about the role of Open Source in the future of AI and how does internal discussions look like for you when the question comes should we open source any models or some models there there's clearly a really important place in the Eos system for open source models there's also really good open source models that now exist um I think there's also a place for like nicely offered well integrated services and apis *** and you know I think it's I think it makes sense that all of this stuff is an offer and people will pick what what works for them as a delivery mechanism we have the open source as of kind of enop to customers and a way to deliver that we can have agents I think there's a lot of uh kind of semantic confusion around what an agent is how do you think about the definition of Agents today and what is an agent to you and what is it not this is like my off-the-cuff answer it's not well considered *** but something that I can give a long duration task to and provide minimal supervision during execution for what do you think people think about agents that actually they get wrong *** well it's more like I don't I don't think any of us yet have an intuition for what this is going to be like you know we're all gesturing at something that seems important maybe I can give the following example when people talk about an AI agent acting on their behalf uh the the main example they seem to give fairly consistant is oh you can like ask the agent to go book you a restaurant reservation um and either it can like use open table or it can like call the restaurant *** okay sure that's that's like a mild Le annoying thing to have to do *** and it maybe like saves you some work one of the things that I think is interesting as a world where uh you can just do things that you wouldn't or couldn't do as a human so what if what if instead of calling uh one restaurant to make a reservation my agent would call me like 300 and figure out which one had the best food for me or some special thing available or whatever and then you would say well that's like really annoying if your agent is calling 300 restaurants but if if it's an agent answering each of those 300 300 places then no problem and it can be this like massively parallel thing that a human can't do so that's like a trivial example but there are these like limitations to human bandwidth that maybe these agents won't have the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker um where you can like collaborate on a project with and the agent can go do like a two-day task or two week task': [interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2]
2024-12-10 22:24:44,515 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.06s
2024-12-10 22:24:44,519 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:44,520 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** but if we use that as an example and imagine forward to towards it think about what think about ...' with 5 documents
2024-12-10 22:24:45,397 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:45,400 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0103
2024-12-10 22:24:45,400 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.95s. Returned 5 results
2024-12-10 22:24:45,400 - src.processing.query_processor - INFO - Processing quotation for keywords: the category I think though is more interesting is not the one that people normally talk about where...
2024-12-10 22:24:45,431 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:45,431 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...'
2024-12-10 22:24:45,432 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:45,491 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.059s]
2024-12-10 22:24:45,521 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.023s]
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:45,522 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:45,522 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:45,522 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:45,522 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun *** but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure *** but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it *** it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one *** but the actual like Revenue we can make from a model I think justifies the investment to be fair *** uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable *** then *** yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality *** spe *** yeah *** I hope it's just going to work *** I mean it obviously takes some doing to get done *** but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:45,522 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:24:45,532 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:45,532 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...' with 5 documents
2024-12-10 22:24:46,408 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:46,411 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0004
2024-12-10 22:24:46,411 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.98s. Returned 5 results
2024-12-10 22:24:46,412 - src.processing.query_processor - INFO - Processing quotation for keywords: reasoning is our current most important area of focus I think this is what unlocks the next like mas...
2024-12-10 22:24:46,440 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:46,441 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...'
2024-12-10 22:24:46,441 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:46,497 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.056s]
2024-12-10 22:24:46,530 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.023s]
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:46,530 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:24:46,530 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:24:46,530 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:46,530 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** really well and you know ping you at when it has questions but come back to you with like a great work product does this fundamentally change the way that SAS is priced when you think about extraction of value bluntly and normally it's on a per seat basis but now you're actually kind of replacing labor so to speak how do you think about the future of pricing with that in mind when you are such a cool part of an Enterprise Workforce I'll speculate here for fun *** but we really have no idea I mean I could imagine a world where you can say like I want one GPU or 10 gpus or 100 gpus to just be like turning on my problems all the time and it's not like you're not like paying per seat or even per agent but you're like it's priced based off the amount of compute that's like working on a you know on your problems all the time do we need to build specific models for agentic use or do we not how do you think about that there's a huge amount of infrastructure and Scaffolding to build for sure *** but I think 01 points the way to a model that is capable of doing great agentic tasks on the model side Sam everyone says that uh models are depreciating assets the commoditization of models is so Rife how do you respond and think about that and when you think about the increasing Capital intensity to train models are we actually seeing the reversion of that where it requires so much money that actually very few people can do it *** it's definitely true that there are depreciating assets um this thing that they're not though worth as much as they cost to train that seems totally wrong um to say nothing of the fact that there's like a there's a positive compounding effect as you learn to train these models you get better at training the next one *** but the actual like Revenue we can make from a model I think justifies the investment to be fair *** uh I don't think that's true for everyone and there's a lot of there are probably too many people training very similar models and if you're a little behind or if you don't have a product with the sort of normal rules of business that make that product sticky and valuable *** then *** yeah maybe you can't maybe it's harder to get a return on the investment we're very fortunate to have chat GPT and hundreds of millions of people that use our models and so even if it cost a lot we get to like amortize that cost across a lot of people how do you think about how open AI models continue to differentiate over time and where you most want to focus to expand that differentiation reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created so that's we'll improve them in lots of ways uh we will do multimodal work uh we will do other features in the models that we think are super important to the ways that people want to use these things how do you think about reasoning in multimodal work like there the challenges what you want to achieve love to understand that reasoning in multimodality *** spe *** yeah *** I hope it's just going to work *** I mean it obviously takes some doing to get done *** but uh you know like people like when they're babies and toddlers before they're good at language can still do quite complex visual reasoning so clearly this is possible totally is um how will Vision capabilities scale with new inference time Paradigm set by 01 without spoiling anything I would expect rapid progress in image based models going off schedule is one thing trying to tease that out might get me in real trouble how does open AI make breakthroughs in terms of like core reasoning do we need to start pushing into reinforcement learning as a pathway or other new techniques aside from the Transformer I mean there's two questions in there there's how we do it': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:24:46,530 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:24:46,539 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:46,539 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** really well and you know ping you at when it has questions but come back to you with like a grea...' with 5 documents
2024-12-10 22:24:48,466 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:48,468 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.93s. Top score: 1.0000, Bottom score: 0.0004
2024-12-10 22:24:48,468 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.03s. Returned 5 results
2024-12-10 22:24:48,468 - src.processing.query_processor - INFO - Processing quotation for keywords: the actual like Revenue we can make from a model I think justifies the investment to be fair...
2024-12-10 22:24:48,490 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:48,490 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:24:48,490 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:48,546 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.056s]
2024-12-10 22:24:48,581 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.023s]
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:24:48,581 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:48,581 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:48,581 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:48,581 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:48,582 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:24:48,589 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:48,590 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:24:49,450 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:49,451 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:24:49,451 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.96s. Returned 5 results
2024-12-10 22:24:49,451 - src.processing.query_processor - INFO - Processing quotation for keywords: what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...
2024-12-10 22:24:49,475 - src.processing.query_processor - INFO - Extracted 5 keywords for quotation.
2024-12-10 22:24:49,476 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:24:49,476 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:49,532 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.057s]
2024-12-10 22:24:49,563 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.022s]
2024-12-10 22:24:49,563 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:49,563 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:49,563 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:49,563 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:49,563 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:49,564 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:49,564 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:49,564 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:49,564 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:24:49,564 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:49,564 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:49,564 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:49,564 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:49,564 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:24:49,573 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:49,573 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:24:50,449 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:50,451 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:24:50,451 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.98s. Returned 5 results
2024-12-10 22:24:50,451 - src.processing.query_processor - INFO - Processing quotation for keywords: the repeated ability to go off and do something new and totally unproven...
2024-12-10 22:24:50,475 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:50,475 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:24:50,475 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:50,581 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.106s]
2024-12-10 22:24:50,615 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.019s]
2024-12-10 22:24:50,615 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:50,615 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:50,615 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:50,615 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:50,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:50,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:50,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:50,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:50,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:24:50,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:50,616 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:50,616 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:50,616 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:50,616 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.14s
2024-12-10 22:24:50,628 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:50,628 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:24:53,076 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:53,078 - src.retrieval.reranking - INFO - Cohere reranking completed in 2.45s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:24:53,078 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.60s. Returned 5 results
2024-12-10 22:24:53,078 - src.processing.query_processor - INFO - Processing quotation for keywords: there's a huge amount of wasted human talent because this is not an organization style or culture...
2024-12-10 22:24:53,106 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:53,107 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...'
2024-12-10 22:24:53,107 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:53,153 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.045s]
2024-12-10 22:24:53,186 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.025s]
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:24:53,187 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:53,187 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:24:53,187 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:53,187 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and then you know there's everyone's favorite question which is what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works uh and one of the reasons that people don't talk about about why it's so easy is you have the conviction to know what's possible *** and so after after a research does something even if you don't know exactly how they did it *** it's I say easy *** but it's doable to go off and copy it *** and you can see this in the replications of gp4 *** and I'm sure you'll see this in replications of 01 what is really hard and the thing that I'm most proud of about our culture is the repeated ability to go off and do something new and totally unproven and a lot of organizations *** not I'm not not talking about AI research just generally a lot of organizations talk about the ability to do this there are very few that do um across any field and in some sense I think this is one of the most important inputs to human progress so one of the like retirement things I fantasize about doing is writing a book of everything I've learned about how to build an organization and a culture that does this thing not the organization that just copies what everybody else has done because I think this is something that the world could have a lot more of it's limited by human talent but there's a huge amount of wasted human talent because this is not an organization style or culture whatever you want to call it that we are all good at building *** so I'd love way more of that and that is I think the thing most special about us *** Sam how is human Talent wasted oh there's just a lot of really talented people in the world that are not working to their full potential um because they work at a Bad Company or they live in a country that doesn't support any good companies uh or a long list of other things I mean the one of the things I'm most excited about with AI is I hope it'll get us much better than we are now at helping get everyone to their Max potential which we are nowhere nowhere near there's a lot of people in the world that I'm sure would be phenomenal AI researchers had their life paths just gone a little bit differently you've had an incredible journey over the last few years through you know unbelievable hyper growth you say about writing a book there in retirement if you reflect back on the 10 years of leadership change that you've undergone how have you changed your leadership most significantly I think the thing that has been most unusual for me about these last couple of years is just the rate at which things have changed at a normal company you get time to go from zero to 100 million in Revenue 100 million to a billion billion to 10 billion you don't have to do that in like a two-year period and you don't have to like build the company we had to research that *** but we really didn't have a company in the sense of a traditional Silicon Valley startup that's you know scaling and serving lots of customers whatever um having to do that so quickly there was just like a lot of stuff that I was supposed to get more time to learn than I got what did you not know that you would have liked more time to learn I mean I would say like what did I know one of the things that just came to mind out of like a rolling list of a hundred is how hard it is how much active work it takes to get the company to focus not on how you grow the next 10% but the next 10x and growing the next 10% it's the same things that worked before will work again but to go from a company doing say like a billion to1 billion dollars in Revenue requires a whole lot of change and it is not the sort of like let's do last week what we did this week mindset and in a world where people don't get time to even get caught up on the basics because growth is just so rapid': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:53,188 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:53,196 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:53,196 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and then you know there's everyone's favorite question which is what comes beyond the Transforme...' with 5 documents
2024-12-10 22:24:54,942 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:54,944 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.75s. Top score: 1.0000, Bottom score: 0.0002
2024-12-10 22:24:54,945 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.84s. Returned 5 results
2024-12-10 22:24:54,945 - src.processing.query_processor - INFO - Processing quotation for keywords: I hope it'll get us much better than we are now at helping get everyone to their Max potential...
2024-12-10 22:24:54,973 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:54,973 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:24:54,973 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:55,025 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.051s]
2024-12-10 22:24:55,053 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.017s]
2024-12-10 22:24:55,053 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:55,053 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:55,053 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:55,053 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:55,053 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:55,054 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:55,054 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:55,054 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:55,054 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:24:55,054 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:55,054 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:55,054 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:55,064 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:55,064 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:24:55,943 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:55,946 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:24:55,946 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.97s. Returned 5 results
2024-12-10 22:24:55,946 - src.processing.query_processor - INFO - Processing quotation for keywords: I badly underappreciated the amount of work it took to be able to like keep charging at the next big...
2024-12-10 22:24:55,976 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:24:55,976 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:24:55,976 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:56,032 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.055s]
2024-12-10 22:24:56,060 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.018s]
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:56,060 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:56,060 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:24:56,060 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:56,060 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:56,061 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:24:56,070 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:56,070 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:24:56,967 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:56,967 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.90s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:24:56,967 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.99s. Returned 5 results
2024-12-10 22:24:56,967 - src.processing.query_processor - INFO - Processing quotation for keywords: there was either no playbook for this or someone had a secret Playbook they didn't give me....
2024-12-10 22:24:56,987 - src.processing.query_processor - INFO - Extracted 5 keywords for quotation.
2024-12-10 22:24:56,987 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:24:56,987 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:57,032 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.045s]
2024-12-10 22:24:57,056 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.018s]
2024-12-10 22:24:57,056 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:57,057 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:57,057 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:24:57,057 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:57,057 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:57,057 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:24:57,063 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:57,063 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:24:58,194 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:58,196 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.13s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:24:58,196 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.21s. Returned 5 results
2024-12-10 22:24:58,196 - src.processing.query_processor - INFO - Processing quotation for keywords: you should hire incredibly young people under 30 and that is what Peter teal taught him....
2024-12-10 22:24:58,230 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:24:58,230 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:24:58,230 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:58,273 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.043s]
2024-12-10 22:24:58,302 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.021s]
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:58,302 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:58,302 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:24:58,302 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:58,302 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:58,302 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:24:58,310 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:58,310 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:24:59,219 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:24:59,222 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.91s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:24:59,222 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.99s. Returned 5 results
2024-12-10 22:24:59,223 - src.processing.query_processor - INFO - Processing quotation for keywords: when you're like designing some of the most complex and massively expensive computer systems that Hu...
2024-12-10 22:24:59,250 - src.processing.query_processor - INFO - Extracted 5 keywords for quotation.
2024-12-10 22:24:59,251 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...'
2024-12-10 22:24:59,251 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:24:59,297 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.045s]
2024-12-10 22:24:59,322 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.016s]
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:24:59,322 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:24:59,322 - src.retrieval.retrieval - INFO - Filtered 8 chunks due to missing metadata.
2024-12-10 22:24:59,322 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:24:59,322 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do there's a big piece of internal communication around that and how you sort of share information how you build the structures to like get the to get good at thinking about 10x more stuff or bigger stuff or more complex stuff every eight months 12 months whatever um there's a big piece in there about planning about how you balance what has to happen today and next month with the the long lead pieces you need in place for to be able to execute in a year or two years with you know build out of compute or even you know things that are more normal like planning a head enough for like office space in a city like San Francisco is surprisingly hard at this kind of rate *** so I I think there was either no playbook for this or someone had a secret Playbook they didn't give me um or all of us like we've all just sort of fumbled our way through this *** but there's been a lot to learn on the Fly God I don't know if I'm going to get into trouble for this but s it I'll ask it anyway *** and if so I'll deal with it later um Keith R boy uh did a talk *** and he said about you should hire incredibly young people under 30 and that is what Peter teal taught him and that is the secret to building great companies I'm intrigued when you think about this book that you write in retirement and that advice you build great companies by building incredibly young hungry ambitious people who are under 30 and that is the mechanism how do you feel I think I was 30 when we started opening eye or at least thereabouts *** so you know I wasn't that young seem to work *** okay so far worth a try uh uh going back to uh is the question like the question is how do you think about hiring incredibly young under 30s as this like Trojan Horse of Youth energy ambition but less experience or the much more experienced *** I know how to do this I've done it before I mean the obvious answer is you can succeed with Hing both classes of people like we have I was just like right before this I was sending someone a slack message about there was a guy that we recently hired on one of the teams I don't know how old he is but low 20s probably doing just insanely amazing work and I was like can we find a lot more people like this this is just like off the charts brilliant I don't get how these people can be so good so young *** but it clearly happens and when you can find those people they bring amazing fresh perspective energy whatever else on the other hand uh when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built actually like pieces of infrastructure of any sort *** then I would not be comfortable taking a bet on someone who is just sort of like starting out uh where the stakes are higher so you want both *** uh and I think what you really want is just like an extremely high Talent bar of people at any age and a strategy that said I'm only going to hire younger people or I'm only going to hire older people I believe would be misguided I think it's like': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:24:59,323 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:24:59,331 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:24:59,332 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** uh I I badly underappreciated the amount of work it took to be able to like keep charging at the...' with 5 documents
2024-12-10 22:25:00,204 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:00,207 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0134
2024-12-10 22:25:00,207 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.96s. Returned 5 results
2024-12-10 22:25:00,207 - src.processing.query_processor - INFO - Processing quotation for keywords: you want both....
2024-12-10 22:25:00,237 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:00,237 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...'
2024-12-10 22:25:00,237 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:00,264 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.027s]
2024-12-10 22:25:00,278 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.005s]
2024-12-10 22:25:00,278 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:00,278 - src.retrieval.retrieval - INFO - Filtered 1 chunks due to missing metadata.
2024-12-10 22:25:00,278 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:00,278 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'somehow just not it's not quite the framing that resonates with me but the part of it that does is and one of the things that I feel most grateful about why combinator 4 is inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value and uh we as a society should bet on those people and it's a great thing I am going to return to some semblance of the schedule is I'm I'm really going to get told off but anthropics models have been sometimes cited as being better for coding Tas why is that do you think that's fair and how should developers think about when to pick open AI versus a different provider *** yeah they have a model that is great at coding for sure ***': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:25:00,278 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:00,286 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:00,287 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'somehow just not it's not quite the framing that resonates with me but the part of it that does is a...' with 5 documents
2024-12-10 22:25:01,010 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:01,012 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9999, Bottom score: 0.0026
2024-12-10 22:25:01,013 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.78s. Returned 5 results
2024-12-10 22:25:01,013 - src.processing.query_processor - INFO - Processing quotation for keywords: inexperience does not inherently mean not valuable and there are incredibly high potential people at...
2024-12-10 22:25:01,046 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:01,047 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:25:01,047 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:01,100 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.053s]
2024-12-10 22:25:01,131 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.021s]
2024-12-10 22:25:01,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:01,131 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:01,132 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:01,132 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:25:01,132 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:01,132 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:01,132 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:25:01,141 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:01,141 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:25:02,088 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:02,091 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.95s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:25:02,091 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.04s. Returned 5 results
2024-12-10 22:25:02,091 - src.processing.query_processor - INFO - Processing quotation for keywords: I think developers use multiple models most of the time and I'm not sure how that's all going to evo...
2024-12-10 22:25:02,124 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:25:02,124 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:25:02,125 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:02,176 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.051s]
2024-12-10 22:25:02,206 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.021s]
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:02,206 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:02,206 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:25:02,206 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:02,206 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:02,206 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:25:02,216 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:02,216 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:25:03,419 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:03,422 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.21s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:25:03,422 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.30s. Returned 5 results
2024-12-10 22:25:03,422 - src.processing.query_processor - INFO - Processing quotation for keywords: we have a lot of people here who are excited to build AGI and that that's a very motivating thing...
2024-12-10 22:25:03,453 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:03,453 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...'
2024-12-10 22:25:03,453 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:03,506 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.053s]
2024-12-10 22:25:03,542 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.025s]
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:03,542 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:03,543 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:25:03,543 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:03,543 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World um *** but I sort of think there's just going to be a lot of AI everywhere and something about the way that we currently talk about it or think about it feels wrong uh may maybe if I had to describe it we will shift from talking about models to talking about systems but that'll take a while when we think about scaling models how many more model iterations do you think scaling laws will hold true for it was the kind of common refrain that it won't last for long *** and it seems to be proving to last longer than people think without going into detail about how it's going to happen the the the core of the question that you're getting at is is the trajectory of model capability Improvement going to keep going like it has has been going and the answer that I believe is yes for a long time have you ever doubted that totally why uh we have had well we've had like Behavior we don't understand we've had failed training runs we all sorts of things we've had to figure out new paradigms when we kind of get to towards the end of one and have to figure out the next what was the hardest one to navigate well when we started working on gp4 there were some issues that caused us a lot of consternation that we really didn't know how to solve we figured it out *** but there was there was definitely a time period where we just didn't know how we were going to do that model and then in this shift to 01 and the idea of reasoning models uh that was something we had been excited about for a long time *** but it was like a long and Winding Road of research to get here is it difficult to maintain morale when it is long and winding roads when training runs can fail how do you maintain morale in those times you know we have a lot of people here who are excited to build AGI and that that's a very motivating thing *** and no one expects that to be easy and a straight line to success *** but there's a famous quote from history it's something like I'm gonna get this totally wrong but the spirit of it is like I never pray and ask for God to be on my side *** you know I pray and hope to be on God's side and there is something about betting on deep learning that feels like being on the side of the angels and you kind of just it eventually seems to work out even though you hit some big stumbling blocks along the way and so like a deep belief in that has been good for us *** can I ask a really weird one I had a great quote the other day *** and it was the heaviest things in life are not iron or gold but unmade decisions what unmade decision weighs on your mind most it's different every day like I don't there's not one big one *** I mean I guess there are some big ones like about are we going to bet on this next product or that next product uh or are we going to like build our next computer this way or that way they are kind of like really high stakes one-way doorish that like everybody else I probably delay for too long *** but but mostly the hard part is every day it feels like there are a few new 5149 decisions that come up that kind of make it to me because they were 5149 in the first place *** and then I don't feel like particularly likely *** I can do better than somebody else would have done but I kind of have to make them *** anyway *** and it's it's the volume of them it is not anyone is there a commonality in the person that you cool when it's 5149': [interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:03,543 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:25:03,550 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:03,550 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** and it's impressive work *** I I think developers use multiple models most of the time and I'm n...' with 5 documents
2024-12-10 22:25:04,435 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:04,438 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.89s. Top score: 1.0000, Bottom score: 0.0073
2024-12-10 22:25:04,438 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.98s. Returned 5 results
2024-12-10 22:25:04,438 - src.processing.query_processor - INFO - Processing quotation for keywords: the heaviest things in life are not iron or gold but unmade decisions...
2024-12-10 22:25:04,471 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:04,472 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:25:04,472 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:04,529 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.057s]
2024-12-10 22:25:04,565 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.025s]
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:04,565 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:04,565 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:04,565 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:04,565 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:04,566 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:25:04,576 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:04,576 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:25:05,369 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:05,373 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.80s. Top score: 0.9998, Bottom score: 0.0322
2024-12-10 22:25:05,373 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.90s. Returned 5 results
2024-12-10 22:25:05,373 - src.processing.query_processor - INFO - Processing quotation for keywords: I think the wrong way to do that is to have one person you lean on for everything and the right way ...
2024-12-10 22:25:05,401 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:05,401 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:25:05,401 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:05,464 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.062s]
2024-12-10 22:25:05,502 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.028s]
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:05,502 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:05,502 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:05,502 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:05,502 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:05,503 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:25:05,512 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:05,512 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:25:06,383 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:06,387 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.87s. Top score: 0.9998, Bottom score: 0.0322
2024-12-10 22:25:06,387 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.99s. Returned 5 results
2024-12-10 22:25:06,387 - src.processing.query_processor - INFO - Processing quotation for keywords: the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...
2024-12-10 22:25:06,414 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:25:06,415 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...'
2024-12-10 22:25:06,415 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:06,461 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.046s]
2024-12-10 22:25:06,489 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.019s]
2024-12-10 22:25:06,489 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:06,489 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:06,490 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:06,490 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:06,490 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:06,490 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** no um I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way and you get to like phone a friend to the best expert rather than try to have just one across the board in terms of hard decisions I do want to touch ON Semiconductor Supply chains how worried are you about semiconductor Supply chains and international tensions today I don't know how to quantify that worried of course is the answer uh it's probably not it's well I guess I could quantify it this way it is not my top worry but it is in like the top 10% of all worries am I allowed to ask what's your top worry I'm I'm in so much I've got past the stage of being in trouble for this one sort of generalized complexity of all we as a whole field are trying to do and it feels like a I think it's all going to work out fine but it feels like a very complex system now this kind of like works fractally at every level so you can say that's also true like inside of opening ey itself uh that's also true inside of anyone team um but you know and example of this since you were just talking about semiconductors is you got to balance the power availability with the right networking decisions with being able to like get enough chips in time and whatever risk there's going to be there um with the ability to have the research ready to intersect that so you don't either like be caught totally flat footed or have a system that you can't utilize um with the right product that is going to use that research to be able to like pay the eye watering cost of that system so it's Supply chain makes it sign sound too much like a pipeline but but yeah the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before uh and some version of that is probably my top worry you said unlike anything we've seen before a lot of people I think compare this you know wave to the internet bubble uh in terms of you know the excitement and the exuberance and I think the thing that's different is the amount that people are spending Larry Ellison said that it will cost hundred billion doar to enter the foundation model race as a starting point do you agree with that statement and when you saw that we like yeah that makes sense uh no I think it will cost less than that but there's an interesting point here um which is everybody likes to use previous examples of a technology Revolution to talk about to put a new one into more familiar context and a I think that's a bad habit on the whole and but I understand why people do it and B I think the ones people pick for analogize into AI are particularly bad so the internet was obviously quite different than Ai and you brought up this one thing about cost and whether it cost like 10 billion or 100 billion or whatever to be competitive it was very like one of the defining things about the internet Revolution was it was actually really easy to get started now another thing that Cuts more towards the internet is mostly for many companies this will just be like a continuation of the Internet it's just like someone else makes these AI models and you get to use them to build all sorts of great stuff and it's like a new primitive for Building Technology': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:06,490 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:25:06,500 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:06,500 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** no um I think the wrong way to do that is to have one person you lean on for everything and the ...' with 5 documents
2024-12-10 22:25:07,849 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:07,853 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.35s. Top score: 0.9998, Bottom score: 0.0322
2024-12-10 22:25:07,853 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.44s. Returned 5 results
2024-12-10 22:25:07,853 - src.processing.query_processor - INFO - Processing quotation for keywords: it was very like one of the defining things about the internet Revolution was it was actually really...
2024-12-10 22:25:07,882 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:07,883 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...'
2024-12-10 22:25:07,883 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:07,928 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.045s]
2024-12-10 22:25:07,953 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.019s]
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:07,953 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:07,954 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:07,954 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:07,954 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:07,954 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:07,954 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:25:07,954 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:25:07,960 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:07,960 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...' with 5 documents
2024-12-10 22:25:09,119 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:09,122 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.16s. Top score: 1.0000, Bottom score: 0.0831
2024-12-10 22:25:09,122 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.24s. Returned 5 results
2024-12-10 22:25:09,122 - src.processing.query_processor - INFO - Processing quotation for keywords: the one I like the most caveat by my earlier comment that I don't think people should be doing this ...
2024-12-10 22:25:09,154 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:09,155 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...'
2024-12-10 22:25:09,155 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:09,204 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.049s]
2024-12-10 22:25:09,230 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.017s]
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:09,230 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:09,231 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:09,231 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:09,231 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:09,231 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:25:09,231 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:25:09,240 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:09,240 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...' with 5 documents
2024-12-10 22:25:10,082 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:10,086 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 1.0000, Bottom score: 0.0831
2024-12-10 22:25:10,086 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.93s. Returned 5 results
2024-12-10 22:25:10,087 - src.processing.query_processor - INFO - Processing quotation for keywords: something about an AI that can understand your whole life doesn't have to like literally be infinite...
2024-12-10 22:25:10,112 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:25:10,112 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...'
2024-12-10 22:25:10,112 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:10,167 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.055s]
2024-12-10 22:25:10,206 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.028s]
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:10,207 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:10,207 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:10,207 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:10,207 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '***but if you're trying to build the AI itself that's pretty different another example people uses electricity um which I think doesn't make sense for a ton of reasons the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties it seeped everywhere pretty quickly you know we had things like Moors law in a way that we could now imagine like a bunch of laws for AI that tell us something about how quickly it's going to get better um and everyone kind of B like the whole tech industry kind of benefited from it and there's a lot of transistors involved in the products and delivery of services that you use but you don't really think of them as transistor companies um it's there's a very complex very expensive industrial process around it with a massive supply chain and incredible progress based off of this very simple discovery of physics led to this gigantic uplift of the whole economy for a long time even though most of the time you didn't think about it*** and you don't say oh this is a transistor product it's just like ***oh all right this thing can like process information for me you don't even really think about that it's just expected Sam i' love to do a quick fire round with you ***so I'm going to say so I'm going to say a short statement you give me your immediate thoughts ***okay ***okay ***so you are building today as a whatever 23 24 year old with the infrastructure that we have today what do you choose to build if you started today uh some AI enabled vertical ***I'll I 'll I'll use tutors as an example but like the the the best AI tutoring product or the you know that I could possibly imagine to teach people to learn any category like that could be the AI lawyer could be the sort of like AI CAD engineer whatever you mentioned your book if you were to write a book what would you call it I don't have a title ready I haven't thought about this book other than like I wish something existed because I think it could unlock a lot of human potential ***so maybe I think it would be something about human potential what in AI does no one focus on that everyone should spend more time on what I would love to see there's a lot of different ways to solve this problem but something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data things like that what was one thing that surprised you in the last month ***Sam it's a research result I can't talk about but it is breathtakingly good which competitor do you most respect why them ***I mean I kind of respect everybody in the space right now I think there's like really amazing work coming from the whole field and Incredibly talented incredibly hardworking people I don't mean this to be a question Dodge ***it's like I can point to super talented people doing super great work everywhere in the field is that one not really uh tell me what's your favorite open AI API I think the new realtime API is pretty awesome ***but we have a lot of I mean we have a we have a big API business at this point so there's a lot of good stuff in there who do you most respect in AI today Sam uh let me give a shout out to the cursor team I mean there's a lot of people doing incredible work in AI ***but I think to really have do what they've done and built I thought about like a bunch of researchers I could name um but in terms of using AI to deliver a really magical experience that creates a lot of value in a way that people just didn't quite manage to put the pieces together ***I think that's it's really quite remarkable ***and I specifically left anybody at open a eye out as I was thinking through it': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:25:10,207 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:25:10,216 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:10,216 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '***but if you're trying to build the AI itself that's pretty different another example people uses e...' with 5 documents
2024-12-10 22:25:11,089 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:11,092 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.88s. Top score: 1.0000, Bottom score: 0.0831
2024-12-10 22:25:11,093 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.98s. Returned 5 results
2024-12-10 22:25:11,093 - src.processing.query_processor - INFO - Processing quotation for keywords: I think to really have do what they've done and built I thought about like a bunch of researchers I ...
2024-12-10 22:25:11,123 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:11,124 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:25:11,124 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:11,177 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.053s]
2024-12-10 22:25:11,209 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.023s]
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:11,209 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:11,209 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:25:11,209 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:11,210 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:25:11,210 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.09s
2024-12-10 22:25:11,219 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:11,220 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:25:12,068 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:12,071 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:25:12,071 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.95s. Returned 5 results
2024-12-10 22:25:12,071 - src.processing.query_processor - INFO - Processing quotation for keywords: I think that product is a weakness of mine in general...
2024-12-10 22:25:12,104 - src.processing.query_processor - INFO - Extracted 3 keywords for quotation.
2024-12-10 22:25:12,105 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:25:12,105 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:12,157 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.052s]
2024-12-10 22:25:12,203 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.036s]
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:12,203 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:12,203 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:25:12,203 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:12,203 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:25:12,203 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:25:12,214 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:12,214 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:25:13,963 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:13,965 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.75s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:25:13,965 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.86s. Returned 5 results
2024-12-10 22:25:13,965 - src.processing.query_processor - INFO - Processing quotation for keywords: I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...
2024-12-10 22:25:13,990 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:25:13,990 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...'
2024-12-10 22:25:13,990 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:14,037 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.046s]
2024-12-10 22:25:14,070 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_keyword_extraction/_search [status:200 duration:0.024s]
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:14,071 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:14,071 - src.retrieval.retrieval - INFO - Filtered 10 chunks due to missing metadata.
2024-12-10 22:25:14,071 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:14,071 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query '*** otherwise it would have been a long list of open a eye people first how do you think about the tradeoff between latency and accuracy you need a dial to change between them like in the same way that you want to do a rapid fire thing now *** and I'm not even going that quick *** but I'm you know trying not to think for multiple minutes uh in this context latency is what you want if you *** but if you were like hey Sam *** I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years and the answer is it should be user controllable *** can I ask when you think about insecurity and Leadership I think it's something that everyone has uh it's something we don't often talk about um when you think about maybe an insecurity and Leadership an area of your leadership that you'd like to improve where would you most like to improve as a leader and a CEO to today the thing I'm struggling with most this week is I feel more uncertain than I have in the past about what our like the details of what our product strategy should be um I think that product is a weakness of mine in general *** um and it's something that right now the company like needs stronger and clearer vision on from me like we have a wonderful head of product and a great product team *** but it's an area that I wish I were a lot stronger on and acutely feeling the the miss right now you hired Kevin um I've known Kevin for years he's exceptional Kevin's amazing what makes Kevin worldclass as a product leader to you discipline was the first word that came to mind huh in terms of focus focus what we're going to say no to like really trying to speak on behalf of the user about why we would do something or not do something like really trying to be rigorous about not not having like Fantastical dreams we have a 5year horizon for open Ai and a 10e if you have a magic wand and can paint that scenario for the 5 year in a 10 year can you paint that canvas for me for the five and 10 year I mean I can easily do it for like the next two years but if we are right and we start to make systems that are so good at you know for example helping us with scientific advancement *** actually I I will just say it *** I think in five years it looks like we have an unbelievably rapid rate of improvement in technology itself you know people are like man the AGI moment came and went whatever the like the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science and that feels like if we could sit here now and look at it it would seem like it should be very crazy and then the second part of the prediction is that Society itself actually changes surprisingly little an example of this would be that I think if you asked people five years ago if computers were going to pass the tering test they would say no *** and then if you said well what if an oracle told you it was going to they would say well it would somehow be like just this crazy breathtaking change for society and we did kind of satisfy the Turning test roughly speaking of course and Society didn't change that much it just sort of went whooshing by and that's kind of a example of what I expect to keep happening which is progress scientific progress keeps going outperforming all expectations and Society in a way that I think is good and healthy um changes not that much in the long term it will hugely change five or 10 you've been amazing *** I had this list of questions I I didn't really state to them uh thank you for putting up with my Meandering around different questions thank you everyone for coming I'm so thrilled that we were able to do this today and *** Sam thank you for making it happened man' thank you all': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:25:14,071 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:25:14,080 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:14,080 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: '*** otherwise it would have been a long list of open a eye people first how do you think about the t...' with 5 documents
2024-12-10 22:25:14,938 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:14,941 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.86s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:25:14,942 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.95s. Returned 5 results
2024-12-10 22:25:14,942 - src.processing.query_processor - INFO - Processing quotation for keywords: the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...
2024-12-10 22:25:14,971 - src.processing.query_processor - INFO - Extracted 4 keywords for quotation.
2024-12-10 22:25:14,980 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_keyword_extraction.json'
2024-12-10 22:25:14,980 - __main__ - INFO - Processed queries in 38.73s
2024-12-10 22:25:14,980 - __main__ - INFO - Starting evaluation
2024-12-10 22:25:14,981 - src.data.data_loader - INFO - Loaded JSONL file 'data/evaluation/evaluation_set_keyword.jsonl' with 3 entries successfully.
2024-12-10 22:25:14,981 - __main__ - INFO - Loaded 3 evaluation queries
2024-12-10 22:25:14,981 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:25:14,981 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:25:14,982 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:25:14,982 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:25:14,982 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:14,983 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:25:14,984 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:25:14,984 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:25:14,984 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:14,984 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:25:14,984 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:25:14,984 - __main__ - INFO - Pipeline for KeywordExtractionModule completed in 39.68s
2024-12-10 22:25:14,984 - __main__ - INFO - Completed Keyword Extraction in 39.68s
2024-12-10 22:25:14,984 - __main__ - INFO - Converting keyword results to coding format
2024-12-10 22:25:14,991 - __main__ - INFO - Keyword to coding conversion completed
2024-12-10 22:25:14,991 - __main__ - INFO - Starting Coding Analysis Pipeline
2024-12-10 22:25:14,991 - __main__ - INFO - Starting pipeline with CodingAnalysisModule
2024-12-10 22:25:14,991 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:25:14,991 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:25:14,992 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:25:14,992 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:25:14,992 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:25:14,992 - src.core.contextual_vector_db - INFO - Loading vector database and FAISS index from disk.
2024-12-10 22:25:14,993 - src.core.contextual_vector_db - INFO - Vector database metadata loaded from './data/contextual_db/contextual_vector_db.pkl' with 5 entries.
2024-12-10 22:25:14,994 - src.core.contextual_vector_db - INFO - FAISS index loaded from './data/contextual_db/faiss_index.bin' with 5 vectors.
2024-12-10 22:25:14,994 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:25:14,994 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_coding_analysis
2024-12-10 22:25:14,994 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_coding_analysis
2024-12-10 22:25:15,006 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.010s]
2024-12-10 22:25:15,008 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_coding_analysis [status:200 duration:0.003s]
2024-12-10 22:25:15,008 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_coding_analysis' already exists. Skipping creation.
2024-12-10 22:25:15,027 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.018s]
2024-12-10 22:25:15,045 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_refresh [status:200 duration:0.018s]
2024-12-10 22:25:15,045 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:25:15,045 - __main__ - INFO - Successfully indexed 5 documents in 0.04s
2024-12-10 22:25:15,045 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.05s
2024-12-10 22:25:15,045 - __main__ - INFO - Created Elasticsearch BM25 index in 0.05s
2024-12-10 22:25:15,046 - __main__ - INFO - Loading queries from data/input/queries_coding_standard.json
2024-12-10 22:25:15,046 - src.data.data_loader - INFO - Loaded JSON file 'data/input/queries_coding_standard.json' successfully with 32 entries.
2024-12-10 22:25:15,046 - __main__ - INFO - Loaded 32 queries
2024-12-10 22:25:15,046 - __main__ - INFO - Validating queries
2024-12-10 22:25:15,048 - src.processing.query_processor - INFO - Validated 32 transcripts out of 32 provided.
2024-12-10 22:25:15,048 - __main__ - INFO - Validated 32 queries
2024-12-10 22:25:15,048 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:25:15,048 - __main__ - INFO - Initializing optimizer for CodingAnalysisModule
2024-12-10 22:25:15,048 - __main__ - INFO - Initializing coding analysis optimizer
2024-12-10 22:25:15,648 - __main__ - INFO - Loaded coding training dataset: 3 samples
2024-12-10 22:25:15,663 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,673 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,682 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,692 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,699 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,706 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,713 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,719 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,725 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,732 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:25:15,738 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,745 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:25:15,752 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,758 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,764 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,771 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,778 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,784 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:25:15,791 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,796 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,802 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,808 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,814 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:25:15,821 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,826 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:25:15,832 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,838 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:25:15,845 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,850 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,857 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,863 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,868 - src.analysis.metrics - INFO - Comprehensive metric score: 0.38
2024-12-10 22:25:15,875 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,881 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,887 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,893 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,899 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:25:15,905 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,910 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,916 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,922 - src.analysis.metrics - INFO - Comprehensive metric score: 0.42000000000000004
2024-12-10 22:25:15,927 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,933 - src.analysis.metrics - INFO - Comprehensive metric score: 0.4800000000000001
2024-12-10 22:25:15,940 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,946 - src.analysis.metrics - INFO - Comprehensive metric score: 0.5
2024-12-10 22:25:15,951 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,958 - src.analysis.metrics - INFO - Comprehensive metric score: 0.26
2024-12-10 22:25:15,965 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,971 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:15,976 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:15,983 - src.analysis.metrics - INFO - Comprehensive metric score: 0.34
2024-12-10 22:25:15,989 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:15,995 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:16,003 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:16,009 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:16,016 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:16,022 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:16,028 - src.analysis.metrics - INFO - Comprehensive metric score: 0.28
2024-12-10 22:25:16,036 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:16,043 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:16,049 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:16,055 - src.analysis.metrics - INFO - Comprehensive metric score: 0.88
2024-12-10 22:25:16,061 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9999999999999999
2024-12-10 22:25:16,069 - src.analysis.metrics - INFO - Comprehensive metric score: 0.44000000000000006
2024-12-10 22:25:16,070 - __main__ - INFO - Compiled optimized coding program in 0.42s
2024-12-10 22:25:16,071 - __main__ - INFO - Saved optimized coding program to data/optimized/optimized_coding_program.json
2024-12-10 22:25:16,071 - __main__ - INFO - Coding optimizer initialization completed in 1.02s
2024-12-10 22:25:16,071 - __main__ - INFO - Initialized optimizer in 1.02s
2024-12-10 22:25:16,071 - __main__ - INFO - Initializing CodingAnalysisModule
2024-12-10 22:25:16,075 - __main__ - INFO - Initialized CodingAnalysisModule with assertions
2024-12-10 22:25:16,075 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:25:16,075 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_coding_analysis.json'.
2024-12-10 22:25:16,075 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:25:16,075 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:16,099 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.023s]
2024-12-10 22:25:16,111 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_17
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_40
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_59
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_69
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_66
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:16,112 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:16,112 - src.retrieval.retrieval - INFO - Filtered 18 chunks due to missing metadata.
2024-12-10 22:25:16,112 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:16,112 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better...': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:25:16,113 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:16,118 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:16,118 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:25:16,891 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:16,895 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.78s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:16,895 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.82s. Returned 5 results
2024-12-10 22:25:16,895 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='we are going to try our hardest and believe we will succeed at making our models better and better a...', Keywords=['improvement', 'believe', 'models', 'better']
2024-12-10 22:25:16,896 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:16,918 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:16,919 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:16,919 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...'
2024-12-10 22:25:16,919 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:16,955 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.036s]
2024-12-10 22:25:16,973 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.007s]
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_23
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:16,975 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:16,975 - src.retrieval.retrieval - INFO - Filtered 25 chunks due to missing metadata.
2024-12-10 22:25:16,976 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:16,976 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do...': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_3]
2024-12-10 22:25:16,976 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.06s
2024-12-10 22:25:16,983 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:16,983 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...' with 5 documents
2024-12-10 22:25:17,687 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:17,690 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9996, Bottom score: 0.0006
2024-12-10 22:25:17,691 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:25:17,691 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...', Keywords=['reasoning', 'unlock', 'improvement']
2024-12-10 22:25:17,691 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:17,716 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:17,717 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:17,717 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...'
2024-12-10 22:25:17,717 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:17,747 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.030s]
2024-12-10 22:25:17,764 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:25:17,766 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:17,767 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:25:17,767 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:25:17,767 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:17,767 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:17,767 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:17,767 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:17,767 - src.retrieval.retrieval - INFO - Filtered 7 chunks due to missing metadata.
2024-12-10 22:25:17,767 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:17,767 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:25:17,767 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:17,775 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:17,775 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...' with 5 documents
2024-12-10 22:25:18,501 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:18,503 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9999, Bottom score: 0.0010
2024-12-10 22:25:18,503 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.79s. Returned 5 results
2024-12-10 22:25:18,503 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there will be many trillions of dollars of market cap that gets created new market cap that gets cre...', Keywords=['market cap', 'AI innovations', 'impossible products']
2024-12-10 22:25:18,504 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:18,528 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:18,528 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:18,528 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...'
2024-12-10 22:25:18,528 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:18,566 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.038s]
2024-12-10 22:25:18,592 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.012s]
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_75
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:18,595 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_15
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_59
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_69
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_18
2024-12-10 22:25:18,596 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:25:18,596 - src.retrieval.retrieval - INFO - Filtered 35 chunks due to missing metadata.
2024-12-10 22:25:18,596 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:18,596 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think people have like internalized the rate of Improvement and have heard us on what we intend to do': [interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_3]
2024-12-10 22:25:18,596 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:25:18,604 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:18,604 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...' with 5 documents
2024-12-10 22:25:19,362 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:19,366 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:25:19,366 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.84s. Returned 5 results
2024-12-10 22:25:19,366 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think people have like internalized the rate of Improvement and have heard us on what we intend to...', Keywords=['internalized', 'rate of improvement', 'commitment']
2024-12-10 22:25:19,367 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:19,393 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:19,393 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:19,393 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...'
2024-12-10 22:25:19,393 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:19,414 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.021s]
2024-12-10 22:25:19,425 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:25:19,425 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:25:19,425 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 4 (required min_chunks=1)
2024-12-10 22:25:19,425 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:25:19,425 - src.retrieval.reranking - INFO - Initial retrieval returned 4 results in 0.03s
2024-12-10 22:25:19,434 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:19,434 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...' with 4 documents
2024-12-10 22:25:20,133 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:20,136 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:25:20,136 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.74s. Returned 4 results
2024-12-10 22:25:20,136 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there will be9 trillion dollars of value created did every single year which will offset the $9 tril...', Keywords=['value creation', 'capax', 'AI models']
2024-12-10 22:25:20,137 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:20,163 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:20,164 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:20,164 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...'
2024-12-10 22:25:20,164 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:20,192 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:25:20,207 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:20,208 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:20,208 - src.retrieval.retrieval - INFO - Filtered 11 chunks due to missing metadata.
2024-12-10 22:25:20,208 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:20,208 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:25:20,209 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:20,217 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:20,217 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...' with 5 documents
2024-12-10 22:25:22,004 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:22,007 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.79s. Top score: 0.9991, Bottom score: 0.0000
2024-12-10 22:25:22,007 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.84s. Returned 5 results
2024-12-10 22:25:22,007 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='think about how much economic value gets unlocked for the world if anybody can just describe like a ...', Keywords=['economic value', 'software needs', 'transformative potential', 'reasoning']
2024-12-10 22:25:22,007 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:22,035 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:22,036 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:22,036 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's clearly a really important place in the Eos system for open source models...'
2024-12-10 22:25:22,036 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:22,062 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.025s]
2024-12-10 22:25:22,074 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.007s]
2024-12-10 22:25:22,076 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:25:22,076 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:25:22,076 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:25:22,076 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_45
2024-12-10 22:25:22,076 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:22,076 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:22,076 - src.retrieval.retrieval - INFO - Filtered 6 chunks due to missing metadata.
2024-12-10 22:25:22,076 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:22,076 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's clearly a really important place in the Eos system for open source models': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:25:22,076 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:22,082 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:22,082 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's clearly a really important place in the Eos system for open source models...' with 5 documents
2024-12-10 22:25:22,740 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:22,743 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.66s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:22,743 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.71s. Returned 5 results
2024-12-10 22:25:22,743 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there's clearly a really important place in the Eos system for open source models...', Keywords=['open source models', 'Eos system', 'transformative potential']
2024-12-10 22:25:22,744 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:22,769 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:22,769 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:22,770 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...'
2024-12-10 22:25:22,770 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:22,794 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.024s]
2024-12-10 22:25:22,809 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:25:22,809 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:22,809 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:25:22,809 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:22,809 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:22,809 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:22,809 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:22,810 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:22,810 - src.retrieval.retrieval - INFO - Filtered 15 chunks due to missing metadata.
2024-12-10 22:25:22,810 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:22,810 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:25:22,810 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:22,818 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:22,818 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...' with 5 documents
2024-12-10 22:25:23,632 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:23,634 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.82s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:23,635 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.86s. Returned 5 results
2024-12-10 22:25:23,635 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the category I think though is more interesting is not the one that people normally talk about where...', Keywords=['smart senior co-worker', 'transformative potential', 'complex tasks']
2024-12-10 22:25:23,635 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:23,660 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:23,661 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:23,661 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...'
2024-12-10 22:25:23,661 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:23,688 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:25:23,705 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:23,706 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:23,707 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:23,707 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:23,707 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:23,707 - src.retrieval.retrieval - INFO - Filtered 11 chunks due to missing metadata.
2024-12-10 22:25:23,707 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:23,707 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:23,707 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:23,715 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:23,715 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...' with 5 documents
2024-12-10 22:25:24,421 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:24,424 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:25:24,424 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.76s. Returned 5 results
2024-12-10 22:25:24,424 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='reasoning is our current most important area of focus I think this is what unlocks the next like mas...', Keywords=['reasoning', 'economic value', 'transformation']
2024-12-10 22:25:24,425 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:24,451 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:24,451 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:24,451 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair...'
2024-12-10 22:25:24,451 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:24,488 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.037s]
2024-12-10 22:25:24,523 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.022s]
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_81
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_53
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_40
2024-12-10 22:25:24,532 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_89
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_75
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_15
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_51
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_22
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_31
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_57
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_88
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:24,533 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:25:24,533 - src.retrieval.retrieval - INFO - Filtered 40 chunks due to missing metadata.
2024-12-10 22:25:24,533 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:24,533 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the actual like Revenue we can make from a model I think justifies the investment to be fair': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:25:24,534 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:25:24,542 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:24,542 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair...' with 5 documents
2024-12-10 22:25:25,290 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:25,291 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.75s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:25:25,291 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.84s. Returned 5 results
2024-12-10 22:25:25,291 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the actual like Revenue we can make from a model I think justifies the investment to be fair...', Keywords=['Revenue', 'Investment', 'AI Models']
2024-12-10 22:25:25,291 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:25,308 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:25,308 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:25,308 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...'
2024-12-10 22:25:25,308 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:25,343 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.035s]
2024-12-10 22:25:25,356 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:25,357 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:25,357 - src.retrieval.retrieval - INFO - Filtered 13 chunks due to missing metadata.
2024-12-10 22:25:25,357 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:25,357 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:25:25,357 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:25,364 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:25,364 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...' with 5 documents
2024-12-10 22:25:26,030 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:26,034 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.67s. Top score: 0.9974, Bottom score: 0.0000
2024-12-10 22:25:26,034 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.73s. Returned 5 results
2024-12-10 22:25:26,034 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...', Keywords=['Transformer', 'innovation', 'replicate', 'culture', 'human talent']
2024-12-10 22:25:26,035 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:26,059 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:26,060 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:26,060 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the repeated ability to go off and do something new and totally unproven...'
2024-12-10 22:25:26,060 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:26,090 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.030s]
2024-12-10 22:25:26,107 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.007s]
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_16
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_55
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_67
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_41
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:26,109 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:26,109 - src.retrieval.retrieval - INFO - Filtered 19 chunks due to missing metadata.
2024-12-10 22:25:26,109 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:26,109 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the repeated ability to go off and do something new and totally unproven': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:26,110 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:26,117 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:26,117 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the repeated ability to go off and do something new and totally unproven...' with 5 documents
2024-12-10 22:25:26,961 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:26,963 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.85s. Top score: 0.9962, Bottom score: 0.0000
2024-12-10 22:25:26,963 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.90s. Returned 5 results
2024-12-10 22:25:26,963 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the repeated ability to go off and do something new and totally unproven...', Keywords=['innovation', 'unproven', 'ability']
2024-12-10 22:25:26,964 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:26,985 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:26,985 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:26,986 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture...'
2024-12-10 22:25:26,986 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:27,007 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.021s]
2024-12-10 22:25:27,018 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:25:27,019 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:25:27,019 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:27,019 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's a huge amount of wasted human talent because this is not an organization style or culture': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:25:27,019 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:25:27,027 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:27,027 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture...' with 5 documents
2024-12-10 22:25:27,755 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:27,757 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:25:27,758 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:25:27,758 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there's a huge amount of wasted human talent because this is not an organization style or culture...', Keywords=['wasted human talent', 'organization style', 'innovation']
2024-12-10 22:25:27,758 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:27,783 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:27,783 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:27,784 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential...'
2024-12-10 22:25:27,784 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:27,811 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.027s]
2024-12-10 22:25:27,831 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.008s]
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_40
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_81
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_23
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:27,833 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:27,833 - src.retrieval.retrieval - INFO - Filtered 21 chunks due to missing metadata.
2024-12-10 22:25:27,834 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:27,834 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I hope it'll get us much better than we are now at helping get everyone to their Max potential': [interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_3]
2024-12-10 22:25:27,834 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:27,843 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:27,843 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential...' with 5 documents
2024-12-10 22:25:28,569 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:28,572 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:25:28,572 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.79s. Returned 5 results
2024-12-10 22:25:28,572 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I hope it'll get us much better than we are now at helping get everyone to their Max potential...', Keywords=['Max potential', 'innovation', 'unlock potential']
2024-12-10 22:25:28,573 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:28,601 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:28,602 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:28,602 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...'
2024-12-10 22:25:28,602 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:28,631 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.029s]
2024-12-10 22:25:28,642 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:28,643 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:28,643 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:28,643 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:28,643 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do.': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:28,643 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:28,650 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:28,650 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...' with 5 documents
2024-12-10 22:25:29,359 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:29,362 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:25:29,362 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.76s. Returned 5 results
2024-12-10 22:25:29,363 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I badly underappreciated the amount of work it took to be able to like keep charging at the next big...', Keywords=['underappreciated', 'work', 'next big step', 'neglecting']
2024-12-10 22:25:29,363 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:29,388 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:29,388 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:29,389 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me....'
2024-12-10 22:25:29,389 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:29,408 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.020s]
2024-12-10 22:25:29,420 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:25:29,420 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:29,420 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:29,420 - src.retrieval.retrieval - INFO - Filtered 2 chunks due to missing metadata.
2024-12-10 22:25:29,420 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:29,420 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there was either no playbook for this or someone had a secret Playbook they didn't give me.': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:29,421 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:25:29,428 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:29,428 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me....' with 5 documents
2024-12-10 22:25:30,152 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:30,155 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9996, Bottom score: 0.0000
2024-12-10 22:25:30,156 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:25:30,156 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='there was either no playbook for this or someone had a secret Playbook they didn't give me....', Keywords=['playbook', 'innovation', 'challenges', 'unproven ideas', 'human talent']
2024-12-10 22:25:30,156 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:30,183 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:30,184 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:30,184 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him....'
2024-12-10 22:25:30,184 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:30,225 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.041s]
2024-12-10 22:25:30,235 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:30,235 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:30,235 - src.retrieval.retrieval - INFO - Filtered 9 chunks due to missing metadata.
2024-12-10 22:25:30,235 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:30,235 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you should hire incredibly young people under 30 and that is what Peter teal taught him.': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3]
2024-12-10 22:25:30,235 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:30,242 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:30,242 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him....' with 5 documents
2024-12-10 22:25:30,956 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:30,967 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:30,967 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.78s. Returned 5 results
2024-12-10 22:25:30,967 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='you should hire incredibly young people under 30 and that is what Peter teal taught him....', Keywords=['young people', 'innovation', 'talent']
2024-12-10 22:25:30,968 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:31,013 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:31,013 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:31,014 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...'
2024-12-10 22:25:31,014 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:31,044 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:25:31,052 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:25:31,052 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:31,052 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:31,052 - src.retrieval.retrieval - INFO - Filtered 2 chunks due to missing metadata.
2024-12-10 22:25:31,052 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:31,052 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built.': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:25:31,053 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:31,058 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:31,058 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...' with 5 documents
2024-12-10 22:25:31,797 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:31,800 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:25:31,800 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.79s. Returned 5 results
2024-12-10 22:25:31,801 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='when you're like designing some of the most complex and massively expensive computer systems that Hu...', Keywords=['designing', 'complex', 'expensive', 'computer systems', 'innovation']
2024-12-10 22:25:31,801 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:31,828 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:31,828 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:31,828 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you want both....'
2024-12-10 22:25:31,828 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:31,877 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.049s]
2024-12-10 22:25:31,906 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.010s]
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_85
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_35
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_29
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_28
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_23
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_16
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_70
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_66
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_69
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_14
2024-12-10 22:25:31,910 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_18
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_67
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_60
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_88
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:31,911 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:25:31,911 - src.retrieval.retrieval - INFO - Filtered 45 chunks due to missing metadata.
2024-12-10 22:25:31,911 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:31,911 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you want both.': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3]
2024-12-10 22:25:31,911 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.08s
2024-12-10 22:25:31,920 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:31,920 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you want both....' with 5 documents
2024-12-10 22:25:32,650 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:32,653 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9723, Bottom score: 0.0000
2024-12-10 22:25:32,654 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.83s. Returned 5 results
2024-12-10 22:25:32,654 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='you want both....', Keywords=['innovation', 'replication', 'culture']
2024-12-10 22:25:32,654 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:32,675 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:32,675 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:32,676 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...'
2024-12-10 22:25:32,676 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:32,693 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.017s]
2024-12-10 22:25:32,701 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:25:32,701 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:25:32,701 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:32,701 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3]
2024-12-10 22:25:32,702 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:25:32,710 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:32,710 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...' with 5 documents
2024-12-10 22:25:33,545 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:33,548 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.84s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:33,548 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.87s. Returned 5 results
2024-12-10 22:25:33,549 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='inexperience does not inherently mean not valuable and there are incredibly high potential people at...', Keywords=['inexperience', 'potential', 'value']
2024-12-10 22:25:33,549 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:33,574 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:33,575 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:33,575 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...'
2024-12-10 22:25:33,575 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:33,603 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:25:33,616 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:25:33,616 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:33,617 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:33,617 - src.retrieval.retrieval - INFO - Filtered 13 chunks due to missing metadata.
2024-12-10 22:25:33,617 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:33,617 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:33,617 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:33,624 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:33,625 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...' with 5 documents
2024-12-10 22:25:34,274 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:34,276 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.65s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:34,277 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.70s. Returned 5 results
2024-12-10 22:25:34,277 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think developers use multiple models most of the time and I'm not sure how that's all going to evo...', Keywords=['multiple models', 'AG genified World', 'collaboration', 'reasoning capabilities']
2024-12-10 22:25:34,277 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:34,301 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:34,301 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:34,301 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing...'
2024-12-10 22:25:34,302 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:34,332 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.030s]
2024-12-10 22:25:34,352 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.009s]
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_19
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_15
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_73
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:34,355 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_14
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_46
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:34,356 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:34,356 - src.retrieval.retrieval - INFO - Filtered 28 chunks due to missing metadata.
2024-12-10 22:25:34,356 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:34,356 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:25:34,356 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:34,364 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:34,364 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing...' with 5 documents
2024-12-10 22:25:35,159 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:35,162 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.80s. Top score: 1.0000, Bottom score: 0.0127
2024-12-10 22:25:35,163 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.86s. Returned 5 results
2024-12-10 22:25:35,163 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='we have a lot of people here who are excited to build AGI and that that's a very motivating thing...', Keywords=['AGI', 'motivation', 'collaboration']
2024-12-10 22:25:35,163 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:35,186 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:35,186 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:35,187 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions...'
2024-12-10 22:25:35,187 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:35,197 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.010s]
2024-12-10 22:25:35,203 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.005s]
2024-12-10 22:25:35,203 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:25:35,203 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 3 (required min_chunks=1)
2024-12-10 22:25:35,203 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the heaviest things in life are not iron or gold but unmade decisions': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:25:35,203 - src.retrieval.reranking - INFO - Initial retrieval returned 3 results in 0.02s
2024-12-10 22:25:35,212 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:35,212 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions...' with 3 documents
2024-12-10 22:25:36,207 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:36,208 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.00s. Top score: 0.9963, Bottom score: 0.0000
2024-12-10 22:25:36,208 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.02s. Returned 3 results
2024-12-10 22:25:36,208 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the heaviest things in life are not iron or gold but unmade decisions...', Keywords=['decisions', 'collaboration', 'AI development']
2024-12-10 22:25:36,208 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:36,233 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:36,233 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:36,233 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...'
2024-12-10 22:25:36,233 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:36,249 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.015s]
2024-12-10 22:25:36,261 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:36,262 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:36,262 - src.retrieval.retrieval - INFO - Filtered 16 chunks due to missing metadata.
2024-12-10 22:25:36,262 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:36,262 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_2]
2024-12-10 22:25:36,262 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:25:36,268 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:36,268 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...' with 5 documents
2024-12-10 22:25:37,159 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:37,162 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.89s. Top score: 0.9999, Bottom score: 0.0002
2024-12-10 22:25:37,162 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.93s. Returned 5 results
2024-12-10 22:25:37,163 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think the wrong way to do that is to have one person you lean on for everything and the right way ...', Keywords=['collaboration', 'decision-making', 'diversity']
2024-12-10 22:25:37,163 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:37,189 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:37,189 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:37,189 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...'
2024-12-10 22:25:37,189 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:37,371 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:25:37,383 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_57
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_89
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_46
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:37,384 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:37,384 - src.retrieval.retrieval - INFO - Filtered 15 chunks due to missing metadata.
2024-12-10 22:25:37,384 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:37,384 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before': [interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:37,385 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.20s
2024-12-10 22:25:37,390 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:37,390 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...' with 5 documents
2024-12-10 22:25:39,156 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:39,159 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.77s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:25:39,159 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.97s. Returned 5 results
2024-12-10 22:25:39,159 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...', Keywords=['ecosystem complexity', 'fractal scan', 'collaboration', 'integrated systems']
2024-12-10 22:25:39,160 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:39,187 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:39,187 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:39,187 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...'
2024-12-10 22:25:39,188 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:39,227 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.039s]
2024-12-10 22:25:39,245 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_41
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_57
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_29
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:25:39,246 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:25:39,247 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:39,247 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:39,247 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:39,247 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:39,247 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:39,247 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:39,247 - src.retrieval.retrieval - INFO - Filtered 28 chunks due to missing metadata.
2024-12-10 22:25:39,247 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:39,247 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'it was very like one of the defining things about the internet Revolution was it was actually really easy to get started': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:25:39,247 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.06s
2024-12-10 22:25:39,254 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:39,254 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...' with 5 documents
2024-12-10 22:25:40,155 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:40,158 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.90s. Top score: 0.9983, Bottom score: 0.0000
2024-12-10 22:25:40,158 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.97s. Returned 5 results
2024-12-10 22:25:40,158 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='it was very like one of the defining things about the internet Revolution was it was actually really...', Keywords=['internet Revolution', 'easy to get started', 'AI development']
2024-12-10 22:25:40,159 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:40,187 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:40,188 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:40,188 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...'
2024-12-10 22:25:40,188 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:40,218 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.030s]
2024-12-10 22:25:40,231 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.003s]
2024-12-10 22:25:40,231 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:40,231 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:40,231 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:40,231 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:40,231 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:40,231 - src.retrieval.retrieval - INFO - Filtered 5 chunks due to missing metadata.
2024-12-10 22:25:40,231 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:40,231 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:40,231 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.04s
2024-12-10 22:25:40,240 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:40,240 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...' with 5 documents
2024-12-10 22:25:40,948 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:40,950 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:25:40,950 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.76s. Returned 5 results
2024-12-10 22:25:40,950 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the one I like the most caveat by my earlier comment that I don't think people should be doing this ...', Keywords=['discovery', 'scaling properties', 'analogies']
2024-12-10 22:25:40,951 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:40,975 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:40,975 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:40,975 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...'
2024-12-10 22:25:40,975 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:41,004 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.028s]
2024-12-10 22:25:41,022 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.009s]
2024-12-10 22:25:41,025 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:41,025 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:41,026 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:41,026 - src.retrieval.retrieval - INFO - Filtered 13 chunks due to missing metadata.
2024-12-10 22:25:41,026 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:41,026 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data': [interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:25:41,026 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:41,034 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:41,035 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...' with 5 documents
2024-12-10 22:25:41,786 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:41,789 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.75s. Top score: 0.9999, Bottom score: 0.0001
2024-12-10 22:25:41,790 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.81s. Returned 5 results
2024-12-10 22:25:41,790 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='something about an AI that can understand your whole life doesn't have to like literally be infinite...', Keywords=['AI', 'understand', 'data', 'enhance']
2024-12-10 22:25:41,790 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:41,816 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:41,816 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:41,816 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...'
2024-12-10 22:25:41,816 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:41,856 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.040s]
2024-12-10 22:25:41,878 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.007s]
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_42
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:25:41,880 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:41,881 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:25:41,881 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_82
2024-12-10 22:25:41,881 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:25:41,881 - src.retrieval.retrieval - INFO - Filtered 26 chunks due to missing metadata.
2024-12-10 22:25:41,881 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:41,881 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think to really have do what they've done and built I thought about like a bunch of researchers I could name': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:25:41,881 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:25:41,890 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:41,890 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...' with 5 documents
2024-12-10 22:25:42,577 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:42,580 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 0.9994, Bottom score: 0.0000
2024-12-10 22:25:42,580 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.76s. Returned 5 results
2024-12-10 22:25:42,581 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think to really have do what they've done and built I thought about like a bunch of researchers I ...', Keywords=['AI', 'researchers', 'leadership']
2024-12-10 22:25:42,581 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:42,606 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:42,606 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:42,606 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think that product is a weakness of mine in general...'
2024-12-10 22:25:42,606 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:42,649 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.042s]
2024-12-10 22:25:42,689 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.026s]
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_81
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_58
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_65
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_32
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_17
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_38
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_44
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_48
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_56
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_66
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_35
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_13
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_46
2024-12-10 22:25:42,702 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_73
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_43
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_14
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_24
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_60
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_49
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_30
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_77
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_51
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_72
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_37
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_71
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_52
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_83
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_64
2024-12-10 22:25:42,703 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_68
2024-12-10 22:25:42,703 - src.retrieval.retrieval - INFO - Filtered 45 chunks due to missing metadata.
2024-12-10 22:25:42,703 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:42,703 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think that product is a weakness of mine in general': [interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2]
2024-12-10 22:25:42,704 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.10s
2024-12-10 22:25:42,711 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:42,712 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think that product is a weakness of mine in general...' with 5 documents
2024-12-10 22:25:43,379 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:43,382 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.67s. Top score: 0.9990, Bottom score: 0.0000
2024-12-10 22:25:43,383 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.78s. Returned 5 results
2024-12-10 22:25:43,383 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I think that product is a weakness of mine in general...', Keywords=['product', 'weakness', 'leadership']
2024-12-10 22:25:43,383 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:43,412 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:43,412 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:43,413 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...'
2024-12-10 22:25:43,413 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:43,443 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.030s]
2024-12-10 22:25:43,458 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.004s]
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_1
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_86
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_3
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_74
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_9
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_4
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_34
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_2
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_36
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_10
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_11
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_79
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_54
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_7
2024-12-10 22:25:43,459 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_8
2024-12-10 22:25:43,459 - src.retrieval.retrieval - INFO - Filtered 18 chunks due to missing metadata.
2024-12-10 22:25:43,460 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:43,460 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years': [interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2]
2024-12-10 22:25:43,460 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:43,468 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:43,468 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...' with 5 documents
2024-12-10 22:25:44,204 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:44,208 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:44,208 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.80s. Returned 5 results
2024-12-10 22:25:44,208 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...', Keywords=['Discovery', 'Physics', 'AI', 'Years']
2024-12-10 22:25:44,209 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:44,236 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:44,236 - src.processing.query_processor - INFO - Developed 3 codes for coding analysis.
2024-12-10 22:25:44,237 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...'
2024-12-10 22:25:44,237 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:44,269 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.032s]
2024-12-10 22:25:44,286 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_coding_analysis/_search [status:200 duration:0.006s]
2024-12-10 22:25:44,287 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_80
2024-12-10 22:25:44,287 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_0
2024-12-10 22:25:44,287 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_5
2024-12-10 22:25:44,287 - src.retrieval.retrieval - WARNING - Chunk metadata not found for chunk_id Document_chunk_6
2024-12-10 22:25:44,287 - src.retrieval.retrieval - INFO - Filtered 4 chunks due to missing metadata.
2024-12-10 22:25:44,287 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:44,287 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:25:44,287 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.05s
2024-12-10 22:25:44,296 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:44,296 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...' with 5 documents
2024-12-10 22:25:45,812 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:45,816 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.52s. Top score: 0.9998, Bottom score: 0.0006
2024-12-10 22:25:45,816 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.58s. Returned 5 results
2024-12-10 22:25:45,816 - src.processing.query_processor - INFO - Processing transcript for coding analysis: Quotation='the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...', Keywords=['pace of progress', 'discovering new stuff', 'AI research', 'Science']
2024-12-10 22:25:45,817 - my_logger - INFO - Starting coding analysis.
2024-12-10 22:25:45,838 - my_logger - INFO - Successfully completed coding analysis.
2024-12-10 22:25:45,838 - src.processing.query_processor - INFO - Developed 2 codes for coding analysis.
2024-12-10 22:25:45,848 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_coding_analysis.json'
2024-12-10 22:25:45,848 - __main__ - INFO - Processed queries in 29.77s
2024-12-10 22:25:45,848 - __main__ - INFO - Starting evaluation
2024-12-10 22:25:45,848 - src.data.data_loader - INFO - Loaded JSONL file 'data/evaluation/evaluation_set_coding.jsonl' with 3 entries successfully.
2024-12-10 22:25:45,848 - __main__ - INFO - Loaded 3 evaluation queries
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:25:45,849 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:25:45,849 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Starting evaluation of 3 queries.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - WARNING - No golden contents found for query 'what is digital transformation?'. Skipping evaluation for this query.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - WARNING - No golden contents found for query 'why is aman not promoting digitalization?'. Skipping evaluation for this query.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - WARNING - No golden contents found for query 'The question is how are we going to deal with these risks these are the key that we are working on Nellie please uh and also Sally provide your perspective your data or the um you know mainly how you are localizing for example in Africa these uh challenges and try to provide solutions while you are going along the way.'. Skipping evaluation for this query.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Total Queries: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries with Golden Data: 3
2024-12-10 22:25:45,850 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:25:45,850 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:25:45,850 - __main__ - INFO - Pipeline for CodingAnalysisModule completed in 30.86s
2024-12-10 22:25:45,851 - __main__ - INFO - Completed Coding Analysis in 30.86s
2024-12-10 22:25:45,851 - __main__ - INFO - Converting coding results to theme format
2024-12-10 22:25:45,856 - __main__ - INFO - Coding to theme conversion completed
2024-12-10 22:25:45,856 - __main__ - INFO - Starting Theme Development Pipeline
2024-12-10 22:25:45,856 - __main__ - INFO - Starting pipeline with ThemedevelopmentAnalysisModule
2024-12-10 22:25:45,856 - __main__ - INFO - Configuring DSPy Language Model
2024-12-10 22:25:45,856 - __main__ - INFO - Loading codebase chunks from data/codebase_chunks/codebase_chunks.json
2024-12-10 22:25:45,857 - src.data.data_loader - INFO - Loaded JSON file 'data/codebase_chunks/codebase_chunks.json' successfully with 1 entries.
2024-12-10 22:25:45,857 - __main__ - INFO - Loaded 1 chunks in 0.00s
2024-12-10 22:25:45,857 - __main__ - INFO - Loading data into ContextualVectorDB
2024-12-10 22:25:45,857 - src.core.contextual_vector_db - INFO - Loading vector database and FAISS index from disk.
2024-12-10 22:25:45,857 - src.core.contextual_vector_db - INFO - Vector database metadata loaded from './data/contextual_db/contextual_vector_db.pkl' with 5 entries.
2024-12-10 22:25:45,857 - src.core.contextual_vector_db - INFO - FAISS index loaded from './data/contextual_db/faiss_index.bin' with 5 vectors.
2024-12-10 22:25:45,857 - __main__ - INFO - Loaded data into ContextualVectorDB in 0.00s
2024-12-10 22:25:45,857 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_theme_development
2024-12-10 22:25:45,857 - __main__ - INFO - Creating Elasticsearch BM25 index: contextual_bm25_index_theme_development
2024-12-10 22:25:45,869 - elastic_transport.transport - INFO - HEAD http://localhost:9200/ [status:200 duration:0.011s]
2024-12-10 22:25:45,874 - elastic_transport.transport - INFO - HEAD http://localhost:9200/contextual_bm25_index_theme_development [status:200 duration:0.005s]
2024-12-10 22:25:45,874 - src.core.elasticsearch_bm25 - INFO - Index 'contextual_bm25_index_theme_development' already exists. Skipping creation.
2024-12-10 22:25:45,895 - elastic_transport.transport - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.021s]
2024-12-10 22:25:45,909 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_refresh [status:200 duration:0.013s]
2024-12-10 22:25:45,909 - src.core.elasticsearch_bm25 - INFO - Indexed 5/5 documents successfully
2024-12-10 22:25:45,909 - __main__ - INFO - Successfully indexed 5 documents in 0.03s
2024-12-10 22:25:45,909 - __main__ - INFO - Elasticsearch BM25 index creation completed in 0.05s
2024-12-10 22:25:45,909 - __main__ - INFO - Created Elasticsearch BM25 index in 0.05s
2024-12-10 22:25:45,909 - __main__ - INFO - Loading queries from data/input/input/queries_theme.json
2024-12-10 22:25:45,909 - src.data.data_loader - INFO - Loaded JSON file 'data/input/input/queries_theme.json' successfully with 32 entries.
2024-12-10 22:25:45,910 - __main__ - INFO - Loaded 32 queries
2024-12-10 22:25:45,910 - __main__ - INFO - Validating queries
2024-12-10 22:25:45,911 - src.processing.query_processor - INFO - Validated 32 transcripts out of 32 provided.
2024-12-10 22:25:45,911 - __main__ - INFO - Validated 32 queries
2024-12-10 22:25:45,911 - __main__ - INFO - Validated queries in 0.00s
2024-12-10 22:25:45,912 - __main__ - INFO - Initializing optimizer for ThemedevelopmentAnalysisModule
2024-12-10 22:25:45,912 - __main__ - INFO - Initializing theme development optimizer
2024-12-10 22:25:46,497 - __main__ - INFO - Loaded theme training dataset: 1 samples
2024-12-10 22:25:46,510 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,521 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,531 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,539 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,546 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,553 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,560 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,566 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,573 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,579 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,586 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,592 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,599 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,605 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,612 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,617 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,623 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,629 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,636 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,642 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,648 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,654 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,660 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,666 - src.analysis.metrics - INFO - Comprehensive metric score: 0.9799999999999999
2024-12-10 22:25:46,667 - __main__ - INFO - Compiled optimized theme program in 0.17s
2024-12-10 22:25:46,667 - __main__ - INFO - Saved optimized theme program to data/optimized/optimized_theme_program.json
2024-12-10 22:25:46,667 - __main__ - INFO - Theme optimizer initialization completed in 0.76s
2024-12-10 22:25:46,667 - __main__ - INFO - Initialized optimizer in 0.76s
2024-12-10 22:25:46,667 - __main__ - INFO - Initializing ThemedevelopmentAnalysisModule
2024-12-10 22:25:46,670 - __main__ - INFO - Initialized ThemedevelopmentAnalysisModule with assertions
2024-12-10 22:25:46,670 - __main__ - INFO - Processing queries with k=20
2024-12-10 22:25:46,670 - src.processing.query_processor - INFO - Starting to process transcripts for output file 'data/output/query_results_theme_development.json'.
2024-12-10 22:25:46,670 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...'
2024-12-10 22:25:46,671 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:46,677 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:25:46,682 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:25:46,682 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:25:46,682 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:46,682 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we are going to try our hardest and believe we will succeed at making our models better and better and better...     ': [interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:25:46,683 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.01s
2024-12-10 22:25:46,687 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:46,687 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we are going to try our hardest and believe we will succeed at making our models better and better a...' with 5 documents
2024-12-10 22:25:47,367 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:47,370 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.68s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:25:47,371 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.70s. Returned 5 results
2024-12-10 22:25:47,371 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='we are going to try our hardest and believe we will succeed at making our models better and better a...', Keywords=['improvement', 'believe', 'models', 'better'], Codes=3
2024-12-10 22:25:47,372 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:25:47,397 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:25:57,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:25:57,104 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:25:57,106 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:25:57,106 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:25:57,106 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...'
2024-12-10 22:25:57,107 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:25:57,115 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.008s]
2024-12-10 22:25:57,121 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:25:57,121 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:25:57,121 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:25:57,121 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting years to do...     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_3]
2024-12-10 22:25:57,121 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:25:57,132 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:25:57,132 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...' with 5 documents
2024-12-10 22:25:57,896 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:25:57,900 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.77s. Top score: 0.9996, Bottom score: 0.0006
2024-12-10 22:25:57,900 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.79s. Returned 5 results
2024-12-10 22:25:57,900 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think reasoning will unlock I hope reason will unlock a lot of the things that we've been waiting ...', Keywords=['reasoning', 'unlock', 'improvement'], Codes=3
2024-12-10 22:25:57,901 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:25:57,924 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:26:08,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:26:08,035 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:26:08,037 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:26:08,038 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:26:08,038 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...'
2024-12-10 22:26:08,038 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:26:08,051 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:26:08,058 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:26:08,058 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:26:08,058 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:26:08,058 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be many trillions of dollars of market cap that gets created new market cap that gets created by using AI to build products and services that were either impossible or quite impractical before     ': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_2]
2024-12-10 22:26:08,058 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:26:08,066 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:26:08,066 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be many trillions of dollars of market cap that gets created new market cap that gets cre...' with 5 documents
2024-12-10 22:26:13,179 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:26:13,182 - src.retrieval.reranking - INFO - Cohere reranking completed in 5.12s. Top score: 0.9999, Bottom score: 0.0010
2024-12-10 22:26:13,182 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 5.14s. Returned 5 results
2024-12-10 22:26:13,182 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there will be many trillions of dollars of market cap that gets created new market cap that gets cre...', Keywords=['market cap', 'AI innovations', 'impossible products'], Codes=2
2024-12-10 22:26:13,183 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:26:13,208 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:26:22,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:26:22,378 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:26:22,380 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:26:22,380 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:26:22,381 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...'
2024-12-10 22:26:22,381 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:26:22,393 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:26:22,400 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:26:22,401 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:26:22,401 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:26:22,401 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think people have like internalized the rate of Improvement and have heard us on what we intend to do     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:26:22,401 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:26:22,410 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:26:22,411 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think people have like internalized the rate of Improvement and have heard us on what we intend to...' with 5 documents
2024-12-10 22:26:23,641 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:26:23,644 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.23s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:26:23,644 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.26s. Returned 5 results
2024-12-10 22:26:23,645 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think people have like internalized the rate of Improvement and have heard us on what we intend to...', Keywords=['internalized', 'rate of improvement', 'commitment'], Codes=3
2024-12-10 22:26:23,645 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:26:23,673 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:26:31,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:26:31,510 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:26:31,513 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:26:31,513 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:26:31,513 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...'
2024-12-10 22:26:31,514 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:26:31,526 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:26:31,532 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:26:31,532 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:26:31,532 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 4 (required min_chunks=1)
2024-12-10 22:26:31,532 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there will be9 trillion dollars of value created did every single year which will offset the $9 trillion capax that he thought would be needed    ': [interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:26:31,533 - src.retrieval.reranking - INFO - Initial retrieval returned 4 results in 0.02s
2024-12-10 22:26:31,542 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:26:31,542 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there will be9 trillion dollars of value created did every single year which will offset the $9 tril...' with 4 documents
2024-12-10 22:26:32,229 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:26:32,230 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:26:32,230 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.72s. Returned 4 results
2024-12-10 22:26:32,230 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there will be9 trillion dollars of value created did every single year which will offset the $9 tril...', Keywords=['value creation', 'capax', 'AI models'], Codes=2
2024-12-10 22:26:32,230 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:26:32,245 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:26:39,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:26:39,436 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:26:39,439 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:26:39,439 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:26:39,439 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...'
2024-12-10 22:26:39,440 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:26:39,451 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:26:39,459 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:26:39,459 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:26:39,459 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:26:39,459 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'think about how much economic value gets unlocked for the world if anybody can just describe like a whole company's worth of software that they want     ': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:26:39,459 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:26:39,468 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:26:39,468 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'think about how much economic value gets unlocked for the world if anybody can just describe like a ...' with 5 documents
2024-12-10 22:26:40,474 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:26:40,474 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.01s. Top score: 0.9991, Bottom score: 0.0000
2024-12-10 22:26:40,474 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.04s. Returned 5 results
2024-12-10 22:26:40,474 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='think about how much economic value gets unlocked for the world if anybody can just describe like a ...', Keywords=['economic value', 'software needs', 'transformative potential', 'reasoning'], Codes=3
2024-12-10 22:26:40,475 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:26:40,487 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:26:49,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:26:49,904 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:26:49,906 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:26:49,907 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:26:49,908 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's clearly a really important place in the Eos system for open source models     ...'
2024-12-10 22:26:49,908 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:26:49,918 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:26:49,926 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:26:49,926 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:26:49,926 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:26:49,926 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's clearly a really important place in the Eos system for open source models     ': [interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4]
2024-12-10 22:26:49,926 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:26:49,934 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:26:49,934 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's clearly a really important place in the Eos system for open source models     ...' with 5 documents
2024-12-10 22:26:50,674 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:26:50,677 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:26:50,678 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:26:50,678 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there's clearly a really important place in the Eos system for open source models...', Keywords=['open source models', 'Eos system', 'transformative potential'], Codes=3
2024-12-10 22:26:50,678 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:26:50,703 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:27:04,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:27:04,872 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:27:04,875 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:27:04,875 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:27:04,876 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...'
2024-12-10 22:27:04,876 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:27:04,888 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:27:04,896 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:27:04,896 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:27:04,896 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:27:04,896 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the category I think though is more interesting is not the one that people normally talk about where you have this thing calling restaurants for you but something that's more like a really smart senior co-worker     ': [interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0]
2024-12-10 22:27:04,896 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:27:04,903 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:27:04,903 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the category I think though is more interesting is not the one that people normally talk about where...' with 5 documents
2024-12-10 22:27:05,679 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:27:05,682 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.78s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:27:05,683 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.81s. Returned 5 results
2024-12-10 22:27:05,683 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the category I think though is more interesting is not the one that people normally talk about where...', Keywords=['smart senior co-worker', 'transformative potential', 'complex tasks'], Codes=2
2024-12-10 22:27:05,683 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:27:05,708 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:27:17,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:27:17,776 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:27:17,777 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:27:17,778 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:27:17,778 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...'
2024-12-10 22:27:17,778 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:27:17,789 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:27:17,796 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:27:17,796 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:27:17,797 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:27:17,797 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'reasoning is our current most important area of focus I think this is what unlocks the next like massive Leap Forward in in value created     ': [interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:27:17,797 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:27:17,807 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:27:17,807 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'reasoning is our current most important area of focus I think this is what unlocks the next like mas...' with 5 documents
2024-12-10 22:27:18,490 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:27:18,492 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:27:18,492 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.71s. Returned 5 results
2024-12-10 22:27:18,492 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='reasoning is our current most important area of focus I think this is what unlocks the next like mas...', Keywords=['reasoning', 'economic value', 'transformation'], Codes=3
2024-12-10 22:27:18,493 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:27:18,514 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:27:28,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:27:28,998 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:27:29,000 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:27:29,000 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:27:29,000 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair     ...'
2024-12-10 22:27:29,000 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:27:29,013 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:27:29,018 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.004s]
2024-12-10 22:27:29,018 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:27:29,018 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:27:29,018 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the actual like Revenue we can make from a model I think justifies the investment to be fair     ': [interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:27:29,018 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:27:29,026 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:27:29,026 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the actual like Revenue we can make from a model I think justifies the investment to be fair     ...' with 5 documents
2024-12-10 22:27:29,740 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:27:29,743 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.72s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:27:29,743 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.74s. Returned 5 results
2024-12-10 22:27:29,743 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the actual like Revenue we can make from a model I think justifies the investment to be fair...', Keywords=['Revenue', 'Investment', 'AI Models'], Codes=2
2024-12-10 22:27:29,744 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:27:29,768 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:27:36,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:27:36,514 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:27:36,516 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:27:36,517 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:27:36,517 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...'
2024-12-10 22:27:36,517 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:27:36,528 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:27:36,535 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:27:36,535 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:27:36,535 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:27:36,535 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy to copy something you know Works     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:27:36,536 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:27:36,546 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:27:36,546 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...' with 5 documents
2024-12-10 22:27:37,255 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:27:37,259 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9974, Bottom score: 0.0000
2024-12-10 22:27:37,259 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.74s. Returned 5 results
2024-12-10 22:27:37,259 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='what comes beyond the Transformer how we do it is like our special sauce it's easy it's really easy ...', Keywords=['Transformer', 'innovation', 'replicate', 'culture', 'human talent'], Codes=3
2024-12-10 22:27:37,260 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:27:37,283 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:27:47,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:27:47,156 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:27:47,159 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:27:47,159 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:27:47,160 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the repeated ability to go off and do something new and totally unproven     ...'
2024-12-10 22:27:47,160 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:27:47,167 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:27:47,171 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:27:47,171 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:27:47,171 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:27:47,171 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the repeated ability to go off and do something new and totally unproven     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:27:47,171 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.01s
2024-12-10 22:27:47,180 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:27:47,181 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the repeated ability to go off and do something new and totally unproven     ...' with 5 documents
2024-12-10 22:27:47,897 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:27:47,900 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.72s. Top score: 0.9962, Bottom score: 0.0000
2024-12-10 22:27:47,900 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.74s. Returned 5 results
2024-12-10 22:27:47,900 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the repeated ability to go off and do something new and totally unproven...', Keywords=['innovation', 'unproven', 'ability'], Codes=2
2024-12-10 22:27:47,901 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:27:47,926 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:27:55,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:27:55,780 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:27:55,783 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:27:55,783 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:27:55,784 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture   ...'
2024-12-10 22:27:55,784 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:27:55,795 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:27:55,802 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:27:55,802 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:27:55,802 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:27:55,802 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there's a huge amount of wasted human talent because this is not an organization style or culture     ': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_3]
2024-12-10 22:27:55,802 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:27:55,810 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:27:55,810 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there's a huge amount of wasted human talent because this is not an organization style or culture   ...' with 5 documents
2024-12-10 22:27:57,808 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:27:57,812 - src.retrieval.reranking - INFO - Cohere reranking completed in 2.00s. Top score: 0.9972, Bottom score: 0.0000
2024-12-10 22:27:57,812 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.03s. Returned 5 results
2024-12-10 22:27:57,812 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there's a huge amount of wasted human talent because this is not an organization style or culture...', Keywords=['wasted human talent', 'organization style', 'innovation'], Codes=3
2024-12-10 22:27:57,813 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:27:57,835 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:28:07,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:28:07,667 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:28:07,669 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:28:07,670 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:28:07,670 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     ...'
2024-12-10 22:28:07,671 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:28:07,681 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:28:07,688 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:28:07,688 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:28:07,688 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:28:07,688 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     ': [interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_3]
2024-12-10 22:28:07,688 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:28:07,698 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:28:07,698 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I hope it'll get us much better than we are now at helping get everyone to their Max potential     ...' with 5 documents
2024-12-10 22:28:09,277 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:28:09,280 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.58s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:28:09,281 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.61s. Returned 5 results
2024-12-10 22:28:09,281 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I hope it'll get us much better than we are now at helping get everyone to their Max potential...', Keywords=['Max potential', 'innovation', 'unlock potential'], Codes=3
2024-12-10 22:28:09,282 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:28:09,302 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:28:19,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:28:19,214 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:28:19,216 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:28:19,216 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:28:19,217 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...'
2024-12-10 22:28:19,217 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:28:19,227 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:28:19,234 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:28:19,235 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:28:19,235 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:28:19,235 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big step forward while still not neglecting everything else that we have to do.     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_0, interview_001_chunk_4]
2024-12-10 22:28:19,235 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:28:19,245 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:28:19,246 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I badly underappreciated the amount of work it took to be able to like keep charging at the next big...' with 5 documents
2024-12-10 22:28:20,028 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:28:20,031 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.79s. Top score: 0.9999, Bottom score: 0.0000
2024-12-10 22:28:20,032 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.82s. Returned 5 results
2024-12-10 22:28:20,032 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I badly underappreciated the amount of work it took to be able to like keep charging at the next big...', Keywords=['underappreciated', 'work', 'next big step', 'neglecting'], Codes=2
2024-12-10 22:28:20,032 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:28:20,052 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:28:30,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:28:30,718 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:28:30,720 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:28:30,720 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:28:30,721 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     ...'
2024-12-10 22:28:30,721 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:28:30,731 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.010s]
2024-12-10 22:28:30,737 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:28:30,737 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:28:30,737 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:28:30,737 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     ': [interview_001_chunk_2, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:28:30,738 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:28:30,747 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:28:30,747 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'there was either no playbook for this or someone had a secret Playbook they didn't give me.     ...' with 5 documents
2024-12-10 22:28:31,440 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:28:31,443 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.70s. Top score: 0.9996, Bottom score: 0.0000
2024-12-10 22:28:31,443 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.72s. Returned 5 results
2024-12-10 22:28:31,443 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='there was either no playbook for this or someone had a secret Playbook they didn't give me....', Keywords=['playbook', 'innovation', 'challenges', 'unproven ideas', 'human talent'], Codes=3
2024-12-10 22:28:31,444 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:28:31,467 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:28:42,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:28:42,052 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:28:42,054 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:28:42,055 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:28:42,055 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     ...'
2024-12-10 22:28:42,055 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:28:42,067 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:28:42,073 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:28:42,073 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:28:42,073 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:28:42,073 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     ': [interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_3]
2024-12-10 22:28:42,073 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:28:42,081 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:28:42,081 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you should hire incredibly young people under 30 and that is what Peter teal taught him.     ...' with 5 documents
2024-12-10 22:28:45,066 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:28:45,069 - src.retrieval.reranking - INFO - Cohere reranking completed in 2.99s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:28:45,069 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 3.01s. Returned 5 results
2024-12-10 22:28:45,070 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='you should hire incredibly young people under 30 and that is what Peter teal taught him....', Keywords=['young people', 'innovation', 'talent'], Codes=2
2024-12-10 22:28:45,070 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:28:45,098 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:28:52,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:28:52,622 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:28:52,624 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:28:52,624 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:28:52,625 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...'
2024-12-10 22:28:52,625 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:28:52,642 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.016s]
2024-12-10 22:28:52,651 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:28:52,653 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:28:52,653 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:28:52,653 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'when you're like designing some of the most complex and massively expensive computer systems that Humanity has ever built.     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_0]
2024-12-10 22:28:52,653 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:28:52,663 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:28:52,663 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'when you're like designing some of the most complex and massively expensive computer systems that Hu...' with 5 documents
2024-12-10 22:28:58,297 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:28:58,300 - src.retrieval.reranking - INFO - Cohere reranking completed in 5.64s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:28:58,300 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 5.68s. Returned 5 results
2024-12-10 22:28:58,300 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='when you're like designing some of the most complex and massively expensive computer systems that Hu...', Keywords=['designing', 'complex', 'expensive', 'computer systems', 'innovation'], Codes=2
2024-12-10 22:28:58,301 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:28:58,323 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:29:08,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:29:08,161 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:29:08,163 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:29:08,164 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:29:08,164 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'you want both.     ...'
2024-12-10 22:29:08,164 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:29:08,173 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.008s]
2024-12-10 22:29:08,179 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:29:08,179 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:29:08,179 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 3 (required min_chunks=1)
2024-12-10 22:29:08,179 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'you want both.     ': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:29:08,180 - src.retrieval.reranking - INFO - Initial retrieval returned 3 results in 0.02s
2024-12-10 22:29:08,191 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:29:08,191 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'you want both.     ...' with 3 documents
2024-12-10 22:29:08,850 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:29:08,853 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.66s. Top score: 0.9723, Bottom score: 0.0000
2024-12-10 22:29:08,853 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.69s. Returned 3 results
2024-12-10 22:29:08,853 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='you want both....', Keywords=['innovation', 'replication', 'culture'], Codes=2
2024-12-10 22:29:08,854 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:29:08,876 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:29:16,050 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:29:16,054 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:29:16,055 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:29:16,056 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:29:16,056 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...'
2024-12-10 22:29:16,056 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:29:16,066 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:29:16,072 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:29:16,072 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:29:16,072 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:29:16,072 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'inexperience does not inherently mean not valuable and there are incredibly high potential people at the very beginning of their career that can create huge amounts of value     ': [interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_3]
2024-12-10 22:29:16,072 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:29:16,078 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:29:16,078 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'inexperience does not inherently mean not valuable and there are incredibly high potential people at...' with 5 documents
2024-12-10 22:29:16,743 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:29:16,746 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.67s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:29:16,746 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.69s. Returned 5 results
2024-12-10 22:29:16,746 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='inexperience does not inherently mean not valuable and there are incredibly high potential people at...', Keywords=['inexperience', 'potential', 'value'], Codes=2
2024-12-10 22:29:16,747 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:29:16,775 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:29:25,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:29:25,269 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:29:25,272 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:29:25,272 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:29:25,273 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...'
2024-12-10 22:29:25,273 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:29:25,289 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.015s]
2024-12-10 22:29:25,296 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:29:25,296 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:29:25,296 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:29:25,296 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think developers use multiple models most of the time and I'm not sure how that's all going to evolve as we head towards this more AG genified World     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_4, interview_001_chunk_0]
2024-12-10 22:29:25,297 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:29:25,307 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:29:25,308 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think developers use multiple models most of the time and I'm not sure how that's all going to evo...' with 5 documents
2024-12-10 22:29:26,040 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:29:26,043 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.74s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:29:26,043 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:29:26,043 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think developers use multiple models most of the time and I'm not sure how that's all going to evo...', Keywords=['multiple models', 'AG genified World', 'collaboration', 'reasoning capabilities'], Codes=3
2024-12-10 22:29:26,044 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:29:26,065 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:29:39,229 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:29:39,243 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:29:39,245 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:29:39,246 - src.processing.query_processor - INFO - Developed 3 themes for theme development.
2024-12-10 22:29:39,246 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing   ...'
2024-12-10 22:29:39,247 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:29:39,257 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.009s]
2024-12-10 22:29:39,263 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:29:39,264 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:29:39,264 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:29:39,264 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing     ': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1]
2024-12-10 22:29:39,264 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:29:39,275 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:29:39,276 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'we have a lot of people here who are excited to build AGI and that that's a very motivating thing   ...' with 5 documents
2024-12-10 22:29:39,981 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:29:39,985 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 1.0000, Bottom score: 0.0127
2024-12-10 22:29:39,985 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.74s. Returned 5 results
2024-12-10 22:29:39,985 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='we have a lot of people here who are excited to build AGI and that that's a very motivating thing...', Keywords=['AGI', 'motivation', 'collaboration'], Codes=2
2024-12-10 22:29:39,985 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:29:40,004 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:29:49,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:29:49,367 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:29:49,371 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:29:49,373 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:29:49,375 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions   ...'
2024-12-10 22:29:49,375 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:29:49,432 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.054s]
2024-12-10 22:29:49,436 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:29:49,436 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:29:49,436 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 3 (required min_chunks=1)
2024-12-10 22:29:49,436 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the heaviest things in life are not iron or gold but unmade decisions   ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_4]
2024-12-10 22:29:49,436 - src.retrieval.reranking - INFO - Initial retrieval returned 3 results in 0.06s
2024-12-10 22:29:49,449 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:29:49,449 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the heaviest things in life are not iron or gold but unmade decisions   ...' with 3 documents
2024-12-10 22:29:50,089 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:29:50,093 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.64s. Top score: 0.9963, Bottom score: 0.0000
2024-12-10 22:29:50,093 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.72s. Returned 3 results
2024-12-10 22:29:50,093 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the heaviest things in life are not iron or gold but unmade decisions...', Keywords=['decisions', 'collaboration', 'AI development'], Codes=2
2024-12-10 22:29:50,094 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:29:50,122 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:29:58,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:29:58,899 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:29:58,902 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:29:58,902 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:29:58,903 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...'
2024-12-10 22:29:58,903 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:29:58,922 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.019s]
2024-12-10 22:29:58,929 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:29:58,929 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:29:58,929 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:29:58,929 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think the wrong way to do that is to have one person you lean on for everything and the right way to at least for me the right way to do it is to have like 15 or 20 people Each of which you have come to believe has good instincts and good context in a particular way     ': [interview_001_chunk_3, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_4, interview_001_chunk_1]
2024-12-10 22:29:58,929 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:29:58,939 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:29:58,939 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think the wrong way to do that is to have one person you lean on for everything and the right way ...' with 5 documents
2024-12-10 22:29:59,649 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:29:59,652 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.71s. Top score: 0.9999, Bottom score: 0.0002
2024-12-10 22:29:59,652 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.75s. Returned 5 results
2024-12-10 22:29:59,652 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think the wrong way to do that is to have one person you lean on for everything and the right way ...', Keywords=['collaboration', 'decision-making', 'diversity'], Codes=2
2024-12-10 22:29:59,652 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:29:59,676 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:30:08,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:30:08,314 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:30:08,315 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:30:08,316 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:30:08,316 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...'
2024-12-10 22:30:08,316 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:30:08,327 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.011s]
2024-12-10 22:30:08,334 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.006s]
2024-12-10 22:30:08,335 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:30:08,335 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:30:08,335 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have seen in any industry before     ': [interview_001_chunk_1, interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:30:08,335 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:30:08,344 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:30:08,344 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...' with 5 documents
2024-12-10 22:30:10,373 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:30:10,376 - src.retrieval.reranking - INFO - Cohere reranking completed in 2.03s. Top score: 0.9998, Bottom score: 0.0000
2024-12-10 22:30:10,376 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 2.06s. Returned 5 results
2024-12-10 22:30:10,376 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the overall ecosystem complexity at every level of like the fractal scan is unlike anything I have s...', Keywords=['ecosystem complexity', 'fractal scan', 'collaboration', 'integrated systems'], Codes=3
2024-12-10 22:30:10,377 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:30:10,402 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:30:20,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:30:20,830 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:30:20,833 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:30:20,833 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:30:20,834 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...'
2024-12-10 22:30:20,834 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:30:20,849 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.014s]
2024-12-10 22:30:20,856 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.007s]
2024-12-10 22:30:20,856 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:30:20,856 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:30:20,856 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'it was very like one of the defining things about the internet Revolution was it was actually really easy to get started     ': [interview_001_chunk_3, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_1, interview_001_chunk_4]
2024-12-10 22:30:20,857 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:30:20,866 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:30:20,866 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'it was very like one of the defining things about the internet Revolution was it was actually really...' with 5 documents
2024-12-10 22:30:21,618 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:30:21,621 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.76s. Top score: 0.9983, Bottom score: 0.0000
2024-12-10 22:30:21,621 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.79s. Returned 5 results
2024-12-10 22:30:21,622 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='it was very like one of the defining things about the internet Revolution was it was actually really...', Keywords=['internet Revolution', 'easy to get started', 'AI development'], Codes=2
2024-12-10 22:30:21,622 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:30:21,645 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:30:28,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:30:28,985 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:30:28,987 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:30:28,988 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:30:28,988 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...'
2024-12-10 22:30:28,988 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:30:29,010 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.021s]
2024-12-10 22:30:29,013 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:30:29,013 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:30:29,013 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:30:29,014 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the one I like the most caveat by my earlier comment that I don't think people should be doing this or trying to like use these analogies too seriously is the transistor it was a new discovery of physics it had incredible scaling properties     ': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:30:29,014 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:30:29,024 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:30:29,024 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the one I like the most caveat by my earlier comment that I don't think people should be doing this ...' with 5 documents
2024-12-10 22:30:29,713 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:30:29,716 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.69s. Top score: 0.9997, Bottom score: 0.0000
2024-12-10 22:30:29,716 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.73s. Returned 5 results
2024-12-10 22:30:29,716 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the one I like the most caveat by my earlier comment that I don't think people should be doing this ...', Keywords=['discovery', 'scaling properties', 'analogies'], Codes=3
2024-12-10 22:30:29,717 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:30:29,739 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:30:42,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:30:42,858 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:30:42,861 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:30:42,862 - src.processing.query_processor - INFO - Developed 3 themes for theme development.
2024-12-10 22:30:42,862 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...'
2024-12-10 22:30:42,862 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:30:42,885 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.022s]
2024-12-10 22:30:42,891 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.005s]
2024-12-10 22:30:42,891 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:30:42,891 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:30:42,891 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'something about an AI that can understand your whole life doesn't have to like literally be infinite context but some way that you can have an AI agent that like knows everything there is to know about you has access to all of your data     ': [interview_001_chunk_4, interview_001_chunk_3, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:30:42,891 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:30:42,898 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:30:42,898 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'something about an AI that can understand your whole life doesn't have to like literally be infinite...' with 5 documents
2024-12-10 22:30:43,897 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:30:43,898 - src.retrieval.reranking - INFO - Cohere reranking completed in 1.00s. Top score: 0.9999, Bottom score: 0.0001
2024-12-10 22:30:43,898 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 1.04s. Returned 5 results
2024-12-10 22:30:43,898 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='something about an AI that can understand your whole life doesn't have to like literally be infinite...', Keywords=['AI', 'understand', 'data', 'enhance'], Codes=2
2024-12-10 22:30:43,898 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:30:43,909 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:30:59,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:30:59,613 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:30:59,616 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:30:59,616 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:30:59,617 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...'
2024-12-10 22:30:59,618 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:30:59,626 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.008s]
2024-12-10 22:30:59,630 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:30:59,631 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:30:59,631 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:30:59,631 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think to really have do what they've done and built I thought about like a bunch of researchers I could name     ': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:30:59,631 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.01s
2024-12-10 22:30:59,639 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:30:59,640 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think to really have do what they've done and built I thought about like a bunch of researchers I ...' with 5 documents
2024-12-10 22:31:00,368 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:31:00,372 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9994, Bottom score: 0.0000
2024-12-10 22:31:00,372 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.76s. Returned 5 results
2024-12-10 22:31:00,372 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think to really have do what they've done and built I thought about like a bunch of researchers I ...', Keywords=['AI', 'researchers', 'leadership'], Codes=2
2024-12-10 22:31:00,373 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:31:00,396 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:31:07,073 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:31:07,079 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:31:07,082 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:31:07,082 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:31:07,083 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I think that product is a weakness of mine in general     ...'
2024-12-10 22:31:07,083 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:31:07,097 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.013s]
2024-12-10 22:31:07,106 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.008s]
2024-12-10 22:31:07,107 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:31:07,107 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:31:07,107 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I think that product is a weakness of mine in general     ': [interview_001_chunk_4, interview_001_chunk_2, interview_001_chunk_0, interview_001_chunk_3, interview_001_chunk_1]
2024-12-10 22:31:07,108 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.02s
2024-12-10 22:31:07,118 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:31:07,119 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I think that product is a weakness of mine in general     ...' with 5 documents
2024-12-10 22:31:07,846 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:31:07,849 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.73s. Top score: 0.9990, Bottom score: 0.0000
2024-12-10 22:31:07,849 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.77s. Returned 5 results
2024-12-10 22:31:07,849 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I think that product is a weakness of mine in general...', Keywords=['product', 'weakness', 'leadership'], Codes=2
2024-12-10 22:31:07,849 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:31:07,875 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:31:18,664 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:31:18,674 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:31:18,685 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:31:18,687 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:31:18,699 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...'
2024-12-10 22:31:18,700 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:31:18,763 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.050s]
2024-12-10 22:31:18,767 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.003s]
2024-12-10 22:31:18,767 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:31:18,767 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:31:18,767 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a couple of years     ': [interview_001_chunk_4, interview_001_chunk_0, interview_001_chunk_2, interview_001_chunk_1, interview_001_chunk_3]
2024-12-10 22:31:18,767 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.07s
2024-12-10 22:31:18,777 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:31:18,777 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...' with 5 documents
2024-12-10 22:31:24,789 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:31:24,790 - src.retrieval.reranking - INFO - Cohere reranking completed in 6.01s. Top score: 1.0000, Bottom score: 0.0000
2024-12-10 22:31:24,790 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 6.09s. Returned 5 results
2024-12-10 22:31:24,790 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='I want you to go like make a new important Discovery in physics you'd probably be happy to wait a co...', Keywords=['Discovery', 'Physics', 'AI', 'Years'], Codes=3
2024-12-10 22:31:24,790 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:31:24,810 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:31:35,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:31:35,181 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:31:35,184 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:31:35,184 - src.processing.query_processor - INFO - Developed 2 themes for theme development.
2024-12-10 22:31:35,185 - src.retrieval.reranking - INFO - Starting retrieval and reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...'
2024-12-10 22:31:35,185 - src.core.contextual_vector_db - ERROR - Embeddings or metadata are not loaded. Cannot perform search.
2024-12-10 22:31:35,202 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.017s]
2024-12-10 22:31:35,218 - elastic_transport.transport - INFO - POST http://localhost:9200/contextual_bm25_index_theme_development/_search [status:200 duration:0.012s]
2024-12-10 22:31:35,219 - src.retrieval.retrieval - INFO - Filtered 0 chunks due to missing metadata.
2024-12-10 22:31:35,219 - src.retrieval.retrieval - INFO - Total chunks retrieved after filtering: 5 (required min_chunks=1)
2024-12-10 22:31:35,219 - src.retrieval.retrieval - INFO - Chunks used for hybrid retrieval for query 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI research and also about all of the rest of Science     ': [interview_001_chunk_3, interview_001_chunk_4, interview_001_chunk_1, interview_001_chunk_2, interview_001_chunk_0]
2024-12-10 22:31:35,219 - src.retrieval.reranking - INFO - Initial retrieval returned 5 results in 0.03s
2024-12-10 22:31:35,232 - src.retrieval.reranking - INFO - CohereReRanker initialized successfully
2024-12-10 22:31:35,232 - src.retrieval.reranking - INFO - Starting Cohere reranking for query: 'the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...' with 5 documents
2024-12-10 22:31:35,866 - httpx - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank "HTTP/1.1 200 OK"
2024-12-10 22:31:35,869 - src.retrieval.reranking - INFO - Cohere reranking completed in 0.64s. Top score: 0.9998, Bottom score: 0.0006
2024-12-10 22:31:35,870 - src.retrieval.reranking - INFO - Retrieval and reranking completed in 0.68s. Returned 5 results
2024-12-10 22:31:35,870 - src.processing.query_processor - INFO - Processing transcript for theme development: Quotation='the pace of progress is like totally crazy and we're discovering all this new stuff both about AI re...', Keywords=['pace of progress', 'discovering new stuff', 'AI research', 'Science'], Codes=2
2024-12-10 22:31:35,870 - src.analysis.theme_development_module - INFO - Starting theme development analysis.
2024-12-10 22:31:35,890 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2024-12-10 22:31:44,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-10 22:31:44,799 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2024-12-10 22:31:44,801 - src.analysis.theme_development_module - INFO - Successfully completed theme development analysis.
2024-12-10 22:31:44,801 - src.processing.query_processor - INFO - Developed 1 themes for theme development.
2024-12-10 22:31:44,818 - src.processing.query_processor - INFO - All transcript results have been saved to 'data/output/query_results_theme_development.json'
2024-12-10 22:31:44,819 - __main__ - INFO - Processed queries in 358.15s
2024-12-10 22:31:44,819 - __main__ - INFO - Starting evaluation
2024-12-10 22:31:44,819 - src.data.data_loader - ERROR - Error loading JSON file 'data/evaluation/evaluation_set_theme.jsonl': File does not exist.
2024-12-10 22:31:44,819 - __main__ - INFO - Loaded 0 evaluation queries
2024-12-10 22:31:44,819 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@5
2024-12-10 22:31:44,819 - src.evaluation.evaluation - INFO - Starting evaluation of 0 queries.
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Pass@5: 0.00%, Average Score: 0.0000
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Pass@5: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@10
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Starting evaluation of 0 queries.
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Pass@10: 0.00%, Average Score: 0.0000
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Pass@10: 0.00%
2024-12-10 22:31:44,820 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Starting evaluation for Pass@20
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Starting evaluation of 0 queries.
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Evaluation completed.
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Pass@20: 0.00%, Average Score: 0.0000
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Semantic Hits: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - BM25 Contextual Hits: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Pass@20: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Average Score: 0.0000
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Semantic Hit Percentage: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - BM25 Contextual Hit Percentage: 0.00%
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Total Queries: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Queries with Golden Data: 0
2024-12-10 22:31:44,821 - src.evaluation.evaluation - INFO - Queries without Golden Data: 0

2024-12-10 22:31:44,821 - __main__ - INFO - Completed evaluation in 0.00s
2024-12-10 22:31:44,821 - __main__ - INFO - Pipeline for ThemedevelopmentAnalysisModule completed in 358.97s
2024-12-10 22:31:44,821 - __main__ - INFO - Completed Theme Development in 358.97s
2024-12-10 22:31:44,821 - __main__ - INFO - All pipeline stages completed successfully in 444.14s
2024-12-10 22:31:44,822 - __main__ - INFO - Pipeline execution completed successfully
2024-12-10 22:31:44,822 - __main__ - INFO - Thematic Analysis Pipeline execution finished
